{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "k9Hvt1frVXwO",
    "outputId": "a52e3d65-6bc5-486a-8022-0359787ccc19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mne\n",
      "  Downloading mne-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting pyedflib\n",
      "  Downloading pyEDFlib-0.1.38-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.4)\n",
      "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.4)\n",
      "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from mne) (3.8.0)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from mne) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (24.2)\n",
      "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.2)\n",
      "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from mne) (1.13.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (1.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (3.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.8.30)\n",
      "Downloading mne-1.8.0-py3-none-any.whl (7.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyEDFlib-0.1.38-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyedflib, mne\n",
      "Successfully installed mne-1.8.0 pyedflib-0.1.38\n"
     ]
    }
   ],
   "source": [
    "pip install mne pyedflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "QI05iApjVjis",
    "outputId": "8d8ad0cc-6bdd-47dc-8efe-51dc07e3960e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "from glob import glob\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "BXbWKzYUoyjl",
    "outputId": "19cb15ee-a74f-43f5-f389-66284644b3a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy Data Shape: (14, 19, 50, 500)\n",
      "Unhealthy Data Shape: (14, 19, 50, 500)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pyedflib\n",
    "import os\n",
    "\n",
    "# Directory containing EDF files\n",
    "# directory = '/content/drive/MyDrive/dataverse_files(2)'\n",
    "directory = '/content/drive/MyDrive/dataverse_files (2)'\n",
    "\n",
    "# Use glob to get a list of EDF file paths\n",
    "myfiles = glob.glob(directory + '/*.edf')\n",
    "\n",
    "# Sampling rate of your signals\n",
    "sampling_rate = 250  # Hz\n",
    "epoch_length = sampling_rate * 2  # 2 seconds = 500 samples per epoch\n",
    "num_samples_per_subject = 50  # Number of 2-second epochs to extract from each subject\n",
    "\n",
    "# Function to adjust EEG signal length to the nearest multiple of epoch length\n",
    "def adjust_signal_length(signal, epoch_length):\n",
    "    # Calculate the number of epochs that can be extracted\n",
    "    num_epochs = len(signal) // epoch_length\n",
    "    if num_epochs == 0:\n",
    "        return np.array([])  # Return empty array if not enough data\n",
    "    return signal[:num_epochs * epoch_length]  # Keep only the data that can be fully divided\n",
    "\n",
    "# Function to extract 2-second epochs directly from the signal\n",
    "def extract_epochs(signal, epoch_length):\n",
    "    num_epochs = len(signal) // epoch_length\n",
    "    epochs = []\n",
    "    for i in range(num_epochs):\n",
    "        start = i * epoch_length\n",
    "        end = start + epoch_length\n",
    "        epochs.append(signal[start:end])\n",
    "    return epochs\n",
    "\n",
    "# Function to randomly select a specified number of epochs\n",
    "def select_random_samples(epochs, num_samples):\n",
    "    epochs_array = np.array(epochs)  # Convert to a NumPy array\n",
    "    if len(epochs_array) <= num_samples:\n",
    "        return epochs_array  # If there are fewer epochs than needed, return all\n",
    "    indices = np.random.choice(len(epochs_array), num_samples, replace=False)\n",
    "    return epochs_array[indices]  # Select the samples by indices\n",
    "\n",
    "# Initialize lists to store epochs for unhealthy and healthy signals\n",
    "# Assume maximum of 19 channels and 14 subjects\n",
    "num_channels = 19\n",
    "num_subjects = 14\n",
    "num_epochs = num_samples_per_subject\n",
    "epoch_length = 500\n",
    "\n",
    "# Initialize multidimensional arrays to store epochs\n",
    "healthy_data = np.empty((num_subjects, num_channels, num_epochs, epoch_length))\n",
    "unhealthy_data = np.empty((num_subjects, num_channels, num_epochs, epoch_length))\n",
    "\n",
    "# Initialize counters for subjects\n",
    "healthy_subject_counter = 0\n",
    "unhealthy_subject_counter = 0\n",
    "\n",
    "# Process each file\n",
    "for file in myfiles:\n",
    "    # Open the EDF file\n",
    "    f = pyedflib.EdfReader(file)\n",
    "\n",
    "    # Get signal labels (channel names)\n",
    "    signal_labels = f.getSignalLabels()\n",
    "\n",
    "    # Extract the filename and determine if the subject is healthy or unhealthy\n",
    "    filename = file.split('/')[-1]\n",
    "    subject_type = 'healthy' if 'h' in filename else 'unhealthy'\n",
    "\n",
    "    # Initialize temporary storage for epochs\n",
    "    temp_epochs = {label: [] for label in signal_labels}\n",
    "\n",
    "    # Process each channel (electrode)\n",
    "    for i, label in enumerate(signal_labels):\n",
    "        signal = f.readSignal(i)\n",
    "\n",
    "        # Adjust the signal length to the nearest multiple of epoch length\n",
    "        adjusted_signal = adjust_signal_length(signal, epoch_length)\n",
    "\n",
    "        # Extract 2-second epochs directly from the signal\n",
    "        epochs = extract_epochs(adjusted_signal, epoch_length)\n",
    "\n",
    "        # Select 50 random epochs if there are enough, otherwise use all available\n",
    "        selected_epochs = select_random_samples(epochs, num_samples_per_subject)\n",
    "\n",
    "        # Store epochs in temporary storage\n",
    "        temp_epochs[label] = selected_epochs\n",
    "\n",
    "    # Store the epochs in the appropriate multidimensional array\n",
    "    if subject_type == 'healthy':\n",
    "        for ch in range(num_channels):\n",
    "            if ch < len(signal_labels):  # Ensure channel exists\n",
    "                healthy_data[healthy_subject_counter, ch, :, :] = temp_epochs[signal_labels[ch]]\n",
    "        healthy_subject_counter += 1\n",
    "    else:\n",
    "        for ch in range(num_channels):\n",
    "            if ch < len(signal_labels):  # Ensure channel exists\n",
    "                unhealthy_data[unhealthy_subject_counter, ch, :, :] = temp_epochs[signal_labels[ch]]\n",
    "        unhealthy_subject_counter += 1\n",
    "\n",
    "    f._close()  # Close the EDF file\n",
    "\n",
    "# Check dimensions and save the data\n",
    "print(f\"Healthy Data Shape: {healthy_data.shape}\")\n",
    "print(f\"Unhealthy Data Shape: {unhealthy_data.shape}\")\n",
    "\n",
    "# Optionally save the data to disk\n",
    "np.save('healthy_data.npy', healthy_data)\n",
    "np.save('unhealthy_data.npy', unhealthy_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "E0cbNNH7n9uZ",
    "outputId": "2f814314-ecc0-4a2e-a479-cd5a50af38af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.317479857782855"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy_data[0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "id": "cqfkO1c9894s",
    "outputId": "e841fe9e-3776-495c-bd2d-a68381539eb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Subject_ID Channel  Epoch  \\\n",
      "0           1     Fp1      1   \n",
      "1           1     Fp1      2   \n",
      "2           1     Fp1      3   \n",
      "3           1     Fp1      4   \n",
      "4           1     Fp1      5   \n",
      "\n",
      "                                       Signal_Values  \n",
      "0  [11.317479857782855, 11.011669591356267, 11.77...  \n",
      "1  [-5.9608001953193535, -10.395049058504876, -11...  \n",
      "2  [8.870997726370152, 9.023902859583446, 4.89546...  \n",
      "3  [-11.465384990997933, -11.006669591358051, -8....  \n",
      "4  [74.62020500808651, 61.16455328531666, 52.4489...  \n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_healthy\",\n  \"rows\": 13300,\n  \"fields\": [\n    {\n      \"column\": \"Subject_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 1,\n        \"max\": 14,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          10,\n          12,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Channel\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"Fp1\",\n          \"C4\",\n          \"F8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 1,\n        \"max\": 50,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          14,\n          40,\n          31\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Signal_Values\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_healthy"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-3cdd1ed2-fb90-4f60-a77c-c379ec4d76cd\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject_ID</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Signal_Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>1</td>\n",
       "      <td>[11.317479857782855, 11.011669591356267, 11.77...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>2</td>\n",
       "      <td>[-5.9608001953193535, -10.395049058504876, -11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>3</td>\n",
       "      <td>[8.870997726370152, 9.023902859583446, 4.89546...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>4</td>\n",
       "      <td>[-11.465384990997933, -11.006669591358051, -8....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>5</td>\n",
       "      <td>[74.62020500808651, 61.16455328531666, 52.4489...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13295</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>46</td>\n",
       "      <td>[-1.0678359324939495, -4.584653996399709, -5.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13296</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>47</td>\n",
       "      <td>[-10.242143925291582, -10.089238792078289, -9....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13297</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>48</td>\n",
       "      <td>[7.18904126102392, 3.6722231971181607, 1.68445...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13298</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>49</td>\n",
       "      <td>[-5.349179662466178, -7.489851527452292, -9.63...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13299</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>50</td>\n",
       "      <td>[2.143171864985222, 0.6141205328522832, 0.0024...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13300 rows × 4 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cdd1ed2-fb90-4f60-a77c-c379ec4d76cd')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-3cdd1ed2-fb90-4f60-a77c-c379ec4d76cd button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-3cdd1ed2-fb90-4f60-a77c-c379ec4d76cd');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-80cca02c-eb23-4bc4-976c-448d08854fcc\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-80cca02c-eb23-4bc4-976c-448d08854fcc')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-80cca02c-eb23-4bc4-976c-448d08854fcc button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_9a98ec0c-429e-4413-8a1f-ece8f74a2d20\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_healthy')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_9a98ec0c-429e-4413-8a1f-ece8f74a2d20 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df_healthy');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "       Subject_ID Channel  Epoch  \\\n",
       "0               1     Fp1      1   \n",
       "1               1     Fp1      2   \n",
       "2               1     Fp1      3   \n",
       "3               1     Fp1      4   \n",
       "4               1     Fp1      5   \n",
       "...           ...     ...    ...   \n",
       "13295          14      Pz     46   \n",
       "13296          14      Pz     47   \n",
       "13297          14      Pz     48   \n",
       "13298          14      Pz     49   \n",
       "13299          14      Pz     50   \n",
       "\n",
       "                                           Signal_Values  \n",
       "0      [11.317479857782855, 11.011669591356267, 11.77...  \n",
       "1      [-5.9608001953193535, -10.395049058504876, -11...  \n",
       "2      [8.870997726370152, 9.023902859583446, 4.89546...  \n",
       "3      [-11.465384990997933, -11.006669591358051, -8....  \n",
       "4      [74.62020500808651, 61.16455328531666, 52.4489...  \n",
       "...                                                  ...  \n",
       "13295  [-1.0678359324939495, -4.584653996399709, -5.5...  \n",
       "13296  [-10.242143925291582, -10.089238792078289, -9....  \n",
       "13297  [7.18904126102392, 3.6722231971181607, 1.68445...  \n",
       "13298  [-5.349179662466178, -7.489851527452292, -9.63...  \n",
       "13299  [2.143171864985222, 0.6141205328522832, 0.0024...  \n",
       "\n",
       "[13300 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Define dimensions\n",
    "num_subjects = 14\n",
    "num_channels = 19\n",
    "num_epochs = 50\n",
    "samples_per_epoch = 500\n",
    "\n",
    "# Create random healthy data\n",
    "# healthy_data _epoch)\n",
    "\n",
    "# Define channel labels\n",
    "signal_labels = [\n",
    "    \"Fp1\", \"Fp2\", \"F3\", \"F4\", \"C3\", \"C4\", \"P3\", \"P4\", \"O1\", \"O2\",\n",
    "    \"F7\", \"F8\", \"T3\", \"T4\", \"T5\", \"T6\", \"Fz\", \"Cz\", \"Pz\"\n",
    "]\n",
    "\n",
    "# Initialize a list to store rows of tabular data\n",
    "tabular_data = []\n",
    "\n",
    "# Iterate through each subject, channel, and epoch to flatten the data\n",
    "for subject in range(num_subjects):\n",
    "    for channel in range(num_channels):\n",
    "        for epoch in range(num_epochs):\n",
    "            # Extract the signal for the current subject, channel, and epoch\n",
    "            signal = healthy_data[subject, channel, epoch, :]\n",
    "\n",
    "            # Create a row with metadata and the signal values\n",
    "            row = {\n",
    "                'Subject_ID': subject + 1,\n",
    "                'Channel': signal_labels[channel],\n",
    "                'Epoch': epoch + 1,\n",
    "                'Signal_Values': list(signal)  # Convert numpy array to a list for better readability\n",
    "            }\n",
    "\n",
    "            # Append the row to the list\n",
    "            tabular_data.append(row)\n",
    "\n",
    "# Create a DataFrame from the list of rows\n",
    "df_healthy = pd.DataFrame(tabular_data)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df_healthy.head())\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file for further analysis\n",
    "df_healthy.to_csv('healthy_data_tabular.csv', index=False)\n",
    "\n",
    "# Optionally, display the DataFrame in a tabular format in Google Colab\n",
    "display(df_healthy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "id": "jRSYzRFttWzp",
    "outputId": "eff49fd7-1b8d-42b3-a670-1285bc3d1394"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Subject_ID Channel  Epoch  \\\n",
      "0           1     Fp1      1   \n",
      "1           1     Fp1      2   \n",
      "2           1     Fp1      3   \n",
      "3           1     Fp1      4   \n",
      "4           1     Fp1      5   \n",
      "\n",
      "                                       Signal_Values  \n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_healthy\",\n  \"rows\": 13300,\n  \"fields\": [\n    {\n      \"column\": \"Subject_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 1,\n        \"max\": 14,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          10,\n          12,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Channel\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"Fp1\",\n          \"C4\",\n          \"F8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 1,\n        \"max\": 50,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          14,\n          40,\n          31\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Signal_Values\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_healthy"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-8ed44691-eff6-4762-8030-0f01f106f24c\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject_ID</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Signal_Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13295</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>46</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13296</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>47</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13297</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>48</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13298</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>49</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13299</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>50</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13300 rows × 4 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ed44691-eff6-4762-8030-0f01f106f24c')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-8ed44691-eff6-4762-8030-0f01f106f24c button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-8ed44691-eff6-4762-8030-0f01f106f24c');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-a14e91c0-8d6f-4636-9557-ce038dc722b7\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a14e91c0-8d6f-4636-9557-ce038dc722b7')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-a14e91c0-8d6f-4636-9557-ce038dc722b7 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_46448edb-a055-4891-a1ed-8bbb595586cc\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_healthy')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_46448edb-a055-4891-a1ed-8bbb595586cc button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df_healthy');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "       Subject_ID Channel  Epoch  \\\n",
       "0               1     Fp1      1   \n",
       "1               1     Fp1      2   \n",
       "2               1     Fp1      3   \n",
       "3               1     Fp1      4   \n",
       "4               1     Fp1      5   \n",
       "...           ...     ...    ...   \n",
       "13295          14      Pz     46   \n",
       "13296          14      Pz     47   \n",
       "13297          14      Pz     48   \n",
       "13298          14      Pz     49   \n",
       "13299          14      Pz     50   \n",
       "\n",
       "                                           Signal_Values  \n",
       "0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "...                                                  ...  \n",
       "13295  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "13296  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "13297  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "13298  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "13299  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "\n",
       "[13300 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize a list to store rows of tabular data\n",
    "tabular_data = []\n",
    "\n",
    "# Iterate through each subject, channel, and epoch to flatten the data\n",
    "for subject in range(num_subjects):\n",
    "    for channel in range(num_channels):\n",
    "        for epoch in range(num_epochs):\n",
    "            # Extract the signal for the current subject, channel, and epoch\n",
    "            signal = healthy_data[subject, channel, epoch, :]\n",
    "\n",
    "            # Create a row with metadata and the signal values\n",
    "            row = {\n",
    "                'Subject_ID': subject + 1,\n",
    "                'Channel': signal_labels[channel],\n",
    "                'Epoch': epoch + 1,\n",
    "                'Signal_Values': list(signal)  # Convert numpy array to a list for better readability\n",
    "            }\n",
    "\n",
    "            # Append the row to the list\n",
    "            tabular_data.append(row)\n",
    "\n",
    "# Create a DataFrame from the list of rows\n",
    "df_healthy = pd.DataFrame(tabular_data)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df_healthy.head())\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file for further analysis\n",
    "df_healthy.to_csv('healthy_data_tabular.csv', index=False)\n",
    "\n",
    "# Optionally, display the DataFrame in a tabular format in Google Colab\n",
    "from IPython.display import display\n",
    "display(df_healthy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "id": "dQNFAOmDzbpu",
    "outputId": "516e5487-01d0-4782-932f-c5b8d53d1e02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Subject_ID Channel  Epoch  \\\n",
      "0           1     Fp1      1   \n",
      "1           1     Fp1      2   \n",
      "2           1     Fp1      3   \n",
      "3           1     Fp1      4   \n",
      "4           1     Fp1      5   \n",
      "\n",
      "                                       Signal_Values  \n",
      "0  [-3.5143180639066514, -1.526551332133831, -0.3...  \n",
      "1  [2.44898213141181, 4.742559129611218, 7.036136...  \n",
      "2  [-4.431748863186415, -4.125938596759827, -5.04...  \n",
      "3  [-3.6672231971199456, -3.8201283303332394, -6....  \n",
      "4  [3.2135077974782793, 3.6722231971181607, 2.754...  \n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_unhealthy\",\n  \"rows\": 13300,\n  \"fields\": [\n    {\n      \"column\": \"Subject_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 1,\n        \"max\": 14,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          10,\n          12,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Channel\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"Fp1\",\n          \"C4\",\n          \"F8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 1,\n        \"max\": 50,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          14,\n          40,\n          31\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Signal_Values\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_unhealthy"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-3436ae6d-60c5-4606-9460-bcfee970a298\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject_ID</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Signal_Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>1</td>\n",
       "      <td>[-3.5143180639066514, -1.526551332133831, -0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>2</td>\n",
       "      <td>[2.44898213141181, 4.742559129611218, 7.036136...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>3</td>\n",
       "      <td>[-4.431748863186415, -4.125938596759827, -5.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>4</td>\n",
       "      <td>[-3.6672231971199456, -3.8201283303332394, -6....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>5</td>\n",
       "      <td>[3.2135077974782793, 3.6722231971181607, 2.754...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13295</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>46</td>\n",
       "      <td>[-13.597209280679062, -15.56500930814572, 3.57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13296</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>47</td>\n",
       "      <td>[4.291881878108741, -14.133882015442696, -11.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13297</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>48</td>\n",
       "      <td>[-3.579318231757892, 10.73195469527235, 8.0485...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13298</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>49</td>\n",
       "      <td>[-10.019391048921502, 8.764154667805693, 12.69...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13299</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>50</td>\n",
       "      <td>[15.025336573381423, 8.406372844629937, -10.01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13300 rows × 4 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3436ae6d-60c5-4606-9460-bcfee970a298')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-3436ae6d-60c5-4606-9460-bcfee970a298 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-3436ae6d-60c5-4606-9460-bcfee970a298');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-46dab3b1-1fb8-4af6-934a-c6a401557213\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-46dab3b1-1fb8-4af6-934a-c6a401557213')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-46dab3b1-1fb8-4af6-934a-c6a401557213 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_41463e12-a66f-49be-abd6-6f33975d448d\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_unhealthy')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_41463e12-a66f-49be-abd6-6f33975d448d button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df_unhealthy');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "       Subject_ID Channel  Epoch  \\\n",
       "0               1     Fp1      1   \n",
       "1               1     Fp1      2   \n",
       "2               1     Fp1      3   \n",
       "3               1     Fp1      4   \n",
       "4               1     Fp1      5   \n",
       "...           ...     ...    ...   \n",
       "13295          14      Pz     46   \n",
       "13296          14      Pz     47   \n",
       "13297          14      Pz     48   \n",
       "13298          14      Pz     49   \n",
       "13299          14      Pz     50   \n",
       "\n",
       "                                           Signal_Values  \n",
       "0      [-3.5143180639066514, -1.526551332133831, -0.3...  \n",
       "1      [2.44898213141181, 4.742559129611218, 7.036136...  \n",
       "2      [-4.431748863186415, -4.125938596759827, -5.04...  \n",
       "3      [-3.6672231971199456, -3.8201283303332394, -6....  \n",
       "4      [3.2135077974782793, 3.6722231971181607, 2.754...  \n",
       "...                                                  ...  \n",
       "13295  [-13.597209280679062, -15.56500930814572, 3.57...  \n",
       "13296  [4.291881878108741, -14.133882015442696, -11.4...  \n",
       "13297  [-3.579318231757892, 10.73195469527235, 8.0485...  \n",
       "13298  [-10.019391048921502, 8.764154667805693, 12.69...  \n",
       "13299  [15.025336573381423, 8.406372844629937, -10.01...  \n",
       "\n",
       "[13300 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize a list to store rows of tabular data for unhealthy data\n",
    "tabular_data_unhealthy = []\n",
    "\n",
    "# Iterate through each subject, channel, and epoch to flatten the unhealthy data\n",
    "for subject in range(num_subjects):\n",
    "    for channel in range(num_channels):\n",
    "        for epoch in range(num_epochs):\n",
    "            # Extract the signal for the current subject, channel, and epoch\n",
    "            signal = unhealthy_data[subject, channel, epoch, :]\n",
    "\n",
    "            # Create a row with metadata and the signal values\n",
    "            row = {\n",
    "                'Subject_ID': subject + 1,\n",
    "                'Channel': signal_labels[channel],\n",
    "                'Epoch': epoch + 1,\n",
    "                'Signal_Values': list(signal)  # Convert numpy array to a list for better readability\n",
    "            }\n",
    "\n",
    "            # Append the row to the list\n",
    "            tabular_data_unhealthy.append(row)\n",
    "\n",
    "# Create a DataFrame from the list of rows for unhealthy data\n",
    "df_unhealthy = pd.DataFrame(tabular_data_unhealthy)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df_unhealthy.head())\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file for further analysis\n",
    "df_unhealthy.to_csv('unhealthy_data_tabular.csv', index=False)\n",
    "\n",
    "# Optionally, display the DataFrame in a tabular format in Google Colab\n",
    "from IPython.display import display\n",
    "display(df_unhealthy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bv7mXOsy5ecV"
   },
   "source": [
    "Working perfectly for IMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WEpTnec71Usm",
    "outputId": "7e6f8843-05e2-450a-cb37-9016a01bc486"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Subject: 1, Epoch: 1\n",
      "Processing Subject: 1, Epoch: 2\n",
      "Processing Subject: 1, Epoch: 3\n",
      "Processing Subject: 1, Epoch: 4\n",
      "Processing Subject: 1, Epoch: 5\n",
      "Processing Subject: 1, Epoch: 6\n",
      "Processing Subject: 1, Epoch: 7\n",
      "Processing Subject: 1, Epoch: 8\n",
      "Processing Subject: 1, Epoch: 9\n",
      "Processing Subject: 1, Epoch: 10\n",
      "Processing Subject: 1, Epoch: 11\n",
      "Processing Subject: 1, Epoch: 12\n",
      "Processing Subject: 1, Epoch: 13\n",
      "Processing Subject: 1, Epoch: 14\n",
      "Processing Subject: 1, Epoch: 15\n",
      "Processing Subject: 1, Epoch: 16\n",
      "Processing Subject: 1, Epoch: 17\n",
      "Processing Subject: 1, Epoch: 18\n",
      "Processing Subject: 1, Epoch: 19\n",
      "Processing Subject: 1, Epoch: 20\n",
      "Processing Subject: 1, Epoch: 21\n",
      "Processing Subject: 1, Epoch: 22\n",
      "Processing Subject: 1, Epoch: 23\n",
      "Processing Subject: 1, Epoch: 24\n",
      "Processing Subject: 1, Epoch: 25\n",
      "Processing Subject: 1, Epoch: 26\n",
      "Processing Subject: 1, Epoch: 27\n",
      "Processing Subject: 1, Epoch: 28\n",
      "Processing Subject: 1, Epoch: 29\n",
      "Processing Subject: 1, Epoch: 30\n",
      "Processing Subject: 1, Epoch: 31\n",
      "Processing Subject: 1, Epoch: 32\n",
      "Processing Subject: 1, Epoch: 33\n",
      "Processing Subject: 1, Epoch: 34\n",
      "Processing Subject: 1, Epoch: 35\n",
      "Processing Subject: 1, Epoch: 36\n",
      "Processing Subject: 1, Epoch: 37\n",
      "Processing Subject: 1, Epoch: 38\n",
      "Processing Subject: 1, Epoch: 39\n",
      "Processing Subject: 1, Epoch: 40\n",
      "Processing Subject: 1, Epoch: 41\n",
      "Processing Subject: 1, Epoch: 42\n",
      "Processing Subject: 1, Epoch: 43\n",
      "Processing Subject: 1, Epoch: 44\n",
      "Processing Subject: 1, Epoch: 45\n",
      "Processing Subject: 1, Epoch: 46\n",
      "Processing Subject: 1, Epoch: 47\n",
      "Processing Subject: 1, Epoch: 48\n",
      "Processing Subject: 1, Epoch: 49\n",
      "Processing Subject: 1, Epoch: 50\n",
      "Processing Subject: 2, Epoch: 1\n",
      "Processing Subject: 2, Epoch: 2\n",
      "Processing Subject: 2, Epoch: 3\n",
      "Processing Subject: 2, Epoch: 4\n",
      "Processing Subject: 2, Epoch: 5\n",
      "Processing Subject: 2, Epoch: 6\n",
      "Processing Subject: 2, Epoch: 7\n",
      "Processing Subject: 2, Epoch: 8\n",
      "Processing Subject: 2, Epoch: 9\n",
      "Processing Subject: 2, Epoch: 10\n",
      "Processing Subject: 2, Epoch: 11\n",
      "Processing Subject: 2, Epoch: 12\n",
      "Processing Subject: 2, Epoch: 13\n",
      "Processing Subject: 2, Epoch: 14\n",
      "Processing Subject: 2, Epoch: 15\n",
      "Processing Subject: 2, Epoch: 16\n",
      "Processing Subject: 2, Epoch: 17\n",
      "Processing Subject: 2, Epoch: 18\n",
      "Processing Subject: 2, Epoch: 19\n",
      "Processing Subject: 2, Epoch: 20\n",
      "Processing Subject: 2, Epoch: 21\n",
      "Processing Subject: 2, Epoch: 22\n",
      "Processing Subject: 2, Epoch: 23\n",
      "Processing Subject: 2, Epoch: 24\n",
      "Processing Subject: 2, Epoch: 25\n",
      "Processing Subject: 2, Epoch: 26\n",
      "Processing Subject: 2, Epoch: 27\n",
      "Processing Subject: 2, Epoch: 28\n",
      "Processing Subject: 2, Epoch: 29\n",
      "Processing Subject: 2, Epoch: 30\n",
      "Processing Subject: 2, Epoch: 31\n",
      "Processing Subject: 2, Epoch: 32\n",
      "Processing Subject: 2, Epoch: 33\n",
      "Processing Subject: 2, Epoch: 34\n",
      "Processing Subject: 2, Epoch: 35\n",
      "Processing Subject: 2, Epoch: 36\n",
      "Processing Subject: 2, Epoch: 37\n",
      "Processing Subject: 2, Epoch: 38\n",
      "Processing Subject: 2, Epoch: 39\n",
      "Processing Subject: 2, Epoch: 40\n",
      "Processing Subject: 2, Epoch: 41\n",
      "Processing Subject: 2, Epoch: 42\n",
      "Processing Subject: 2, Epoch: 43\n",
      "Processing Subject: 2, Epoch: 44\n",
      "Processing Subject: 2, Epoch: 45\n",
      "Processing Subject: 2, Epoch: 46\n",
      "Processing Subject: 2, Epoch: 47\n",
      "Processing Subject: 2, Epoch: 48\n",
      "Processing Subject: 2, Epoch: 49\n",
      "Processing Subject: 2, Epoch: 50\n",
      "Processing Subject: 3, Epoch: 1\n",
      "Processing Subject: 3, Epoch: 2\n",
      "Processing Subject: 3, Epoch: 3\n",
      "Processing Subject: 3, Epoch: 4\n",
      "Processing Subject: 3, Epoch: 5\n",
      "Processing Subject: 3, Epoch: 6\n",
      "Processing Subject: 3, Epoch: 7\n",
      "Processing Subject: 3, Epoch: 8\n",
      "Processing Subject: 3, Epoch: 9\n",
      "Processing Subject: 3, Epoch: 10\n",
      "Processing Subject: 3, Epoch: 11\n",
      "Processing Subject: 3, Epoch: 12\n",
      "Processing Subject: 3, Epoch: 13\n",
      "Processing Subject: 3, Epoch: 14\n",
      "Processing Subject: 3, Epoch: 15\n",
      "Processing Subject: 3, Epoch: 16\n",
      "Processing Subject: 3, Epoch: 17\n",
      "Processing Subject: 3, Epoch: 18\n",
      "Processing Subject: 3, Epoch: 19\n",
      "Processing Subject: 3, Epoch: 20\n",
      "Processing Subject: 3, Epoch: 21\n",
      "Processing Subject: 3, Epoch: 22\n",
      "Processing Subject: 3, Epoch: 23\n",
      "Processing Subject: 3, Epoch: 24\n",
      "Processing Subject: 3, Epoch: 25\n",
      "Processing Subject: 3, Epoch: 26\n",
      "Processing Subject: 3, Epoch: 27\n",
      "Processing Subject: 3, Epoch: 28\n",
      "Processing Subject: 3, Epoch: 29\n",
      "Processing Subject: 3, Epoch: 30\n",
      "Processing Subject: 3, Epoch: 31\n",
      "Processing Subject: 3, Epoch: 32\n",
      "Processing Subject: 3, Epoch: 33\n",
      "Processing Subject: 3, Epoch: 34\n",
      "Processing Subject: 3, Epoch: 35\n",
      "Processing Subject: 3, Epoch: 36\n",
      "Processing Subject: 3, Epoch: 37\n",
      "Processing Subject: 3, Epoch: 38\n",
      "Processing Subject: 3, Epoch: 39\n",
      "Processing Subject: 3, Epoch: 40\n",
      "Processing Subject: 3, Epoch: 41\n",
      "Processing Subject: 3, Epoch: 42\n",
      "Processing Subject: 3, Epoch: 43\n",
      "Processing Subject: 3, Epoch: 44\n",
      "Processing Subject: 3, Epoch: 45\n",
      "Processing Subject: 3, Epoch: 46\n",
      "Processing Subject: 3, Epoch: 47\n",
      "Processing Subject: 3, Epoch: 48\n",
      "Processing Subject: 3, Epoch: 49\n",
      "Processing Subject: 3, Epoch: 50\n",
      "Processing Subject: 4, Epoch: 1\n",
      "Processing Subject: 4, Epoch: 2\n",
      "Processing Subject: 4, Epoch: 3\n",
      "Processing Subject: 4, Epoch: 4\n",
      "Processing Subject: 4, Epoch: 5\n",
      "Processing Subject: 4, Epoch: 6\n",
      "Processing Subject: 4, Epoch: 7\n",
      "Processing Subject: 4, Epoch: 8\n",
      "Processing Subject: 4, Epoch: 9\n",
      "Processing Subject: 4, Epoch: 10\n",
      "Processing Subject: 4, Epoch: 11\n",
      "Processing Subject: 4, Epoch: 12\n",
      "Processing Subject: 4, Epoch: 13\n",
      "Processing Subject: 4, Epoch: 14\n",
      "Processing Subject: 4, Epoch: 15\n",
      "Processing Subject: 4, Epoch: 16\n",
      "Processing Subject: 4, Epoch: 17\n",
      "Processing Subject: 4, Epoch: 18\n",
      "Processing Subject: 4, Epoch: 19\n",
      "Processing Subject: 4, Epoch: 20\n",
      "Processing Subject: 4, Epoch: 21\n",
      "Processing Subject: 4, Epoch: 22\n",
      "Processing Subject: 4, Epoch: 23\n",
      "Processing Subject: 4, Epoch: 24\n",
      "Processing Subject: 4, Epoch: 25\n",
      "Processing Subject: 4, Epoch: 26\n",
      "Processing Subject: 4, Epoch: 27\n",
      "Processing Subject: 4, Epoch: 28\n",
      "Processing Subject: 4, Epoch: 29\n",
      "Processing Subject: 4, Epoch: 30\n",
      "Processing Subject: 4, Epoch: 31\n",
      "Processing Subject: 4, Epoch: 32\n",
      "Processing Subject: 4, Epoch: 33\n",
      "Processing Subject: 4, Epoch: 34\n",
      "Processing Subject: 4, Epoch: 35\n",
      "Processing Subject: 4, Epoch: 36\n",
      "Processing Subject: 4, Epoch: 37\n",
      "Processing Subject: 4, Epoch: 38\n",
      "Processing Subject: 4, Epoch: 39\n",
      "Processing Subject: 4, Epoch: 40\n",
      "Processing Subject: 4, Epoch: 41\n",
      "Processing Subject: 4, Epoch: 42\n",
      "Processing Subject: 4, Epoch: 43\n",
      "Processing Subject: 4, Epoch: 44\n",
      "Processing Subject: 4, Epoch: 45\n",
      "Processing Subject: 4, Epoch: 46\n",
      "Processing Subject: 4, Epoch: 47\n",
      "Processing Subject: 4, Epoch: 48\n",
      "Processing Subject: 4, Epoch: 49\n",
      "Processing Subject: 4, Epoch: 50\n",
      "Processing Subject: 5, Epoch: 1\n",
      "Processing Subject: 5, Epoch: 2\n",
      "Processing Subject: 5, Epoch: 3\n",
      "Processing Subject: 5, Epoch: 4\n",
      "Processing Subject: 5, Epoch: 5\n",
      "Processing Subject: 5, Epoch: 6\n",
      "Processing Subject: 5, Epoch: 7\n",
      "Processing Subject: 5, Epoch: 8\n",
      "Processing Subject: 5, Epoch: 9\n",
      "Processing Subject: 5, Epoch: 10\n",
      "Processing Subject: 5, Epoch: 11\n",
      "Processing Subject: 5, Epoch: 12\n",
      "Processing Subject: 5, Epoch: 13\n",
      "Processing Subject: 5, Epoch: 14\n",
      "Processing Subject: 5, Epoch: 15\n",
      "Processing Subject: 5, Epoch: 16\n",
      "Processing Subject: 5, Epoch: 17\n",
      "Processing Subject: 5, Epoch: 18\n",
      "Processing Subject: 5, Epoch: 19\n",
      "Processing Subject: 5, Epoch: 20\n",
      "Processing Subject: 5, Epoch: 21\n",
      "Processing Subject: 5, Epoch: 22\n",
      "Processing Subject: 5, Epoch: 23\n",
      "Processing Subject: 5, Epoch: 24\n",
      "Processing Subject: 5, Epoch: 25\n",
      "Processing Subject: 5, Epoch: 26\n",
      "Processing Subject: 5, Epoch: 27\n",
      "Processing Subject: 5, Epoch: 28\n",
      "Processing Subject: 5, Epoch: 29\n",
      "Processing Subject: 5, Epoch: 30\n",
      "Processing Subject: 5, Epoch: 31\n",
      "Processing Subject: 5, Epoch: 32\n",
      "Processing Subject: 5, Epoch: 33\n",
      "Processing Subject: 5, Epoch: 34\n",
      "Processing Subject: 5, Epoch: 35\n",
      "Processing Subject: 5, Epoch: 36\n",
      "Processing Subject: 5, Epoch: 37\n",
      "Processing Subject: 5, Epoch: 38\n",
      "Processing Subject: 5, Epoch: 39\n",
      "Processing Subject: 5, Epoch: 40\n",
      "Processing Subject: 5, Epoch: 41\n",
      "Processing Subject: 5, Epoch: 42\n",
      "Processing Subject: 5, Epoch: 43\n",
      "Processing Subject: 5, Epoch: 44\n",
      "Processing Subject: 5, Epoch: 45\n",
      "Processing Subject: 5, Epoch: 46\n",
      "Processing Subject: 5, Epoch: 47\n",
      "Processing Subject: 5, Epoch: 48\n",
      "Processing Subject: 5, Epoch: 49\n",
      "Processing Subject: 5, Epoch: 50\n",
      "Processing Subject: 6, Epoch: 1\n",
      "Processing Subject: 6, Epoch: 2\n",
      "Processing Subject: 6, Epoch: 3\n",
      "Processing Subject: 6, Epoch: 4\n",
      "Processing Subject: 6, Epoch: 5\n",
      "Processing Subject: 6, Epoch: 6\n",
      "Processing Subject: 6, Epoch: 7\n",
      "Processing Subject: 6, Epoch: 8\n",
      "Processing Subject: 6, Epoch: 9\n",
      "Processing Subject: 6, Epoch: 10\n",
      "Processing Subject: 6, Epoch: 11\n",
      "Processing Subject: 6, Epoch: 12\n",
      "Processing Subject: 6, Epoch: 13\n",
      "Processing Subject: 6, Epoch: 14\n",
      "Processing Subject: 6, Epoch: 15\n",
      "Processing Subject: 6, Epoch: 16\n",
      "Processing Subject: 6, Epoch: 17\n",
      "Processing Subject: 6, Epoch: 18\n",
      "Processing Subject: 6, Epoch: 19\n",
      "Processing Subject: 6, Epoch: 20\n",
      "Processing Subject: 6, Epoch: 21\n",
      "Processing Subject: 6, Epoch: 22\n",
      "Processing Subject: 6, Epoch: 23\n",
      "Processing Subject: 6, Epoch: 24\n",
      "Processing Subject: 6, Epoch: 25\n",
      "Processing Subject: 6, Epoch: 26\n",
      "Processing Subject: 6, Epoch: 27\n",
      "Processing Subject: 6, Epoch: 28\n",
      "Processing Subject: 6, Epoch: 29\n",
      "Processing Subject: 6, Epoch: 30\n",
      "Processing Subject: 6, Epoch: 31\n",
      "Processing Subject: 6, Epoch: 32\n",
      "Processing Subject: 6, Epoch: 33\n",
      "Processing Subject: 6, Epoch: 34\n",
      "Processing Subject: 6, Epoch: 35\n",
      "Processing Subject: 6, Epoch: 36\n",
      "Processing Subject: 6, Epoch: 37\n",
      "Processing Subject: 6, Epoch: 38\n",
      "Processing Subject: 6, Epoch: 39\n",
      "Processing Subject: 6, Epoch: 40\n",
      "Processing Subject: 6, Epoch: 41\n",
      "Processing Subject: 6, Epoch: 42\n",
      "Processing Subject: 6, Epoch: 43\n",
      "Processing Subject: 6, Epoch: 44\n",
      "Processing Subject: 6, Epoch: 45\n",
      "Processing Subject: 6, Epoch: 46\n",
      "Processing Subject: 6, Epoch: 47\n",
      "Processing Subject: 6, Epoch: 48\n",
      "Processing Subject: 6, Epoch: 49\n",
      "Processing Subject: 6, Epoch: 50\n",
      "Processing Subject: 7, Epoch: 1\n",
      "Processing Subject: 7, Epoch: 2\n",
      "Processing Subject: 7, Epoch: 3\n",
      "Processing Subject: 7, Epoch: 4\n",
      "Processing Subject: 7, Epoch: 5\n",
      "Processing Subject: 7, Epoch: 6\n",
      "Processing Subject: 7, Epoch: 7\n",
      "Processing Subject: 7, Epoch: 8\n",
      "Processing Subject: 7, Epoch: 9\n",
      "Processing Subject: 7, Epoch: 10\n",
      "Processing Subject: 7, Epoch: 11\n",
      "Processing Subject: 7, Epoch: 12\n",
      "Processing Subject: 7, Epoch: 13\n",
      "Processing Subject: 7, Epoch: 14\n",
      "Processing Subject: 7, Epoch: 15\n",
      "Processing Subject: 7, Epoch: 16\n",
      "Processing Subject: 7, Epoch: 17\n",
      "Processing Subject: 7, Epoch: 18\n",
      "Processing Subject: 7, Epoch: 19\n",
      "Processing Subject: 7, Epoch: 20\n",
      "Processing Subject: 7, Epoch: 21\n",
      "Processing Subject: 7, Epoch: 22\n",
      "Processing Subject: 7, Epoch: 23\n",
      "Processing Subject: 7, Epoch: 24\n",
      "Processing Subject: 7, Epoch: 25\n",
      "Processing Subject: 7, Epoch: 26\n",
      "Processing Subject: 7, Epoch: 27\n",
      "Processing Subject: 7, Epoch: 28\n",
      "Processing Subject: 7, Epoch: 29\n",
      "Processing Subject: 7, Epoch: 30\n",
      "Processing Subject: 7, Epoch: 31\n",
      "Processing Subject: 7, Epoch: 32\n",
      "Processing Subject: 7, Epoch: 33\n",
      "Processing Subject: 7, Epoch: 34\n",
      "Processing Subject: 7, Epoch: 35\n",
      "Processing Subject: 7, Epoch: 36\n",
      "Processing Subject: 7, Epoch: 37\n",
      "Processing Subject: 7, Epoch: 38\n",
      "Processing Subject: 7, Epoch: 39\n",
      "Processing Subject: 7, Epoch: 40\n",
      "Processing Subject: 7, Epoch: 41\n",
      "Processing Subject: 7, Epoch: 42\n",
      "Processing Subject: 7, Epoch: 43\n",
      "Processing Subject: 7, Epoch: 44\n",
      "Processing Subject: 7, Epoch: 45\n",
      "Processing Subject: 7, Epoch: 46\n",
      "Processing Subject: 7, Epoch: 47\n",
      "Processing Subject: 7, Epoch: 48\n",
      "Processing Subject: 7, Epoch: 49\n",
      "Processing Subject: 7, Epoch: 50\n",
      "Processing Subject: 8, Epoch: 1\n",
      "Processing Subject: 8, Epoch: 2\n",
      "Processing Subject: 8, Epoch: 3\n",
      "Processing Subject: 8, Epoch: 4\n",
      "Processing Subject: 8, Epoch: 5\n",
      "Processing Subject: 8, Epoch: 6\n",
      "Processing Subject: 8, Epoch: 7\n",
      "Processing Subject: 8, Epoch: 8\n",
      "Processing Subject: 8, Epoch: 9\n",
      "Processing Subject: 8, Epoch: 10\n",
      "Processing Subject: 8, Epoch: 11\n",
      "Processing Subject: 8, Epoch: 12\n",
      "Processing Subject: 8, Epoch: 13\n",
      "Processing Subject: 8, Epoch: 14\n",
      "Processing Subject: 8, Epoch: 15\n",
      "Processing Subject: 8, Epoch: 16\n",
      "Processing Subject: 8, Epoch: 17\n",
      "Processing Subject: 8, Epoch: 18\n",
      "Processing Subject: 8, Epoch: 19\n",
      "Processing Subject: 8, Epoch: 20\n",
      "Processing Subject: 8, Epoch: 21\n",
      "Processing Subject: 8, Epoch: 22\n",
      "Processing Subject: 8, Epoch: 23\n",
      "Processing Subject: 8, Epoch: 24\n",
      "Processing Subject: 8, Epoch: 25\n",
      "Processing Subject: 8, Epoch: 26\n",
      "Processing Subject: 8, Epoch: 27\n",
      "Processing Subject: 8, Epoch: 28\n",
      "Processing Subject: 8, Epoch: 29\n",
      "Processing Subject: 8, Epoch: 30\n",
      "Processing Subject: 8, Epoch: 31\n",
      "Processing Subject: 8, Epoch: 32\n",
      "Processing Subject: 8, Epoch: 33\n",
      "Processing Subject: 8, Epoch: 34\n",
      "Processing Subject: 8, Epoch: 35\n",
      "Processing Subject: 8, Epoch: 36\n",
      "Processing Subject: 8, Epoch: 37\n",
      "Processing Subject: 8, Epoch: 38\n",
      "Processing Subject: 8, Epoch: 39\n",
      "Processing Subject: 8, Epoch: 40\n",
      "Processing Subject: 8, Epoch: 41\n",
      "Processing Subject: 8, Epoch: 42\n",
      "Processing Subject: 8, Epoch: 43\n",
      "Processing Subject: 8, Epoch: 44\n",
      "Processing Subject: 8, Epoch: 45\n",
      "Processing Subject: 8, Epoch: 46\n",
      "Processing Subject: 8, Epoch: 47\n",
      "Processing Subject: 8, Epoch: 48\n",
      "Processing Subject: 8, Epoch: 49\n",
      "Processing Subject: 8, Epoch: 50\n",
      "Processing Subject: 9, Epoch: 1\n",
      "Processing Subject: 9, Epoch: 2\n",
      "Processing Subject: 9, Epoch: 3\n",
      "Processing Subject: 9, Epoch: 4\n",
      "Processing Subject: 9, Epoch: 5\n",
      "Processing Subject: 9, Epoch: 6\n",
      "Processing Subject: 9, Epoch: 7\n",
      "Processing Subject: 9, Epoch: 8\n",
      "Processing Subject: 9, Epoch: 9\n",
      "Processing Subject: 9, Epoch: 10\n",
      "Processing Subject: 9, Epoch: 11\n",
      "Processing Subject: 9, Epoch: 12\n",
      "Processing Subject: 9, Epoch: 13\n",
      "Processing Subject: 9, Epoch: 14\n",
      "Processing Subject: 9, Epoch: 15\n",
      "Processing Subject: 9, Epoch: 16\n",
      "Processing Subject: 9, Epoch: 17\n",
      "Processing Subject: 9, Epoch: 18\n",
      "Processing Subject: 9, Epoch: 19\n",
      "Processing Subject: 9, Epoch: 20\n",
      "Processing Subject: 9, Epoch: 21\n",
      "Processing Subject: 9, Epoch: 22\n",
      "Processing Subject: 9, Epoch: 23\n",
      "Processing Subject: 9, Epoch: 24\n",
      "Processing Subject: 9, Epoch: 25\n",
      "Processing Subject: 9, Epoch: 26\n",
      "Processing Subject: 9, Epoch: 27\n",
      "Processing Subject: 9, Epoch: 28\n",
      "Processing Subject: 9, Epoch: 29\n",
      "Processing Subject: 9, Epoch: 30\n",
      "Processing Subject: 9, Epoch: 31\n",
      "Processing Subject: 9, Epoch: 32\n",
      "Processing Subject: 9, Epoch: 33\n",
      "Processing Subject: 9, Epoch: 34\n",
      "Processing Subject: 9, Epoch: 35\n",
      "Processing Subject: 9, Epoch: 36\n",
      "Processing Subject: 9, Epoch: 37\n",
      "Processing Subject: 9, Epoch: 38\n",
      "Processing Subject: 9, Epoch: 39\n",
      "Processing Subject: 9, Epoch: 40\n",
      "Processing Subject: 9, Epoch: 41\n",
      "Processing Subject: 9, Epoch: 42\n",
      "Processing Subject: 9, Epoch: 43\n",
      "Processing Subject: 9, Epoch: 44\n",
      "Processing Subject: 9, Epoch: 45\n",
      "Processing Subject: 9, Epoch: 46\n",
      "Processing Subject: 9, Epoch: 47\n",
      "Processing Subject: 9, Epoch: 48\n",
      "Processing Subject: 9, Epoch: 49\n",
      "Processing Subject: 9, Epoch: 50\n",
      "Processing Subject: 10, Epoch: 1\n",
      "Processing Subject: 10, Epoch: 2\n",
      "Processing Subject: 10, Epoch: 3\n",
      "Processing Subject: 10, Epoch: 4\n",
      "Processing Subject: 10, Epoch: 5\n",
      "Processing Subject: 10, Epoch: 6\n",
      "Processing Subject: 10, Epoch: 7\n",
      "Processing Subject: 10, Epoch: 8\n",
      "Processing Subject: 10, Epoch: 9\n",
      "Processing Subject: 10, Epoch: 10\n",
      "Processing Subject: 10, Epoch: 11\n",
      "Processing Subject: 10, Epoch: 12\n",
      "Processing Subject: 10, Epoch: 13\n",
      "Processing Subject: 10, Epoch: 14\n",
      "Processing Subject: 10, Epoch: 15\n",
      "Processing Subject: 10, Epoch: 16\n",
      "Processing Subject: 10, Epoch: 17\n",
      "Processing Subject: 10, Epoch: 18\n",
      "Processing Subject: 10, Epoch: 19\n",
      "Processing Subject: 10, Epoch: 20\n",
      "Processing Subject: 10, Epoch: 21\n",
      "Processing Subject: 10, Epoch: 22\n",
      "Processing Subject: 10, Epoch: 23\n",
      "Processing Subject: 10, Epoch: 24\n",
      "Processing Subject: 10, Epoch: 25\n",
      "Processing Subject: 10, Epoch: 26\n",
      "Processing Subject: 10, Epoch: 27\n",
      "Processing Subject: 10, Epoch: 28\n",
      "Processing Subject: 10, Epoch: 29\n",
      "Processing Subject: 10, Epoch: 30\n",
      "Processing Subject: 10, Epoch: 31\n",
      "Processing Subject: 10, Epoch: 32\n",
      "Processing Subject: 10, Epoch: 33\n",
      "Processing Subject: 10, Epoch: 34\n",
      "Processing Subject: 10, Epoch: 35\n",
      "Processing Subject: 10, Epoch: 36\n",
      "Processing Subject: 10, Epoch: 37\n",
      "Processing Subject: 10, Epoch: 38\n",
      "Processing Subject: 10, Epoch: 39\n",
      "Processing Subject: 10, Epoch: 40\n",
      "Processing Subject: 10, Epoch: 41\n",
      "Processing Subject: 10, Epoch: 42\n",
      "Processing Subject: 10, Epoch: 43\n",
      "Processing Subject: 10, Epoch: 44\n",
      "Processing Subject: 10, Epoch: 45\n",
      "Processing Subject: 10, Epoch: 46\n",
      "Processing Subject: 10, Epoch: 47\n",
      "Processing Subject: 10, Epoch: 48\n",
      "Processing Subject: 10, Epoch: 49\n",
      "Processing Subject: 10, Epoch: 50\n",
      "Processing Subject: 11, Epoch: 1\n",
      "Processing Subject: 11, Epoch: 2\n",
      "Processing Subject: 11, Epoch: 3\n",
      "Processing Subject: 11, Epoch: 4\n",
      "Processing Subject: 11, Epoch: 5\n",
      "Processing Subject: 11, Epoch: 6\n",
      "Processing Subject: 11, Epoch: 7\n",
      "Processing Subject: 11, Epoch: 8\n",
      "Processing Subject: 11, Epoch: 9\n",
      "Processing Subject: 11, Epoch: 10\n",
      "Processing Subject: 11, Epoch: 11\n",
      "Processing Subject: 11, Epoch: 12\n",
      "Processing Subject: 11, Epoch: 13\n",
      "Processing Subject: 11, Epoch: 14\n",
      "Processing Subject: 11, Epoch: 15\n",
      "Processing Subject: 11, Epoch: 16\n",
      "Processing Subject: 11, Epoch: 17\n",
      "Processing Subject: 11, Epoch: 18\n",
      "Processing Subject: 11, Epoch: 19\n",
      "Processing Subject: 11, Epoch: 20\n",
      "Processing Subject: 11, Epoch: 21\n",
      "Processing Subject: 11, Epoch: 22\n",
      "Processing Subject: 11, Epoch: 23\n",
      "Processing Subject: 11, Epoch: 24\n",
      "Processing Subject: 11, Epoch: 25\n",
      "Processing Subject: 11, Epoch: 26\n",
      "Processing Subject: 11, Epoch: 27\n",
      "Processing Subject: 11, Epoch: 28\n",
      "Processing Subject: 11, Epoch: 29\n",
      "Processing Subject: 11, Epoch: 30\n",
      "Processing Subject: 11, Epoch: 31\n",
      "Processing Subject: 11, Epoch: 32\n",
      "Processing Subject: 11, Epoch: 33\n",
      "Processing Subject: 11, Epoch: 34\n",
      "Processing Subject: 11, Epoch: 35\n",
      "Processing Subject: 11, Epoch: 36\n",
      "Processing Subject: 11, Epoch: 37\n",
      "Processing Subject: 11, Epoch: 38\n",
      "Processing Subject: 11, Epoch: 39\n",
      "Processing Subject: 11, Epoch: 40\n",
      "Processing Subject: 11, Epoch: 41\n",
      "Processing Subject: 11, Epoch: 42\n",
      "Processing Subject: 11, Epoch: 43\n",
      "Processing Subject: 11, Epoch: 44\n",
      "Processing Subject: 11, Epoch: 45\n",
      "Processing Subject: 11, Epoch: 46\n",
      "Processing Subject: 11, Epoch: 47\n",
      "Processing Subject: 11, Epoch: 48\n",
      "Processing Subject: 11, Epoch: 49\n",
      "Processing Subject: 11, Epoch: 50\n",
      "Processing Subject: 12, Epoch: 1\n",
      "Processing Subject: 12, Epoch: 2\n",
      "Processing Subject: 12, Epoch: 3\n",
      "Processing Subject: 12, Epoch: 4\n",
      "Processing Subject: 12, Epoch: 5\n",
      "Processing Subject: 12, Epoch: 6\n",
      "Processing Subject: 12, Epoch: 7\n",
      "Processing Subject: 12, Epoch: 8\n",
      "Processing Subject: 12, Epoch: 9\n",
      "Processing Subject: 12, Epoch: 10\n",
      "Processing Subject: 12, Epoch: 11\n",
      "Processing Subject: 12, Epoch: 12\n",
      "Processing Subject: 12, Epoch: 13\n",
      "Processing Subject: 12, Epoch: 14\n",
      "Processing Subject: 12, Epoch: 15\n",
      "Processing Subject: 12, Epoch: 16\n",
      "Processing Subject: 12, Epoch: 17\n",
      "Processing Subject: 12, Epoch: 18\n",
      "Processing Subject: 12, Epoch: 19\n",
      "Processing Subject: 12, Epoch: 20\n",
      "Processing Subject: 12, Epoch: 21\n",
      "Processing Subject: 12, Epoch: 22\n",
      "Processing Subject: 12, Epoch: 23\n",
      "Processing Subject: 12, Epoch: 24\n",
      "Processing Subject: 12, Epoch: 25\n",
      "Processing Subject: 12, Epoch: 26\n",
      "Processing Subject: 12, Epoch: 27\n",
      "Processing Subject: 12, Epoch: 28\n",
      "Processing Subject: 12, Epoch: 29\n",
      "Processing Subject: 12, Epoch: 30\n",
      "Processing Subject: 12, Epoch: 31\n",
      "Processing Subject: 12, Epoch: 32\n",
      "Processing Subject: 12, Epoch: 33\n",
      "Processing Subject: 12, Epoch: 34\n",
      "Processing Subject: 12, Epoch: 35\n",
      "Processing Subject: 12, Epoch: 36\n",
      "Processing Subject: 12, Epoch: 37\n",
      "Processing Subject: 12, Epoch: 38\n",
      "Processing Subject: 12, Epoch: 39\n",
      "Processing Subject: 12, Epoch: 40\n",
      "Processing Subject: 12, Epoch: 41\n",
      "Processing Subject: 12, Epoch: 42\n",
      "Processing Subject: 12, Epoch: 43\n",
      "Processing Subject: 12, Epoch: 44\n",
      "Processing Subject: 12, Epoch: 45\n",
      "Processing Subject: 12, Epoch: 46\n",
      "Processing Subject: 12, Epoch: 47\n",
      "Processing Subject: 12, Epoch: 48\n",
      "Processing Subject: 12, Epoch: 49\n",
      "Processing Subject: 12, Epoch: 50\n",
      "Processing Subject: 13, Epoch: 1\n",
      "Processing Subject: 13, Epoch: 2\n",
      "Processing Subject: 13, Epoch: 3\n",
      "Processing Subject: 13, Epoch: 4\n",
      "Processing Subject: 13, Epoch: 5\n",
      "Processing Subject: 13, Epoch: 6\n",
      "Processing Subject: 13, Epoch: 7\n",
      "Processing Subject: 13, Epoch: 8\n",
      "Processing Subject: 13, Epoch: 9\n",
      "Processing Subject: 13, Epoch: 10\n",
      "Processing Subject: 13, Epoch: 11\n",
      "Processing Subject: 13, Epoch: 12\n",
      "Processing Subject: 13, Epoch: 13\n",
      "Processing Subject: 13, Epoch: 14\n",
      "Processing Subject: 13, Epoch: 15\n",
      "Processing Subject: 13, Epoch: 16\n",
      "Processing Subject: 13, Epoch: 17\n",
      "Processing Subject: 13, Epoch: 18\n",
      "Processing Subject: 13, Epoch: 19\n",
      "Processing Subject: 13, Epoch: 20\n",
      "Processing Subject: 13, Epoch: 21\n",
      "Processing Subject: 13, Epoch: 22\n",
      "Processing Subject: 13, Epoch: 23\n",
      "Processing Subject: 13, Epoch: 24\n",
      "Processing Subject: 13, Epoch: 25\n",
      "Processing Subject: 13, Epoch: 26\n",
      "Processing Subject: 13, Epoch: 27\n",
      "Processing Subject: 13, Epoch: 28\n",
      "Processing Subject: 13, Epoch: 29\n",
      "Processing Subject: 13, Epoch: 30\n",
      "Processing Subject: 13, Epoch: 31\n",
      "Processing Subject: 13, Epoch: 32\n",
      "Processing Subject: 13, Epoch: 33\n",
      "Processing Subject: 13, Epoch: 34\n",
      "Processing Subject: 13, Epoch: 35\n",
      "Processing Subject: 13, Epoch: 36\n",
      "Processing Subject: 13, Epoch: 37\n",
      "Processing Subject: 13, Epoch: 38\n",
      "Processing Subject: 13, Epoch: 39\n",
      "Processing Subject: 13, Epoch: 40\n",
      "Processing Subject: 13, Epoch: 41\n",
      "Processing Subject: 13, Epoch: 42\n",
      "Processing Subject: 13, Epoch: 43\n",
      "Processing Subject: 13, Epoch: 44\n",
      "Processing Subject: 13, Epoch: 45\n",
      "Processing Subject: 13, Epoch: 46\n",
      "Processing Subject: 13, Epoch: 47\n",
      "Processing Subject: 13, Epoch: 48\n",
      "Processing Subject: 13, Epoch: 49\n",
      "Processing Subject: 13, Epoch: 50\n",
      "Processing Subject: 14, Epoch: 1\n",
      "Processing Subject: 14, Epoch: 2\n",
      "Processing Subject: 14, Epoch: 3\n",
      "Processing Subject: 14, Epoch: 4\n",
      "Processing Subject: 14, Epoch: 5\n",
      "Processing Subject: 14, Epoch: 6\n",
      "Processing Subject: 14, Epoch: 7\n",
      "Processing Subject: 14, Epoch: 8\n",
      "Processing Subject: 14, Epoch: 9\n",
      "Processing Subject: 14, Epoch: 10\n",
      "Processing Subject: 14, Epoch: 11\n",
      "Processing Subject: 14, Epoch: 12\n",
      "Processing Subject: 14, Epoch: 13\n",
      "Processing Subject: 14, Epoch: 14\n",
      "Processing Subject: 14, Epoch: 15\n",
      "Processing Subject: 14, Epoch: 16\n",
      "Processing Subject: 14, Epoch: 17\n",
      "Processing Subject: 14, Epoch: 18\n",
      "Processing Subject: 14, Epoch: 19\n",
      "Processing Subject: 14, Epoch: 20\n",
      "Processing Subject: 14, Epoch: 21\n",
      "Processing Subject: 14, Epoch: 22\n",
      "Processing Subject: 14, Epoch: 23\n",
      "Processing Subject: 14, Epoch: 24\n",
      "Processing Subject: 14, Epoch: 25\n",
      "Processing Subject: 14, Epoch: 26\n",
      "Processing Subject: 14, Epoch: 27\n",
      "Processing Subject: 14, Epoch: 28\n",
      "Processing Subject: 14, Epoch: 29\n",
      "Processing Subject: 14, Epoch: 30\n",
      "Processing Subject: 14, Epoch: 31\n",
      "Processing Subject: 14, Epoch: 32\n",
      "Processing Subject: 14, Epoch: 33\n",
      "Processing Subject: 14, Epoch: 34\n",
      "Processing Subject: 14, Epoch: 35\n",
      "Processing Subject: 14, Epoch: 36\n",
      "Processing Subject: 14, Epoch: 37\n",
      "Processing Subject: 14, Epoch: 38\n",
      "Processing Subject: 14, Epoch: 39\n",
      "Processing Subject: 14, Epoch: 40\n",
      "Processing Subject: 14, Epoch: 41\n",
      "Processing Subject: 14, Epoch: 42\n",
      "Processing Subject: 14, Epoch: 43\n",
      "Processing Subject: 14, Epoch: 44\n",
      "Processing Subject: 14, Epoch: 45\n",
      "Processing Subject: 14, Epoch: 46\n",
      "Processing Subject: 14, Epoch: 47\n",
      "Processing Subject: 14, Epoch: 48\n",
      "Processing Subject: 14, Epoch: 49\n",
      "Processing Subject: 14, Epoch: 50\n",
      "IMFs saved to imf_data.csv.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(\"healthy_data_tabular.csv\")  # Replace with your actual file path\n",
    "\n",
    "# Convert the Signal_Values to actual lists\n",
    "df['Signal_Values'] = df['Signal_Values'].apply(eval)\n",
    "\n",
    "# Define a placeholder MVMD function for demonstration (replace with your actual MVMD code)\n",
    "def mvmd(signal, K=3):\n",
    "    # Simulate some output for demonstration\n",
    "    batch_size, num_channels, num_samples = signal.shape\n",
    "    imfs = torch.randn(batch_size, K, num_channels, num_samples)  # Replace with actual MVMD output\n",
    "    return imfs, None, None\n",
    "\n",
    "# Initialize list to collect IMF data for CSV\n",
    "imf_data_list = []\n",
    "unique_subjects = df['Subject_ID'].unique()\n",
    "unique_epochs = df['Epoch'].unique()\n",
    "\n",
    "# Loop over each subject and each epoch\n",
    "for subject in unique_subjects:\n",
    "    for epoch in unique_epochs:\n",
    "        # Filter data for the specific subject and epoch\n",
    "        group_data = df[(df['Subject_ID'] == subject) & (df['Epoch'] == epoch)]\n",
    "\n",
    "        # Sort channels to ensure consistency\n",
    "        group_data = group_data.sort_values(by='Channel')\n",
    "\n",
    "        # Check if we have all 19 channels\n",
    "        if len(group_data) == 19:\n",
    "            # Stack signal values from all 19 channels into a tensor\n",
    "            signal = torch.stack([torch.tensor(row['Signal_Values']) for _, row in group_data.iterrows()])\n",
    "\n",
    "            # Add batch dimension to signal tensor\n",
    "            signal = signal.unsqueeze(0)  # shape becomes (1, 19, 500) where 19 is the channel count\n",
    "\n",
    "            # Check if the shape is correct\n",
    "            if signal.shape[2] == 500:\n",
    "                print(f\"Processing Subject: {subject}, Epoch: {epoch}\")\n",
    "\n",
    "                # Perform MVMD on the multi-channel signal\n",
    "                imfs, _, _ = mvmd(signal, K=3)\n",
    "\n",
    "                # Store each IMF for each channel in the list\n",
    "                for ch in range(imfs.shape[2]):  # Loop over each channel\n",
    "                    for k in range(imfs.shape[1]):  # Loop over each IMF\n",
    "                        imf_values = imfs[0, k, ch, :].tolist()  # Convert IMF tensor to a list\n",
    "                        imf_data_list.append({\n",
    "                            'Subject_ID': subject,\n",
    "                            'Epoch': epoch,\n",
    "                            'Channel': ch,\n",
    "                            'IMF_Number': k + 1,\n",
    "                            'IMF_Values': imf_values\n",
    "                        })\n",
    "\n",
    "# Convert list to DataFrame and save to CSV\n",
    "imf_df = pd.DataFrame(imf_data_list)\n",
    "# change below file name according to health and unhealthy file names\n",
    "imf_df.to_csv(\"imf_data_healthy.csv\", index=False)\n",
    "print(\"IMFs saved to imf_data.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QqMcTaXuWnZc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV data\n",
    "unhealthy_data = pd.read_csv(\"imf_data_healthy.csv\")\n",
    "# healthy_data = pd.read_csv(\"hProcessed_MVMD_IMFs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "s9VFXA0EW5up",
    "outputId": "dd12fc14-de33-40f2-8bc0-5c7fd1e0a8d1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"unhealthy_data\",\n  \"rows\": 39900,\n  \"fields\": [\n    {\n      \"column\": \"Subject_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 1,\n        \"max\": 14,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          10,\n          12,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 1,\n        \"max\": 50,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          14,\n          40,\n          31\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Channel\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 18,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          0,\n          5,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IMF_Number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IMF_Values\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39900,\n        \"samples\": [\n          \"[0.8886160254478455, 0.2636944353580475, -0.38264724612236023, 0.7581228613853455, 1.2764562368392944, 0.7047345638275146, 2.4547765254974365, 0.07840308547019958, -1.512605905532837, 0.948009729385376, -0.601512610912323, 0.0269950982183218, -1.0223833322525024, -1.052545189857483, -0.7429977655410767, -1.9561647176742554, 1.867814064025879, 1.814950942993164, -0.7351778149604797, -0.9188433885574341, -0.5970672369003296, 0.16076599061489105, -0.23048891127109528, 0.025404836982488632, -0.5006993412971497, 0.9965360164642334, 0.38696566224098206, -0.7135052680969238, 0.3812601566314697, 1.4968842267990112, 0.18067577481269836, 0.3266063630580902, -0.23532897233963013, -2.1626651287078857, 0.6246196627616882, 0.7737667560577393, -0.3342505991458893, 0.23318545520305634, -0.8574697375297546, -1.3964316844940186, -1.0674887895584106, 0.5855131149291992, 0.35964518785476685, 0.04445720091462135, 0.3161734938621521, 1.324012041091919, -0.5080947279930115, -0.2699281573295593, -0.17567233741283417, 0.21345438063144684, 0.7342850565910339, 0.5739686489105225, -0.5952497720718384, 2.179140567779541, -1.1379224061965942, 0.18858186900615692, -1.1421160697937012, -0.1850615292787552, -1.801709532737732, 1.1211761236190796, -0.7599246501922607, -0.9297579526901245, 0.9557139873504639, 0.49259626865386963, 1.843260407447815, 0.6204243302345276, 1.6926394701004028, -0.07238128781318665, -0.6565411686897278, 0.6572940945625305, 0.5550588369369507, 2.588470220565796, 1.3842520713806152, -1.1336315870285034, 0.16706439852714539, 1.8359419107437134, -0.504903256893158, -0.47625330090522766, 1.274035930633545, 0.10457172244787216, 0.11539523303508759, 0.4800649881362915, 0.9677603244781494, 0.08181007206439972, 0.2231065332889557, -0.5098386406898499, -0.5275770425796509, 1.0016459226608276, 0.9821021556854248, 0.19741864502429962, -1.1876369714736938, 0.7430890798568726, -0.6601611971855164, -1.5426628589630127, -0.7521434426307678, 0.9272422194480896, -0.6540314555168152, 0.30785056948661804, 0.10953396558761597, 1.2499128580093384, 0.18946000933647156, 1.057824730873108, 0.8362101316452026, 0.767898440361023, 0.23856419324874878, 1.7464120388031006, 1.0367321968078613, 0.012245450168848038, 0.4561309218406677, -2.720804214477539, 1.261556625366211, -0.22083155810832977, -1.739062786102295, 0.9444419741630554, -1.902890920639038, -0.7538804411888123, 0.7937657833099365, -0.301127165555954, -0.8120238780975342, 0.9349289536476135, -1.101749062538147, 0.8973928093910217, 0.16484056413173676, 1.0079059600830078, -0.6252591013908386, -2.1998045444488525, 1.5728710889816284, -0.11502008140087128, 1.4661234617233276, 0.5295996069908142, -1.1212049722671509, 1.818965196609497, 0.1310039609670639, -0.10951054096221924, 0.5777649283409119, -0.6135984659194946, 1.3616808652877808, -0.9930574297904968, -0.2980598509311676, -0.29901963472366333, -1.3957669734954834, -0.07795069366693497, -1.0000934600830078, 0.11049837619066238, -1.745328664779663, 1.6946169137954712, -0.0019929397385567427, -0.4955796003341675, 0.5179811716079712, -0.599632740020752, -0.8550381660461426, -0.24206820130348206, 0.32750755548477173, -2.204009532928467, 1.0853453874588013, -0.8552818894386292, 0.3955499827861786, 0.16855581104755402, -0.15177331864833832, 0.9280906915664673, 0.18094538152217865, -1.007025122642517, 0.27042582631111145, -0.420462965965271, 0.8604782819747925, -1.1543186902999878, -0.8862219452857971, 0.21502463519573212, 1.040459156036377, 0.6195396184921265, 0.8510948419570923, -0.3518400490283966, 0.7944098711013794, 0.17533858120441437, 1.710809350013733, 0.12343001365661621, 1.6604706048965454, 1.7458748817443848, -2.1462926864624023, 0.09433448314666748, 1.71823251247406, 0.3524901866912842, -0.08825688809156418, -1.3333600759506226, -1.3175569772720337, -1.1271722316741943, 0.8784689903259277, 0.4901535212993622, -0.7590636014938354, -0.6112950444221497, 0.4785129129886627, -0.8931884765625, -1.5418227910995483, 0.664964497089386, -0.07647182047367096, -0.0648375153541565, 0.6234861016273499, 0.9530636072158813, 2.1537766456604004, 0.33980593085289, 0.2795979678630829, -0.03732060268521309, -0.8657840490341187, 0.8408179879188538, 0.9277291893959045, -0.23206129670143127, 2.421567916870117, -1.0133403539657593, 0.7665693759918213, -1.8879660367965698, -0.1325167417526245, -1.3110032081604004, -0.7123495936393738, -0.24330992996692657, -0.03678286075592041, 0.09160362184047699, -1.5213782787322998, 1.4595025777816772, -0.14188885688781738, -0.5860571265220642, -1.0290969610214233, 0.7708555459976196, 0.3900318741798401, 1.2051764726638794, 1.3597744703292847, 0.7845120429992676, -1.1669611930847168, 0.28605586290359497, -0.948682427406311, 0.24415984749794006, 1.3416390419006348, -0.4334864616394043, -0.04320426285266876, 1.2305724620819092, -0.9390000104904175, -0.13763576745986938, -1.3306657075881958, 0.07624324411153793, -1.3174412250518799, 0.26027005910873413, -0.8704028129577637, 0.13419067859649658, 1.843854308128357, 0.2691882848739624, 2.1634953022003174, -0.3271615207195282, -0.6890878677368164, 0.9268664717674255, -0.5801020264625549, 0.5436273217201233, -0.3383103311061859, 1.1864066123962402, -0.6411362290382385, -2.092120409011841, -1.6266144514083862, -0.5390368700027466, -0.23845387995243073, -2.629163980484009, 0.9103076457977295, -1.0145187377929688, 0.49147123098373413, 1.1885268688201904, -0.02144329436123371, 1.6962597370147705, -0.6532213687896729, -1.0586379766464233, -0.7709935903549194, 1.5625414848327637, -2.0388357639312744, -0.47454550862312317, 2.4106783866882324, -1.420859932899475, 1.4596883058547974, -1.7452870607376099, -2.548067569732666, 0.3709467947483063, 1.497859001159668, -1.067502498626709, -0.1351694017648697, 0.9044316411018372, -1.3454833030700684, -1.3134452104568481, -0.3795386552810669, 0.5081079602241516, -0.2821369767189026, -0.2983378469944, 0.7277198433876038, 0.34871914982795715, 1.1551861763000488, 3.1369900703430176, 1.3663640022277832, -0.5866401791572571, -0.9996318817138672, -0.4645492136478424, -1.6299152374267578, 0.4585326015949249, -0.7221261262893677, 0.10420297086238861, 0.048524122685194016, -0.5073193907737732, -0.6411806344985962, -0.03773476555943489, -0.6476694345474243, 0.48556774854660034, -1.0787445306777954, -0.059660568833351135, 0.79437255859375, 0.5728983879089355, -0.9351028800010681, -0.9443433880805969, -0.060805514454841614, -0.17235636711120605, 0.6570075750350952, 1.2084617614746094, 0.09419643133878708, 1.559159278869629, 0.1212671622633934, -0.33435162901878357, 1.1102474927902222, 0.29309454560279846, 1.2135249376296997, -1.341495394706726, 1.4408155679702759, -0.21630729734897614, 0.6897395849227905, -1.2965444326400757, -0.8952553868293762, -0.8172335028648376, -2.005254030227661, -0.8074129223823547, -1.043940544128418, 2.4833269119262695, 0.06029666215181351, -2.0347671508789062, -0.3777926564216614, 0.49495014548301697, -0.6905969977378845, -0.39332741498947144, -0.2566086947917938, -0.5238577127456665, -0.3440001904964447, 0.32843783497810364, -1.4504852294921875, 0.4121485650539398, -1.7140121459960938, -0.32345080375671387, -0.25446847081184387, 0.5386413335800171, -0.16755196452140808, 0.0907687172293663, 1.3836307525634766, 0.24823889136314392, -1.8713122606277466, 0.5466507077217102, -0.995884358882904, -0.27606070041656494, -0.522922158241272, 0.7040054202079773, -0.2933462858200073, -0.961193859577179, -0.3022444248199463, -0.12558691203594208, -2.2171685695648193, 0.6373457908630371, 2.277637481689453, 0.664614200592041, 1.3177552223205566, -0.437132328748703, -0.2516445219516754, 0.8942223191261292, 1.2646143436431885, 0.1595069169998169, -0.9286006689071655, 0.7743441462516785, -0.06157993525266647, 1.1533411741256714, -1.24838387966156, 0.42536550760269165, 0.8577962517738342, -0.09959147125482559, 1.4140939712524414, 1.0821913480758667, 0.2698533833026886, -1.3525322675704956, -0.24216635525226593, -0.9010485410690308, -1.0058482885360718, 0.9487212896347046, 0.5898460149765015, -0.7694295048713684, -1.6829577684402466, 1.388834834098816, -0.5660935640335083, -0.6539438366889954, -1.24642014503479, 0.6942775845527649, 0.6277493238449097, -1.058974027633667, 0.5026599168777466, -1.434900164604187, 0.9517359137535095, 1.7026759386062622, -0.4771358370780945, -0.41361579298973083, -1.1893789768218994, -0.9856192469596863, 1.9075093269348145, 0.6916545033454895, 1.7469358444213867, -0.13439947366714478, -1.1481225490570068, -0.6056459546089172, -1.5839015245437622, 0.05180608108639717, 0.13516660034656525, 0.5305288434028625, 0.7024494409561157, -0.9468411207199097, -1.024733543395996, 1.0033857822418213, 1.5974794626235962, 1.2609326839447021, -0.9781748056411743, -0.5548046231269836, 0.5266777873039246, -0.7467864751815796, -1.2819771766662598, 0.2155349850654602, 0.3539105951786041, -0.7571085095405579, 0.5217027068138123, 1.2163443565368652, 0.4904542863368988, 0.36765074729919434, -1.0439409017562866, -1.1481918096542358, -2.77085018157959, 0.2276792675256729, -0.39800891280174255, -0.9414200186729431, -0.14705534279346466, 1.2208831310272217, 0.6757001280784607, -0.0718751922249794, 0.2733115255832672, 2.116851806640625, -0.9600375294685364, 0.4716395437717438, -0.015886561945080757, 0.11500564962625504, -2.4153716564178467, 0.2801569700241089, -0.3090818226337433, 0.057343609631061554, -0.4878343343734741, -1.7182434797286987, -0.09533531963825226, -0.2027321755886078, -0.32530477643013, -2.220709800720215, 1.477250576019287, 0.3223477900028229, 0.31681162118911743, -0.5829758644104004, 1.1691592931747437, -2.059711456298828, 1.0475080013275146, 0.6790154576301575, -0.2455994188785553, -0.8506863117218018, -1.1027580499649048, -0.9025512933731079, 0.02634514309465885, 0.5809873342514038, -0.044304560869932175, -1.1686546802520752, -0.041596148163080215, 0.8350189924240112, 1.7752081155776978, 1.6923097372055054, -1.9096864461898804, -1.5458922386169434, 0.5779628157615662, 0.13388359546661377, 0.4207686185836792, 1.3159706592559814, 1.5274169445037842, 1.541616439819336, -1.6947212219238281, -0.16277939081192017, -1.9364430904388428, -1.2826606035232544, 0.040099237114191055, -0.0029526434373110533, 0.8825315237045288, -0.6724169850349426, 0.25742048025131226, 0.2797250747680664, -0.4100198447704315, -1.4182196855545044]\",\n          \"[-1.1063483953475952, -0.2440674602985382, 0.17710767686367035, 0.5884681344032288, -1.6920663118362427, 0.8947285413742065, -0.41118478775024414, -0.09440580010414124, -1.4225724935531616, -1.190784215927124, -0.2445088028907776, 0.685958206653595, 0.8832570314407349, -1.54590904712677, -0.918099045753479, -1.7804064750671387, 0.90288907289505, 0.5732313990592957, -0.8951202630996704, 0.35801148414611816, -0.7522681951522827, -1.2240467071533203, 0.6536881327629089, 1.591567873954773, -1.661421775817871, -0.02705473266541958, 0.7549992203712463, 0.4282788932323456, -1.1273480653762817, 0.8647480607032776, -0.02039567567408085, 1.2447357177734375, 1.0535472631454468, -0.2032948136329651, -1.2124731540679932, 0.20452848076820374, 0.1270245760679245, 1.2057464122772217, -1.0081807374954224, 0.11631282418966293, 1.33780837059021, 0.829595685005188, 0.6176953911781311, -0.9212389588356018, 0.7438402771949768, 1.6198451519012451, -0.6573320627212524, -0.5617563724517822, -0.5962791442871094, 1.1991050243377686, 0.11720824986696243, -1.1170523166656494, -0.3153446316719055, -0.30794528126716614, 0.9452362060546875, -1.3454478979110718, -0.8475682735443115, -1.1815922260284424, 1.120630145072937, -0.01798132061958313, -1.5514025688171387, 0.2007196843624115, 0.5057973265647888, 0.21523040533065796, 1.4419699907302856, 0.7473052144050598, 1.0394275188446045, -0.1895758956670761, -1.3684381246566772, -2.054140567779541, -0.22126340866088867, 2.3971447944641113, -0.33163997530937195, -0.2919565439224243, 0.4947177469730377, 0.6599196791648865, 1.1203689575195312, 1.1300616264343262, -1.1789551973342896, 0.7345404028892517, -0.5017947554588318, 0.5666323900222778, -0.8265843987464905, 1.9057509899139404, 0.42319729924201965, 0.2495936155319214, -0.5558409690856934, 1.0008412599563599, -0.19655804336071014, -1.7169606685638428, 1.2632472515106201, 1.3607218265533447, 0.4615754187107086, 0.4712095558643341, 1.9510687589645386, -0.09020361304283142, 0.16868488490581512, 2.193413496017456, -0.2144063115119934, 1.4051356315612793, -1.783327341079712, 1.5833181142807007, 0.0041006323881447315, 0.8650418519973755, 1.1927354335784912, -1.0842784643173218, 0.1119963526725769, -0.5042986273765564, -0.1425226926803589, 0.7637108564376831, 1.1858158111572266, -0.4129941463470459, -0.29120203852653503, -1.3906846046447754, -0.7224478125572205, 0.23055396974086761, 0.2492378205060959, 0.6121683120727539, 0.43574467301368713, -0.7738422751426697, -1.643286108970642, 0.01875333860516548, -0.10238704085350037, 0.40588170289993286, 1.605937123298645, -1.3159606456756592, -0.22112451493740082, -0.5369271636009216, 0.37960779666900635, 0.27126574516296387, -1.468796968460083, -0.8509002327919006, -0.9312772154808044, 1.497241497039795, -1.536387324333191, 0.5434917211532593, -0.0712161511182785, -0.308927446603775, -2.241987943649292, -0.4341356158256531, -2.142746686935425, -0.43574976921081543, -1.0067086219787598, 0.32766351103782654, 1.7731600999832153, -0.2048124372959137, -0.0009520058520138264, 2.0531671047210693, -0.21824005246162415, 0.6186782717704773, -0.5091458559036255, -1.9816105365753174, 0.09537061303853989, -1.127712368965149, -0.8628010749816895, 0.15051527321338654, 1.2205837965011597, 1.1116325855255127, 0.4620155394077301, 0.5669459104537964, -0.3735828101634979, 0.16998475790023804, 0.8208932280540466, 1.2222859859466553, -0.3858950436115265, -1.6646833419799805, 1.4689128398895264, 1.110129714012146, -1.8442941904067993, -0.6350507140159607, -1.2805269956588745, -1.0045658349990845, -0.5376892685890198, -1.379770278930664, -0.39744701981544495, -1.7665581703186035, -0.23773851990699768, 1.857935905456543, -2.20353364944458, -0.42700445652008057, 0.356324702501297, -1.3508681058883667, -0.39560794830322266, 1.0655096769332886, -0.12941044569015503, 0.8804051280021667, 1.6773338317871094, -1.2154240608215332, -2.6802926063537598, 0.05295640602707863, 0.5277191996574402, -0.43740859627723694, -0.4841163456439972, -0.15029829740524292, 0.12837257981300354, 0.5215478539466858, -0.08845575898885727, 2.090200662612915, -0.7621423602104187, 0.8083353042602539, -0.009839534759521484, -0.7510045170783997, 0.046330247074365616, 1.3687787055969238, -0.7231682538986206, 0.6681896448135376, 1.073632836341858, -0.24842225015163422, 0.8835967183113098, 1.414803147315979, 0.6934064626693726, 2.108733654022217, -0.5204486846923828, -0.47932490706443787, -2.117042303085327, -1.452447772026062, 0.02454153262078762, 0.27508842945098877, 0.07087615132331848, 0.86385178565979, 0.6278662085533142, -1.2003173828125, 0.08562646061182022, 0.16713985800743103, 1.1676040887832642, -0.22957824170589447, 0.8975925445556641, 0.41284385323524475, -0.20930631458759308, -0.0815160870552063, 1.582513689994812, 0.9225016832351685, 0.10973923653364182, 0.676779568195343, -1.3744862079620361, 0.44062042236328125, 1.6587623357772827, 1.0263876914978027, 1.254001259803772, -1.281435489654541, -0.037555769085884094, -1.7187767028808594, 0.9968693256378174, 0.49224212765693665, -1.6745319366455078, 1.1536152362823486, -0.969594419002533, -1.578237533569336, -0.027811475098133087, 0.10599781572818756, -0.4636293351650238, 0.19931434094905853, 0.11171100288629532, -0.1676163673400879, -0.7468445301055908, 0.3382992744445801, 0.030159469693899155, -0.4554441273212433, -0.10922838002443314, 0.9719472527503967, 0.5389123558998108, -0.4835454225540161, -0.950583279132843, -1.925570011138916, 2.0052127838134766, -1.189974069595337, 1.2789016962051392, 0.4911365509033203, -0.43220943212509155, 1.2820383310317993, 1.2372798919677734, 0.11459358781576157, -0.7444448471069336, -1.0373505353927612, -0.8883005380630493, 0.46101999282836914, -1.4207813739776611, 0.8278084993362427, 0.14626234769821167, -0.40080526471138, 0.18580058217048645, -0.5290127396583557, 1.3611162900924683, -0.6272441148757935, -0.8413102030754089, 1.3703676462173462, -1.4257006645202637, -0.8487222194671631, 1.3769629001617432, -0.7487716674804688, 0.07730574160814285, 1.7100363969802856, 0.08925178647041321, 0.36311179399490356, -1.8791288137435913, -0.6360334157943726, 1.7361977100372314, 0.24174150824546814, -0.5596397519111633, -0.16920708119869232, 0.6119153499603271, 1.888420581817627, 0.15094223618507385, 0.5187928676605225, -0.5335805416107178, 0.0675201267004013, 0.8509601354598999, -0.32812321186065674, 1.8729935884475708, -0.5504623055458069, -0.06191343814134598, -0.20690813660621643, -1.0318577289581299, 0.38531485199928284, -1.2925418615341187, -0.26348552107810974, -2.363952875137329, -1.1002057790756226, 0.07886340469121933, -0.24191726744174957, -1.4395991563796997, -0.30444493889808655, -1.5838119983673096, 0.7318395376205444, 1.0060842037200928, -0.635871171951294, 0.12857051193714142, -0.4287467300891876, -0.23712243139743805, -2.3506016731262207, 0.8628240823745728, -0.6106039881706238, -1.022383451461792, 0.8679198026657104, 0.5896819233894348, -1.5561927556991577, 0.5851472616195679, 0.41651514172554016, 0.3035554885864258, -1.0612835884094238, 0.23858830332756042, 0.2592920958995819, -0.494305819272995, -1.0756323337554932, 0.20675860345363617, 0.28605085611343384, 2.117565631866455, -0.22929756343364716, -0.24127618968486786, 0.021528346464037895, -0.8126671314239502, 0.4860146939754486, -1.2361176013946533, -0.43028879165649414, -2.122307538986206, 1.7558327913284302, -0.812673807144165, 0.8001169562339783, -1.2313264608383179, -0.11927447468042374, 1.5260639190673828, 0.19121496379375458, -1.0140010118484497, -0.5074501037597656, 1.8174687623977661, 0.35976627469062805, -0.8427321314811707, 0.162893146276474, -0.7810853719711304, -0.853422224521637, -1.0524590015411377, 1.2764277458190918, 0.22080101072788239, 0.9028757214546204, -1.6231939792633057, -0.5406610369682312, 0.29958122968673706, -0.14105023443698883, 1.2756510972976685, 1.6536211967468262, 0.5213768482208252, 1.8901227712631226, -1.732663869857788, -1.461833119392395, 0.9668638706207275, 1.4884735345840454, -1.640878438949585, 0.7037336826324463, 2.3092446327209473, -0.543921947479248, -2.156280517578125, -2.2716057300567627, -0.8670099973678589, -0.31340473890304565, 2.0312461853027344, -0.11290179193019867, -0.2861497402191162, -0.3734787702560425, 1.1457685232162476, 0.13768300414085388, -0.47686144709587097, 1.0139000415802002, -0.6830404996871948, -0.22386424243450165, 1.3095719814300537, -2.5599358081817627, 0.8078113794326782, 0.47966358065605164, -0.45291051268577576, 1.1900832653045654, -1.919866919517517, 0.36735206842422485, -2.5946850776672363, -0.6406434178352356, -0.3207066059112549, 0.7804116606712341, -0.5357316136360168, -0.36027204990386963, -0.09222566336393356, -0.4692504405975342, 0.05042003095149994, 0.8538644313812256, 1.5260390043258667, 1.0416593551635742, 2.855008363723755, 0.21817217767238617, 1.70516037940979, 0.15993250906467438, 1.4968349933624268, 0.21987837553024292, -0.42277997732162476, -2.1096692085266113, -0.4789474606513977, 0.035887211561203, 1.5699257850646973, -1.2560762166976929, 0.35150378942489624, -0.0461638979613781, -1.374008297920227, -0.4508325159549713, 1.3601319789886475, -0.12054156512022018, -0.364706426858902, 0.8308679461479187, 0.48180073499679565, -0.2039947360754013, -0.45065292716026306, 0.07758184522390366, 2.612736701965332, 0.10515741258859634, 0.7066106796264648, -1.6831775903701782, -1.0875542163848877, -0.5103896260261536, -0.05474289506673813, -1.257759690284729, -1.722240686416626, -0.5735042691230774, -0.2023407369852066, 0.27625173330307007, -0.40877407789230347, 0.4735877513885498, 0.026882512494921684, -1.1036920547485352, -2.0594964027404785, -0.17498742043972015, -1.3967134952545166, 0.21981434524059296, 0.5024740099906921, 0.6486111879348755, -1.9637420177459717, 0.24008630216121674, 0.5102252960205078, -0.23522073030471802, -0.8219215869903564, 0.07509249448776245, 1.918446660041809, -0.8627345561981201, 0.7390024662017822, -0.16159506142139435, -1.6668219566345215, 0.18449333310127258, -0.11431363970041275, -1.8069703578948975, -0.5961554646492004, -0.2191959023475647, 0.5579364895820618, 0.2791752517223358, 0.2575379014015198, 0.1678631454706192, 0.4271140992641449, 0.7549446225166321, 1.8135255575180054, 0.4750608503818512, -1.5752284526824951, -0.6273547410964966, -1.619468092918396, 0.8955029845237732, 1.8721896409988403, -0.3517681360244751]\",\n          \"[-1.9873310327529907, -0.7066653966903687, 0.6396536827087402, 1.6134153604507446, -0.2853960692882538, -1.283255934715271, -0.7990326881408691, 0.02159348875284195, -0.2574508786201477, -0.6775530576705933, 0.9087270498275757, 1.0291337966918945, 0.01871049962937832, 0.6559333801269531, 0.06509962677955627, 0.6936803460121155, -1.0242234468460083, 0.7995033264160156, 0.33117419481277466, -0.8387545943260193, -0.6724135875701904, 1.4633601903915405, 0.3584885001182556, 2.029362678527832, 0.3713758885860443, 0.651538610458374, 0.8310214281082153, 0.7198255062103271, 2.553861141204834, -0.4722072184085846, 0.7758439183235168, 0.5413640141487122, 0.11924969404935837, 1.446496605873108, -0.5778204798698425, 0.23553691804409027, -0.8580068945884705, -0.41722097992897034, -0.446219801902771, 0.33642351627349854, 0.16126735508441925, -0.026825211942195892, 0.3072311580181122, 0.22165870666503906, -0.5399855971336365, -0.4296513795852661, -0.5025879740715027, 0.12172401696443558, 1.908440113067627, 0.19331438839435577, -0.23147758841514587, -0.14047163724899292, 0.47529128193855286, -0.7908979654312134, -0.6658344864845276, 0.0843755230307579, -0.49423012137413025, -2.6582555770874023, -0.5093440413475037, -0.8981746435165405, -1.2240647077560425, -0.24530856311321259, -0.9139798283576965, -1.936553716659546, 0.8583916425704956, -0.7599979639053345, -0.7162052989006042, -0.033630430698394775, -1.0962433815002441, 1.9255317449569702, 0.1477639079093933, 1.1625396013259888, 0.7685458660125732, -0.8072431087493896, -1.4761077165603638, 2.7323412895202637, -0.8156678676605225, 0.3634885847568512, 1.9643460512161255, -0.14992639422416687, 1.739040732383728, 0.23444902896881104, 2.0301263332366943, -1.1268409490585327, 2.590259075164795, 0.17601120471954346, 0.7503436803817749, -0.6040956377983093, -2.671759605407715, -0.49193671345710754, -1.2844908237457275, 0.8782568573951721, -0.3691295087337494, 0.552582323551178, 1.3955566883087158, -0.2664933502674103, -0.26344478130340576, 0.5275130867958069, -0.052280113101005554, -0.12982794642448425, -0.39947518706321716, 0.2953355312347412, -0.007248407229781151, 0.32496505975723267, -0.6768558621406555, -1.1167731285095215, 0.45254194736480713, -1.9491939544677734, 0.29254233837127686, 0.8723453879356384, -0.4199688732624054, 0.014139330945909023, -1.9452701807022095, -0.6402355432510376, 0.7390187978744507, 0.198898583650589, 0.5773124694824219, -0.3093775510787964, -0.5002143383026123, -0.2327565848827362, 1.1401903629302979, -0.008122904226183891, 0.15585540235042572, 0.6906681656837463, -0.37283071875572205, 0.10241322964429855, 0.31658825278282166, 0.24964609742164612, -0.7306819558143616, -0.8437914252281189, 0.4445861279964447, 0.45402881503105164, 0.4969410002231598, 0.6635794043540955, 0.579866886138916, 0.16731536388397217, -1.5798306465148926, -0.39998823404312134, -0.46196427941322327, -1.860830545425415, -2.41513991355896, 0.18194684386253357, -0.8020592927932739, 0.43746551871299744, -1.9476202726364136, -2.3299214839935303, 0.6756390333175659, 1.2770789861679077, 0.19819113612174988, -0.08749155700206757, 0.3671475350856781, -0.9871340990066528, 0.47051623463630676, 0.6801581382751465, 0.1966182291507721, -0.1270943433046341, 1.0911463499069214, -0.10968416184186935, 0.8834254145622253, 0.8754390478134155, 2.378654718399048, 0.5296703577041626, 0.5738099217414856, -1.5660712718963623, -0.09835591912269592, -1.690657615661621, -1.0440574884414673, 0.28388962149620056, -0.1624108850955963, 1.1502721309661865, 0.2285814881324768, 0.033245619386434555, 0.014694525860249996, -1.0065284967422485, 0.24536456167697906, 0.6625534892082214, 1.3445323705673218, -0.07167280465364456, -0.6151102185249329, -1.900080680847168, -0.6100077629089355, 0.7346416711807251, -0.021968387067317963, -1.1836390495300293, 0.7672598361968994, 1.459257960319519, 0.1588711440563202, -0.8915475606918335, -0.05975652486085892, -1.033080816268921, -3.215186834335327, 0.13053551316261292, 0.3113917410373688, -0.5917400121688843, -0.2794727385044098, -0.0032892695162445307, 1.4878532886505127, -1.3663625717163086, 1.0463460683822632, -0.9780704379081726, -0.0712546780705452, 0.2548881471157074, 1.1779570579528809, 0.40879443287849426, 0.942300021648407, 0.5294682383537292, -0.6822826266288757, 0.9478211998939514, -0.48067134618759155, 0.11417551338672638, -0.5597906112670898, 0.4349224865436554, -0.4171302914619446, -0.7526851892471313, 0.1026962623000145, 1.828123688697815, 0.7410428524017334, 0.5644878149032593, 1.7244305610656738, -0.7846264839172363, -1.2709742784500122, 1.1039321422576904, 0.332734078168869, 0.656880795955658, 0.6163755655288696, 0.29895177483558655, -2.3804938793182373, -0.9347838759422302, -0.8587450385093689, -1.4844856262207031, 0.21162624657154083, 0.8059658408164978, -1.1972393989562988, 1.0480307340621948, -0.4790787994861603, -0.24383364617824554, 0.7851590514183044, -1.4551392793655396, 0.9100878238677979, 0.21281684935092926, 0.43413883447647095, 0.394423246383667, 2.289402723312378, -0.9919643402099609, 1.8763576745986938, 0.3878938555717468, 0.3436681926250458, 0.5371041297912598, 0.3794013559818268, 0.8201960921287537, -1.4545029401779175, 0.20860891044139862, -0.4303131401538849, -0.3811528980731964, -1.2637909650802612, -1.2816897630691528, -0.3832018971443176, -0.9470932483673096, 1.0570305585861206, 1.0527242422103882, 0.2653374671936035, -0.22129422426223755, -1.3927569389343262, 1.3629701137542725, 0.33743909001350403, -0.42012327909469604, 2.065418004989624, 0.15874247252941132, -0.42889538407325745, -1.7812868356704712, 1.5751805305480957, -2.686114549636841, 0.7808138132095337, -0.12478417903184891, -0.8061302304267883, 0.532101035118103, -1.0695405006408691, 1.4202587604522705, 1.2478560209274292, -0.11961520463228226, 1.4616626501083374, 1.2314033508300781, -0.46148860454559326, 0.6537120342254639, 0.29573678970336914, -1.130839467048645, -0.08967985212802887, -1.4603172540664673, 0.9377374649047852, -0.27924463152885437, -0.35726168751716614, 1.264103889465332, -1.2098764181137085, -1.8500739336013794, -0.4884781241416931, 0.0797727108001709, -0.40362218022346497, -0.6225501298904419, -0.2399933785200119, 0.3594323992729187, 1.8356306552886963, 0.667395830154419, -1.0119526386260986, -0.5632514953613281, 0.2730630338191986, 0.7638629078865051, 1.4389671087265015, 0.7217933535575867, 0.7596315145492554, -1.0729202032089233, -1.160733699798584, -0.5010961890220642, 1.9555933475494385, -1.5087846517562866, -1.5105879306793213, 0.741003155708313, 0.21094226837158203, 0.81938636302948, 0.14151790738105774, 0.46975216269493103, -0.4917043149471283, -0.4076990485191345, -1.352573275566101, -1.243435263633728, 0.3991902768611908, 0.586530327796936, 0.1553347259759903, -1.1056511402130127, 1.947556495666504, -0.020591305568814278, 0.06154812127351761, 0.20184177160263062, -0.623653769493103, -0.2531535029411316, 2.387702465057373, -0.3369722366333008, 0.22413207590579987, 0.4387187361717224, 0.8179721236228943, -0.21665479242801666, -0.5358759760856628, 0.9990747570991516, 0.5574100613594055, -0.278899610042572, 1.3119750022888184, -1.201375126838684, 0.13774336874485016, 1.4858721494674683, 0.5321453213691711, -1.780844807624817, -0.30484676361083984, -1.4240413904190063, -0.3487095832824707, -1.482175350189209, 1.3098111152648926, -0.36873215436935425, -0.3323449492454529, -0.07319584488868713, -2.378505229949951, -1.6801828145980835, -1.992066740989685, 0.4474088251590729, 0.08099985867738724, 0.7160826325416565, -0.5804730653762817, 1.1470645666122437, -1.514578104019165, -0.46390485763549805, 0.6271086931228638, -0.6694394946098328, 1.1351991891860962, 0.13530878722667694, 0.6663153171539307, 1.5768799781799316, -1.5804765224456787, 0.0012216471368446946, -1.3045523166656494, 1.6479488611221313, 0.9052802920341492, -0.7807937264442444, -0.09300921857357025, -0.22113680839538574, -0.26607978343963623, 0.8900676369667053, -1.4663851261138916, -0.41955068707466125, 1.5506843328475952, 0.05712868273258209, 2.3225722312927246, 0.3893055319786072, -0.11072269827127457, 1.2306747436523438, 1.466155767440796, -0.3180435001850128, -0.6140380501747131, -0.3410564064979553, 1.081331491470337, -0.990168035030365, -1.4501221179962158, -0.8968985676765442, 1.4384963512420654, 0.9260985851287842, -0.7271430492401123, -1.1905627250671387, 0.024354327470064163, 2.2372419834136963, -0.6248807311058044, 0.46962204575538635, -1.4309699535369873, 0.12380058318376541, -1.0547007322311401, -0.80293208360672, 1.8339025974273682, 0.28523769974708557, -1.5190244913101196, -0.9023064970970154, -1.2258872985839844, -1.3445014953613281, -1.33660888671875, -0.4685781002044678, -1.2461787462234497, 0.6058886647224426, 1.0890733003616333, -0.4712720811367035, 0.24813175201416016, 0.07799844443798065, 0.20013391971588135, 2.345320701599121, 0.6647048592567444, -0.7850891947746277, 0.07996826618909836, 0.7924996614456177, -3.0032896995544434, -1.1796934604644775, -1.5656070709228516, 0.5287393927574158, 0.6092286109924316, -0.7166703939437866, -1.1200954914093018, -0.645056962966919, -1.275882601737976, 0.4506368935108185, 0.5839889049530029, -0.24520725011825562, 0.7736631035804749, -0.12632468342781067, -0.823535144329071, -1.2673331499099731, -0.6133134365081787, 0.8723506927490234, 0.4472636878490448, 0.8133993148803711, -1.3395397663116455, -1.3730515241622925, 1.178209900856018, 1.488966464996338, 0.10627128183841705, -0.6817338466644287, -2.3366475105285645, 0.8934715390205383, 1.0042099952697754, -0.16693708300590515, 2.469393014907837, -1.4989715814590454, 0.46192288398742676, 1.3985774517059326, 1.3199043273925781, -1.1710284948349, 1.2574357986450195, -0.8390964865684509, -0.16763469576835632, -2.7099063396453857, -1.2913540601730347, 0.09080468118190765, -2.0094716548919678, 0.5096197724342346, -0.3670925796031952, -0.17054353654384613, -0.24425670504570007, -0.09085152298212051, 2.0784616470336914, 1.3141810894012451, 2.8708600997924805, -0.5136248469352722, -0.15764692425727844, -0.40235406160354614, -0.27355554699897766, 1.2086988687515259, -0.6634780764579773, 1.72956120967865, -0.24113909900188446, 1.709136962890625, 1.3061410188674927, -2.386237621307373, 0.5272323489189148, -0.4814735949039459, 0.37009546160697937, -0.6244276165962219, 1.2164109945297241, -1.856407880783081]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "unhealthy_data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-cd69a241-6ff9-4490-87cb-b5ca0e67fdf9\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject_ID</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Channel</th>\n",
       "      <th>IMF_Number</th>\n",
       "      <th>IMF_Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-1.1501975059509277, -0.35760951042175293, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.8239970207214355, -0.19944284856319427, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.9796571135520935, -0.3295162320137024, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.5299670696258545, 0.03610764071345329, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.829396665096283, 0.7601236701011658, -0.686...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39895</th>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.000277706392807886, -0.8788760900497437, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39896</th>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.895706295967102, 1.677400827407837, 0.7171...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39897</th>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.16693884134292603, -0.9829882979393005, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39898</th>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.19964121282100677, -0.36058586835861206, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39899</th>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.01533372513949871, 0.3259504437446594, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39900 rows × 5 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd69a241-6ff9-4490-87cb-b5ca0e67fdf9')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-cd69a241-6ff9-4490-87cb-b5ca0e67fdf9 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-cd69a241-6ff9-4490-87cb-b5ca0e67fdf9');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-76d1592b-bc03-432e-a3ad-69b0aaae1572\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-76d1592b-bc03-432e-a3ad-69b0aaae1572')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-76d1592b-bc03-432e-a3ad-69b0aaae1572 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_c85c405b-9a47-4ed8-8e95-f8f361399801\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('unhealthy_data')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_c85c405b-9a47-4ed8-8e95-f8f361399801 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('unhealthy_data');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "       Subject_ID  Epoch  Channel  IMF_Number  \\\n",
       "0               1      1        0           1   \n",
       "1               1      1        0           2   \n",
       "2               1      1        0           3   \n",
       "3               1      1        1           1   \n",
       "4               1      1        1           2   \n",
       "...           ...    ...      ...         ...   \n",
       "39895          14     50       17           2   \n",
       "39896          14     50       17           3   \n",
       "39897          14     50       18           1   \n",
       "39898          14     50       18           2   \n",
       "39899          14     50       18           3   \n",
       "\n",
       "                                              IMF_Values  \n",
       "0      [-1.1501975059509277, -0.35760951042175293, -0...  \n",
       "1      [-0.8239970207214355, -0.19944284856319427, -0...  \n",
       "2      [-0.9796571135520935, -0.3295162320137024, -0....  \n",
       "3      [-0.5299670696258545, 0.03610764071345329, 0.0...  \n",
       "4      [0.829396665096283, 0.7601236701011658, -0.686...  \n",
       "...                                                  ...  \n",
       "39895  [-0.000277706392807886, -0.8788760900497437, 1...  \n",
       "39896  [-0.895706295967102, 1.677400827407837, 0.7171...  \n",
       "39897  [0.16693884134292603, -0.9829882979393005, 0.1...  \n",
       "39898  [-0.19964121282100677, -0.36058586835861206, 1...  \n",
       "39899  [-0.01533372513949871, 0.3259504437446594, -0....  \n",
       "\n",
       "[39900 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unhealthy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NzjoADVHfvnP",
    "outputId": "c1b66b48-497c-46e1-b120-d3a842729b1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10,000 entries saved to 'First_10000_Entries.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"Processed_MVMD_IMFs.csv\"  # Update this path if necessary\n",
    "new_file_path = \"First_10000_Entries.csv\"\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Select the first 10,000 entries\n",
    "    first_10000_entries = data.head(10000)\n",
    "\n",
    "    # Save to a new CSV file\n",
    "    first_10000_entries.to_csv(new_file_path, index=False)\n",
    "    print(f\"First 10,000 entries saved to '{new_file_path}'.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"The file '{file_path}' was not found. Please check the file path and try again.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KhxptSJ3kqKz",
    "outputId": "69cda848-73f9-454d-87ef-f4b0f3b9b4f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting EMD-signal\n",
      "  Downloading EMD_signal-1.6.4-py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.10/dist-packages (from EMD-signal) (1.26.4)\n",
      "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.10/dist-packages (from EMD-signal) (1.13.1)\n",
      "Collecting pathos>=0.2.1 (from EMD-signal)\n",
      "  Downloading pathos-0.3.3-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from EMD-signal) (4.66.6)\n",
      "Collecting ppft>=1.7.6.9 (from pathos>=0.2.1->EMD-signal)\n",
      "  Downloading ppft-1.7.6.9-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting dill>=0.3.9 (from pathos>=0.2.1->EMD-signal)\n",
      "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pox>=0.3.5 (from pathos>=0.2.1->EMD-signal)\n",
      "  Downloading pox-0.3.5-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting multiprocess>=0.70.17 (from pathos>=0.2.1->EMD-signal)\n",
      "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
      "Downloading EMD_signal-1.6.4-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pathos-0.3.3-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.17-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pox-0.3.5-py3-none-any.whl (29 kB)\n",
      "Downloading ppft-1.7.6.9-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ppft, pox, dill, multiprocess, pathos, EMD-signal\n",
      "Successfully installed EMD-signal-1.6.4 dill-0.3.9 multiprocess-0.70.17 pathos-0.3.3 pox-0.3.5 ppft-1.7.6.9\n"
     ]
    }
   ],
   "source": [
    "!pip install EMD-signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w44f5EHwWXlG",
    "outputId": "585eb814-b251-4fcb-a887-bda4aeb03e9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy results saved to 'IMF_Entropy_Results.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"Processed_MVMD_IMFs.csv\")  # Replace with your file name\n",
    "\n",
    "# Define a function to calculate Shannon entropy\n",
    "def calculate_shannon_entropy(imf_values):\n",
    "    # Convert values to absolute values to avoid negative probabilities\n",
    "    imf_values = np.abs(imf_values)\n",
    "    # Normalize the IMF values to use as a probability distribution\n",
    "    probability_distribution = imf_values / np.sum(imf_values)\n",
    "    # Calculate Shannon entropy\n",
    "    return entropy(probability_distribution)\n",
    "\n",
    "# Prepare to store entropy results\n",
    "entropy_results = []\n",
    "\n",
    "# Group by Subject_ID, Epoch, and Channel and calculate entropy for IMF_1\n",
    "for (subject_id, epoch, channel), group_data in data.groupby(['Subject_ID', 'Epoch', 'Channel']):\n",
    "    # Calculate entropy for IMF_1\n",
    "    imf_entropy = calculate_shannon_entropy(group_data['IMF_1'].values)\n",
    "\n",
    "    # Store the results in a dictionary\n",
    "    entropy_results.append({\n",
    "        'Subject_ID': subject_id,\n",
    "        'Epoch': epoch,\n",
    "        'Channel': channel,\n",
    "        'IMF_1_Entropy': imf_entropy\n",
    "    })\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "entropy_df = pd.DataFrame(entropy_results)\n",
    "\n",
    "# Save to CSV if needed\n",
    "entropy_df.to_csv(\"IMF_Entropy_Results.csv\", index=False)\n",
    "print(\"Entropy results saved to 'IMF_Entropy_Results.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_w4HJqyQaCAv",
    "outputId": "6ac2a7e9-f0ec-46be-dd53-d2e0e65c176a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "F8\n",
      "Fp2\n",
      "T4\n",
      "Entropy results for all channels saved to 'IMF_Entropy_Results_All_Channels.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"Processed_MVMD_IMFs.csv\")  # Replace with your file name\n",
    "\n",
    "# Define a function to calculate Shannon entropy\n",
    "def calculate_shannon_entropy(imf_values):\n",
    "    imf_values = np.abs(imf_values)  # Avoid negative probabilities\n",
    "    probability_distribution = imf_values / np.sum(imf_values)\n",
    "    return entropy(probability_distribution)\n",
    "\n",
    "# Prepare to store entropy results for each channel\n",
    "entropy_results = []\n",
    "\n",
    "# Loop through each Subject, Epoch, and Channel group to compute entropy\n",
    "for (subject_id, epoch, channel), group_data in data.groupby(['Subject_ID', 'Epoch', 'Channel']):\n",
    "    print(channel)\n",
    "    imf_entropy = calculate_shannon_entropy(group_data['IMF_1'].values)\n",
    "\n",
    "    # Store results for each channel\n",
    "    entropy_results.append({\n",
    "        'Subject_ID': subject_id,\n",
    "        'Epoch': epoch,\n",
    "        'Channel': channel,\n",
    "        'IMF_1_Entropy': imf_entropy\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "entropy_df = pd.DataFrame(entropy_results)\n",
    "\n",
    "# Save entropy values for all channels to CSV\n",
    "entropy_df.to_csv(\"IMF_Entropy_Results_All_Channels.csv\", index=False)\n",
    "print(\"Entropy results for all channels saved to 'IMF_Entropy_Results_All_Channels.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jWlIYdpQ-uwR"
   },
   "outputs": [],
   "source": [
    "# features to be find\n",
    "# ---------------------------------\n",
    "# 1. shannon\n",
    "# 2. absolute\n",
    "# 3. approximate\n",
    "# 4. spectral\n",
    "# 5. sample\n",
    "# 6. svd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "tS9-P6lEmFGx",
    "outputId": "e0133d2e-a2a2-499d-adc4-78f816bd7075"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-1c98c8d0-1253-4d79-98f3-28f83eda2a58\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-1c98c8d0-1253-4d79-98f3-28f83eda2a58\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-67285ac52f0e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Prompts you to upload a file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()  # Prompts you to upload a file\n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "df = pd.read_csv(io.BytesIO(uploaded['un_imf_entropies_with_measures.csv']))\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "id": "uVXe4luApbns",
    "outputId": "125edcbc-60e6-4e9e-82b0-355b70b1f8c9"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'un_imf_entropies.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ee1a2c1affb3>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Reading the CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'un_imf_entropies.csv'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Replace 'your_file.csv' with your file's name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Displays the first 5 rows of the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'un_imf_entropies.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading the CSV file\n",
    "df = pd.read_csv('un_imf_entropies.csv')  # Replace 'your_file.csv' with your file's name\n",
    "print(df.head())  # Displays the first 5 rows of the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5TdSyvXPHAIZ",
    "outputId": "247bcc82-dd90-4e3e-930f-801492d165d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Subject_ID  Epoch  Channel  IMF_Number  Shannon_Entropy  \\\n",
      "0           1      1        0           1        64.447018   \n",
      "1           1      1        0           2        66.109106   \n",
      "2           1      1        0           3        73.466164   \n",
      "3           1      1        1           1        71.560436   \n",
      "4           1      1        1           2        65.538417   \n",
      "\n",
      "   Approximate_Entropy  Absolute_Entropy  Sample_Entropy  Spectral_Entropy  \\\n",
      "0             1.296682       -298.652953        1.414918          7.310699   \n",
      "1             1.380944       -313.000785        1.468334          7.399364   \n",
      "2             1.405421       -270.588803        1.497151          7.359589   \n",
      "3             1.360427       -302.098013        1.449004          7.339466   \n",
      "4             1.381318       -304.033035        1.481001          7.371134   \n",
      "\n",
      "   SVD_Entropy  \n",
      "0     1.584733  \n",
      "1     1.584860  \n",
      "2     1.584664  \n",
      "3     1.583511  \n",
      "4     1.584587  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('imf_entropies_with_measures.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3v8vjW-dIlJZ",
    "outputId": "a95bbd5e-c06b-4cd5-c350-601a7a98149b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    71.600200    1.328251    -262.765943   1.428459     7.303451    \\\n",
      "0    68.699080     1.363542  -305.286896     1.496620     7.346205   \n",
      "1    74.198253     1.340605  -329.116923     1.454319     7.354627   \n",
      "2    71.816201     1.342889  -244.083279     1.435167     7.306929   \n",
      "3    66.165703     1.313681  -315.992394     1.436436     7.332617   \n",
      "4    69.101628     1.331392  -314.182161     1.436849     7.465824   \n",
      "\n",
      "    1.584197    -1.000000    \n",
      "0     1.584959           -1  \n",
      "1     1.584863           -1  \n",
      "2     1.584731            1  \n",
      "3     1.584806            1  \n",
      "4     1.583212            1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79799 entries, 0 to 79798\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   71.60020034   79799 non-null  float64\n",
      " 1   1.328251248   79799 non-null  float64\n",
      " 2   -262.7659428  79799 non-null  float64\n",
      " 3   1.428459083   79799 non-null  float64\n",
      " 4   7.303450851   79799 non-null  float64\n",
      " 5   1.584196923   79799 non-null  float64\n",
      " 6   -1.0          79799 non-null  int64  \n",
      "dtypes: float64(6), int64(1)\n",
      "memory usage: 4.3 MB\n",
      "None\n",
      "Accuracy: 0.5057017543859649\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.50      0.63      0.56      7933\n",
      "           1       0.51      0.39      0.44      8027\n",
      "\n",
      "    accuracy                           0.51     15960\n",
      "   macro avg       0.51      0.51      0.50     15960\n",
      "weighted avg       0.51      0.51      0.50     15960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Load the Excel file\n",
    "file_path = 'entropy_data.xlsx'  # Replace with your file name\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Step 2: Explore the data\n",
    "print(df.head())  # Print first few rows\n",
    "print(df.info())  # Check for missing data and data types\n",
    "\n",
    "# Step 3: Prepare the data\n",
    "# Assuming the last column is the target variable (replace with the correct column names)\n",
    "X = df.iloc[:, :-1]  # Features (all columns except the last)\n",
    "y = df.iloc[:, -1]   # Target (last column)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Train the SVM model\n",
    "svm_model = SVC(kernel='linear')  # You can try other kernels like 'rbf', 'poly', etc.\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Make predictions\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uc7wHsFuPvbH",
    "outputId": "eadcefd1-4b41-48ac-d776-3acfef639a5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    71.600200    1.328251    -262.765943   1.428459     7.303451    \\\n",
      "0    68.699080     1.363542  -305.286896     1.496620     7.346205   \n",
      "1    74.198253     1.340605  -329.116923     1.454319     7.354627   \n",
      "2    71.816201     1.342889  -244.083279     1.435167     7.306929   \n",
      "3    66.165703     1.313681  -315.992394     1.436436     7.332617   \n",
      "4    69.101628     1.331392  -314.182161     1.436849     7.465824   \n",
      "\n",
      "    1.584197    -1.000000    \n",
      "0     1.584959           -1  \n",
      "1     1.584863           -1  \n",
      "2     1.584731            1  \n",
      "3     1.584806            1  \n",
      "4     1.583212            1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79799 entries, 0 to 79798\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   71.60020034   79799 non-null  float64\n",
      " 1   1.328251248   79799 non-null  float64\n",
      " 2   -262.7659428  79799 non-null  float64\n",
      " 3   1.428459083   79799 non-null  float64\n",
      " 4   7.303450851   79799 non-null  float64\n",
      " 5   1.584196923   79799 non-null  float64\n",
      " 6   -1.0          79799 non-null  int64  \n",
      "dtypes: float64(6), int64(1)\n",
      "memory usage: 4.3 MB\n",
      "None\n",
      "Accuracy: 0.5020676691729323\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.50      0.55      0.52      7893\n",
      "           1       0.51      0.46      0.48      8067\n",
      "\n",
      "    accuracy                           0.50     15960\n",
      "   macro avg       0.50      0.50      0.50     15960\n",
      "weighted avg       0.50      0.50      0.50     15960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Load the Excel file\n",
    "file_path = 'entropy_data.xlsx'  # Replace with your file name\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Step 2: Explore the data\n",
    "print(df.head())  # Print first few rows\n",
    "print(df.info())  # Check for missing data and data types\n",
    "\n",
    "# Step 3: Prepare the data\n",
    "# Assuming the last column is the target variable (replace with the correct column names)\n",
    "X = df.iloc[:, :-1]  # Features (all columns except the last)\n",
    "y = df.iloc[:, -1]   # Target (last column)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Step 4: Train the SVM model\n",
    "svm_model = SVC(kernel='linear')  # You can try other kernels like 'rbf', 'poly', etc.\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Make predictions\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "nwoUdUZuUGGR",
    "outputId": "f55e2d84-1bc0-4309-f541-0d2b8fc325c0"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-59126f42250e>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load the dataset (replace with your dataset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'entropy_data.xlsx'\u001b[0m  \u001b[0;31m# Replace with your file name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Prepare the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         data = io.parse(\n\u001b[0m\u001b[1;32m    509\u001b[0m             \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, sheet_name, header, names, index_col, usecols, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, date_format, thousands, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[1;32m   1614\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# doctest: +SKIP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1615\u001b[0m         \"\"\"\n\u001b[0;32m-> 1616\u001b[0;31m         return self._reader.parse(\n\u001b[0m\u001b[1;32m   1617\u001b[0m             \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1618\u001b[0m             \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0mfile_rows_needed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calc_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sheet_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msheet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_rows_needed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msheet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"close\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m                 \u001b[0;31m# pyxlsb opens two TemporaryFiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_openpyxl.py\u001b[0m in \u001b[0;36mget_sheet_data\u001b[0;34m(self, sheet, file_rows_needed)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mScalar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0mlast_row_with_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mrow_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0mconverted_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mconverted_row\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconverted_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openpyxl/worksheet/_read_only.py\u001b[0m in \u001b[0;36m_cells_by_row\u001b[0;34m(self, min_col, min_row, max_col, max_row, values_only)\u001b[0m\n\u001b[1;32m     83\u001b[0m                                      timedelta_formats=self.parent._timedelta_formats)\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmax_row\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_row\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openpyxl/worksheet/_reader.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# add a finaliser to close the source when this becomes possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0mtag_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtag_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdispatcher\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36miterator\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m   1256\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1258\u001b[0;31m                 \u001b[0mpullparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1259\u001b[0m             \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpullparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_and_return_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpullparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mSyntaxError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1711\u001b[0m         \u001b[0;34m\"\"\"Feed encoded data to parser.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1713\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1714\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raiseerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m../Modules/pyexpat.c\u001b[0m in \u001b[0;36mStartElement\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36m_start\u001b[0;34m(self, tag, attr_list)\u001b[0m\n\u001b[1;32m   1639\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_ns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1641\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1642\u001b[0m         \u001b[0;31m# Handler for expat's StartElementHandler. Since ordered_attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1643\u001b[0m         \u001b[0;31m# is set, the attributes are reported as a list of alternating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "# Load the dataset (replace with your dataset)\n",
    "file_path = 'entropy_data.xlsx'  # Replace with your file name\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Prepare the data\n",
    "X = df.iloc[:, :-1]  # Features (all columns except the last)\n",
    "y = df.iloc[:, -1]   # Target (last column)\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm_model = SVC(kernel='linear')  # You can choose other kernels like 'rbf', 'poly', etc.\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "scores = cross_val_score(svm_model, X, y, cv=10, scoring='accuracy')\n",
    "\n",
    "# Print results\n",
    "print(\"Cross-validation scores for each fold:\", scores)\n",
    "print(\"Mean Accuracy:\", scores.mean())\n",
    "print(\"Standard Deviation:\", scores.std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "y6wl4QNBxuZu",
    "outputId": "ff688016-9428-4eee-ef4c-713ecab8a25c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Best Cross-Validation Accuracy: 0.5074249541638278\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = 'entropy_data.xlsx'  # Replace with your file path\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Prepare the data\n",
    "X = df.iloc[:, :-1]  # Features (all columns except the last)\n",
    "y = df.iloc[:, -1]   # Target (last column)\n",
    "\n",
    "# Define the KNN model\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_neighbors': range(1, 21),  # Test k from 1 to 20\n",
    "    'weights': ['uniform', 'distance'],  # Uniform vs distance-based weights\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']  # Distance metrics\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=knn_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=10,  # 10-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    verbose=2,  # Show progress\n",
    "    n_jobs=-1   # Use all available CPU cores\n",
    ")\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "4wOyqrTL9eOT",
    "outputId": "1098e468-1db7-4da0-e48d-683dc62c41bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Value at Step 1 (Load Data): 47\n",
      "    71.600200    1.328251    -262.765943   1.428459     7.303451    \\\n",
      "0    68.699080     1.363542  -305.286896     1.496620     7.346205   \n",
      "1    74.198253     1.340605  -329.116923     1.454319     7.354627   \n",
      "2    71.816201     1.342889  -244.083279     1.435167     7.306929   \n",
      "3    66.165703     1.313681  -315.992394     1.436436     7.332617   \n",
      "4    69.101628     1.331392  -314.182161     1.436849     7.465824   \n",
      "\n",
      "    1.584197    -1.000000    \n",
      "0     1.584959           -1  \n",
      "1     1.584863           -1  \n",
      "2     1.584731            1  \n",
      "3     1.584806            1  \n",
      "4     1.583212            1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79799 entries, 0 to 79798\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   71.60020034   79799 non-null  float64\n",
      " 1   1.328251248   79799 non-null  float64\n",
      " 2   -262.7659428  79799 non-null  float64\n",
      " 3   1.428459083   79799 non-null  float64\n",
      " 4   7.303450851   79799 non-null  float64\n",
      " 5   1.584196923   79799 non-null  float64\n",
      " 6   -1.0          79799 non-null  int64  \n",
      "dtypes: float64(6), int64(1)\n",
      "memory usage: 4.3 MB\n",
      "None\n",
      "Random Value at Step 2 (Explore Data): 14\n",
      "Random Value at Step 3 (Data Preparation): 53\n",
      "Random Value at Step 4 (Train SVM): 30\n",
      "Random Value at Step 5 (Predictions): 26\n",
      "Accuracy: 0.5020676691729323\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.50      0.55      0.52      7893\n",
      "           1       0.51      0.46      0.48      8067\n",
      "\n",
      "    accuracy                           0.50     15960\n",
      "   macro avg       0.50      0.50      0.50     15960\n",
      "weighted avg       0.50      0.50      0.50     15960\n",
      "\n",
      "Random Value at Step 6 (Model Evaluation): 7\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import random  # For generating random values\n",
    "\n",
    "# Step 1: Load the Excel file\n",
    "file_path = 'entropy_data.xlsx'  # Replace with your file name\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Very the random value from 1 to 100 and print result each time\n",
    "random_value = random.randint(1, 100)  # Generate random integer between 1 and 100\n",
    "print(f\"Random Value at Step 1 (Load Data): {random_value}\")\n",
    "\n",
    "# Step 2: Explore the data\n",
    "print(df.head())  # Print first few rows\n",
    "print(df.info())  # Check for missing data and data types\n",
    "random_value = random.randint(1, 100)  # Generate a new random integer\n",
    "print(f\"Random Value at Step 2 (Explore Data): {random_value}\")\n",
    "\n",
    "# Step 3: Prepare the data\n",
    "# Assuming the last column is the target variable (replace with the correct column names)\n",
    "X = df.iloc[:, :-1]  # Features (all columns except the last)\n",
    "y = df.iloc[:, -1]   # Target (last column)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "random_value = random.randint(1, 100)  # Generate a new random integer\n",
    "print(f\"Random Value at Step 3 (Data Preparation): {random_value}\")\n",
    "\n",
    "# Step 4: Train the SVM model\n",
    "svm_model = SVC(kernel='linear')  # You can try other kernels like 'rbf', 'poly', etc.\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "random_value = random.randint(1, 100)  # Generate a new random integer\n",
    "print(f\"Random Value at Step 4 (Train SVM): {random_value}\")\n",
    "\n",
    "# Step 5: Make predictions\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "random_value = random.randint(1, 100)  # Generate a new random integer\n",
    "print(f\"Random Value at Step 5 (Predictions): {random_value}\")\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "random_value = random.randint(1, 100)  # Generate a new random integer\n",
    "print(f\"Random Value at Step 6 (Model Evaluation): {random_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MDshU9oODGAl",
    "outputId": "4c5c133f-1078-4019-8161-54fec2ee63d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Value at Step 1 (Load Data): 52\n",
      "    71.600200    1.328251    -262.765943   1.428459     7.303451    \\\n",
      "0    68.699080     1.363542  -305.286896     1.496620     7.346205   \n",
      "1    74.198253     1.340605  -329.116923     1.454319     7.354627   \n",
      "2    71.816201     1.342889  -244.083279     1.435167     7.306929   \n",
      "3    66.165703     1.313681  -315.992394     1.436436     7.332617   \n",
      "4    69.101628     1.331392  -314.182161     1.436849     7.465824   \n",
      "\n",
      "    1.584197    -1.000000    \n",
      "0     1.584959           -1  \n",
      "1     1.584863           -1  \n",
      "2     1.584731            1  \n",
      "3     1.584806            1  \n",
      "4     1.583212            1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79799 entries, 0 to 79798\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   71.60020034   79799 non-null  float64\n",
      " 1   1.328251248   79799 non-null  float64\n",
      " 2   -262.7659428  79799 non-null  float64\n",
      " 3   1.428459083   79799 non-null  float64\n",
      " 4   7.303450851   79799 non-null  float64\n",
      " 5   1.584196923   79799 non-null  float64\n",
      " 6   -1.0          79799 non-null  int64  \n",
      "dtypes: float64(6), int64(1)\n",
      "memory usage: 4.3 MB\n",
      "None\n",
      "Random Value at Step 2 (Explore Data): 74\n",
      "Random Value at Step 3 (Data Preparation): 9\n",
      "Random Value at Step 4 (Train SVM): 17\n",
      "Random Value at Step 5 (Predictions): 87\n",
      "Accuracy: 0.5020676691729323\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.50      0.55      0.52      7893\n",
      "           1       0.51      0.46      0.48      8067\n",
      "\n",
      "    accuracy                           0.50     15960\n",
      "   macro avg       0.50      0.50      0.50     15960\n",
      "weighted avg       0.50      0.50      0.50     15960\n",
      "\n",
      "Random Value at Step 6 (Model Evaluation): 98\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import random  # For generating random values\n",
    "\n",
    "# Step 1: Load the Excel file\n",
    "file_path = 'entropy_data.xlsx'  # Replace with your file name\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Very the random value from 1 to 100 and print result each time\n",
    "random_value = random.randint(1, 100)  # Generate random integer between 1 and 100\n",
    "print(f\"Random Value at Step 1 (Load Data): {random_value}\")\n",
    "\n",
    "# Step 2: Explore the data\n",
    "print(df.head())  # Print first few rows\n",
    "print(df.info())  # Check for missing data and data types\n",
    "random_value = random.randint(1, 100)  # Generate a new random integer\n",
    "print(f\"Random Value at Step 2 (Explore Data): {random_value}\")\n",
    "\n",
    "# Step 3: Prepare the data\n",
    "# Assuming the last column is the target variable (replace with the correct column names)\n",
    "X = df.iloc[:, :-1]  # Features (all columns except the last)\n",
    "y = df.iloc[:, -1]   # Target (last column)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "random_value = random.randint(1, 100)  # Generate a new random integer\n",
    "print(f\"Random Value at Step 3 (Data Preparation): {random_value}\")\n",
    "\n",
    "# Step 4: Train the SVM model\n",
    "svm_model = SVC(kernel='linear')  # You can try other kernels like 'rbf', 'poly', etc.\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "random_value = random.randint(1, 100)  # Generate a new random integer\n",
    "print(f\"Random Value at Step 4 (Train SVM): {random_value}\")\n",
    "\n",
    "# Step 5: Make predictions\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "random_value = random.randint(1, 100)  # Generate a new random integer\n",
    "print(f\"Random Value at Step 5 (Predictions): {random_value}\")\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "random_value = random.randint(1, 100)  # Generate a new random integer\n",
    "print(f\"Random Value at Step 6 (Model Evaluation): {random_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9cRmdpdPMpF",
    "outputId": "0d95c4e7-24ac-4707-d12b-bddac5963ff2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Value at Step 1 (Load Data): 35\n",
      "    71.600200    1.328251    -262.765943   1.428459     7.303451    \\\n",
      "0    68.699080     1.363542  -305.286896     1.496620     7.346205   \n",
      "1    74.198253     1.340605  -329.116923     1.454319     7.354627   \n",
      "2    71.816201     1.342889  -244.083279     1.435167     7.306929   \n",
      "3    66.165703     1.313681  -315.992394     1.436436     7.332617   \n",
      "4    69.101628     1.331392  -314.182161     1.436849     7.465824   \n",
      "\n",
      "    1.584197    -1.000000    \n",
      "0     1.584959           -1  \n",
      "1     1.584863           -1  \n",
      "2     1.584731            1  \n",
      "3     1.584806            1  \n",
      "4     1.583212            1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79799 entries, 0 to 79798\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   71.60020034   79799 non-null  float64\n",
      " 1   1.328251248   79799 non-null  float64\n",
      " 2   -262.7659428  79799 non-null  float64\n",
      " 3   1.428459083   79799 non-null  float64\n",
      " 4   7.303450851   79799 non-null  float64\n",
      " 5   1.584196923   79799 non-null  float64\n",
      " 6   -1.0          79799 non-null  int64  \n",
      "dtypes: float64(6), int64(1)\n",
      "memory usage: 4.3 MB\n",
      "None\n",
      "Random Value at Step 2 (Explore Data): 31\n",
      "Random Value at Step 3 (Data Preparation): 96\n",
      "Random Value at Step 4 (Train SVM): 66\n",
      "Random Value at Step 5 (Predictions): 36\n",
      "Accuracy: 0.5057017543859649\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.50      0.63      0.56      7933\n",
      "           1       0.51      0.39      0.44      8027\n",
      "\n",
      "    accuracy                           0.51     15960\n",
      "   macro avg       0.51      0.51      0.50     15960\n",
      "weighted avg       0.51      0.51      0.50     15960\n",
      "\n",
      "Random Value at Step 6 (Model Evaluation): 20\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import random  # For generating random values\n",
    "\n",
    "# Step 1: Load the Excel file\n",
    "file_path = 'entropy_data.xlsx'  # Replace with your file name\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Verify the random value from 1 to 100 and print result each time\n",
    "random_value = random.randint(1, 100)  # Generate random integer between 1 and 100\n",
    "print(f\"Random Value at Step 1 (Load Data): {random_value}\")\n",
    "\n",
    "# Step 2: Explore the data\n",
    "print(df.head())  # Print first few rows\n",
    "print(df.info())  # Check for missing data and data types\n",
    "random_value = random.randint(1, 100)  # Generate a new random integer\n",
    "print(f\"Random Value at Step 2 (Explore Data): {random_value}\")\n",
    "\n",
    "# Step 3: Prepare the data\n",
    "# Assuming the last column is the target variable (replace with the correct column names)\n",
    "X = df.iloc[:, :-1]  # Features (all columns except the last)\n",
    "y = df.iloc[:, -1]   # Target (last column)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "random_value = random.randint(1, 100)  # Generate a new random integer\n",
    "print(f\"Random Value at Step 3 (Data Preparation): {random_value}\")\n",
    "\n",
    "# Step 4: Train the SVM model\n",
    "svm_model = SVC(kernel='linear')  # You can change kernel to 'rbf', 'poly', etc.\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "random_value = random.randint(1, 100)  # Generate a new random integer\n",
    "print(f\"Random Value at Step 4 (Train SVM): {random_value}\")\n",
    "\n",
    "# Step 5: Make predictions\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "random_value = random.randint(1, 100)  # Generate a new random integer\n",
    "print(f\"Random Value at Step 5 (Predictions): {random_value}\")\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "random_value = random.randint(1, 100)  # Generate a new random integer\n",
    "print(f\"Random Value at Step 6 (Model Evaluation): {random_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UfIPC-5OQ9e"
   },
   "source": [
    "Direct approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "RY-h7sE9QAI6",
    "outputId": "0a956851-f64d-45e7-f716-d6d160f534bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyinform\n",
      "  Downloading pyinform-0.2.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyinform) (1.26.4)\n",
      "Downloading pyinform-0.2.0-py3-none-any.whl (131 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/131.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.2/131.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyinform\n",
      "Successfully installed pyinform-0.2.0\n",
      "Collecting antropy\n",
      "  Downloading antropy-0.1.6.tar.gz (17 kB)\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from antropy) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from antropy) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from antropy) (1.5.2)\n",
      "Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.10/dist-packages (from antropy) (0.60.0)\n",
      "Collecting stochastic (from antropy)\n",
      "  Downloading stochastic-0.7.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57->antropy) (0.43.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->antropy) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->antropy) (3.5.0)\n",
      "Downloading stochastic-0.7.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: antropy\n",
      "  Building wheel for antropy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for antropy: filename=antropy-0.1.6-py3-none-any.whl size=16877 sha256=bdb49c00b4b4d6273af60062a6f9c2b73a4729d5b89d00f14aae5989035f036e\n",
      "  Stored in directory: /root/.cache/pip/wheels/98/22/06/e91d7bb213c7133d5e2eb34258623e1e19928d5f05e1ee6812\n",
      "Successfully built antropy\n",
      "Installing collected packages: stochastic, antropy\n",
      "Successfully installed antropy-0.1.6 stochastic-0.7.0\n"
     ]
    }
   ],
   "source": [
    "# pip install numpy pandas pyinform\n",
    "!pip install --upgrade pyinform\n",
    "!pip install antropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "huuci9oAu72c",
    "outputId": "43910acf-6f3e-485a-c701-1e0bd803101e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/antropy/entropy.py:253: RuntimeWarning: invalid value encountered in divide\n",
      "  psd_norm = psd / psd.sum(axis=axis, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy calculations complete. Results saved to data_with_entropies.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from scipy.stats import entropy as shannon_entropy\n",
    "import antropy as ant\n",
    "\n",
    "# Function to calculate Shannon Entropy\n",
    "def calculate_shannon_entropy(signal):\n",
    "    counter = Counter(signal)  # Count occurrences of each value\n",
    "    total_count = len(signal)\n",
    "    probabilities = [count / total_count for count in counter.values()]\n",
    "    return -sum(p * np.log2(p) for p in probabilities if p > 0)\n",
    "\n",
    "# Function to calculate Approximate Entropy\n",
    "def calculate_approximate_entropy(signal, m=2, r=0.2):\n",
    "    return ant.app_entropy(signal, order=m, metric=\"chebyshev\")\n",
    "\n",
    "# Function to calculate Sample Entropy\n",
    "def calculate_sample_entropy(signal, m=2, r=0.2):\n",
    "    return ant.sample_entropy(signal, order=m, metric=\"chebyshev\")\n",
    "\n",
    "# Function to calculate Tsallis Entropy\n",
    "def calculate_tsallis_entropy(signal, q=2):\n",
    "    counter = Counter(signal)  # Count occurrences of each value\n",
    "    total_count = len(signal)\n",
    "    probabilities = np.array([count / total_count for count in counter.values()])\n",
    "    tsallis = (1 - np.sum(probabilities ** q)) / (q - 1) if q != 1 else calculate_shannon_entropy(signal)\n",
    "    return tsallis\n",
    "\n",
    "# Function to calculate Spectral Entropy\n",
    "def calculate_spectral_entropy(signal, sampling_frequency=1):\n",
    "    return ant.spectral_entropy(signal, sf=sampling_frequency, method=\"welch\", normalize=True)\n",
    "\n",
    "# Load CSV data\n",
    "input_file = 'healthy_data_tabular.csv'  # Replace with your actual file\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "# Ensure Signal_Values is parsed as a list of floats\n",
    "data['Signal_Values'] = data['Signal_Values'].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Initialize new columns\n",
    "data['Shannon_Entropy'] = data['Signal_Values'].apply(calculate_shannon_entropy)\n",
    "data['Approximate_Entropy'] = data['Signal_Values'].apply(calculate_approximate_entropy)\n",
    "data['Sample_Entropy'] = data['Signal_Values'].apply(calculate_sample_entropy)\n",
    "data['Tsallis_Entropy'] = data['Signal_Values'].apply(calculate_tsallis_entropy)\n",
    "data['Spectral_Entropy'] = data['Signal_Values'].apply(calculate_spectral_entropy)\n",
    "\n",
    "# Save updated data to a new CSV\n",
    "output_file = 'data_with_entropies.csv'\n",
    "data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Entropy calculations complete. Results saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 790
    },
    "id": "EENQwlS6Pmi4",
    "outputId": "0b30106d-b258-4449-9b44-972b6a2ff983"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"hdata\",\n  \"rows\": 13300,\n  \"fields\": [\n    {\n      \"column\": \"Subject_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 1,\n        \"max\": 14,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          10,\n          12,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Channel\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"Fp1\",\n          \"C4\",\n          \"F8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 1,\n        \"max\": 50,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          14,\n          40,\n          31\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Signal_Values\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13285,\n        \"samples\": [\n          \"[-1.832361598560419, -1.2207410657072433, -0.30331026642748005, 0.46121539963898933, 0.6141205328522832, -0.30331026642748005, -0.7620256660673617, -1.9852667317737127, -6.419515594959235, -7.489851527452292, -9.324713126011819, -9.477618259225112, -8.56018745994535, -7.948566927092174, -8.101472060305468, -5.043369396039591, -1.2207410657072433, 1.0728359324921648, 6.883230994597333, 8.41228232673027, 7.95356692709039, 5.048369396037806, 5.2012745292511, 4.742559129611218, 3.9780334635447487, 3.366412930691573, -1.526551332133831, -9.324713126011819, -17.734495452742983, -22.78036484878168, -25.53265724662097, -24.921036713767794, -25.53265724662097, -26.144277779474145, -26.144277779474145, -27.214613711967203, -24.156511047701326, -18.957736518449334, -13.911867122410635, -6.725325861385823, 0.7670256660655771, 5.507084795677687, 12.387815790275912, 14.68139278847532, 13.458151722768969, 11.317479857782855, 4.43674886318463, -0.7620256660673617, -5.043369396039591, -9.171807992798525, -11.159574724571346, -10.395049058504876, -10.242143925291582, -9.018902859585232, -8.101472060305468, -9.936333658864994, -11.465384990997933, -11.31247985778464, -9.324713126011819, -7.0311361278124105, -2.1381718649870067, 1.2257410657054588, 2.7547923978383975, 5.354179662464394, 6.730325861384038, 7.341946394237214, 8.71809259315686, 10.094238792076505, 9.176807992796741, 7.036136127810626, 6.883230994597333, 3.366412930691573, -0.9149307992806556, -2.1381718649870067, -7.0311361278124105, -10.242143925291582, -9.018902859585232, -14.064772255623929, -17.887400585956275, -19.416451918089216, -23.85070078127474, -23.239080248421562, -19.11064165166263, -13.606056855984047, -4.737559129613002, 1.8373615985586342, 8.71809259315686, 13.916867122408851, 18.656926252020963, 20.95050325022037, 21.71502891628684, 23.855700781272954, 19.574357051300723, 14.375582522048733, 9.635523392436623, 2.143171864985222, -3.973033463546533, -8.865997726371937, -10.700859324931464, -9.936333658864994, -5.80789506210606, -0.7620256660673617, 7.18904126102392, 9.635523392436623, 9.635523392436623, 9.788428525649916, 9.176807992796741, 11.317479857782855, 11.776195257422737, 14.528487655262026, 10.70585932492968, 4.43674886318463, 1.8373615985586342, -0.9149307992806556, 0.15540513321240157, 3.366412930691573, 4.895464262824512, 4.283843729971337, 1.6844564653453404, -1.832361598560419, -2.2910769982003005, -3.5143180639066514, -3.2085077974800638, -1.526551332133831, -2.7497923978401824, -0.1504051332141862, 2.9076975310516913, 8.106472060303684, 11.164574724569562, 12.6936260567025, 14.375582522048733, 11.623290124209444, 7.8006617938770955, 6.577420728170744, 2.9076975310516913, 0.15540513321240157, 0.0024999999991076978, -1.9852667317737127, -4.125938596759827, -7.79566179387888, -9.171807992798525, -9.630523392438407, -9.477618259225112, -5.654989928892766, -3.8201283303332394, -7.336946394238999, -9.7834285256517, -11.924100390637815, -12.994436323130872, -6.878230994599117, 0.15540513321240157, 5.2012745292511, 9.94133365886321, 12.540720923489205, 11.623290124209444, 9.023902859583446, 4.895464262824512, -1.0678359324939495, -7.489851527452292, -14.064772255623929, -18.04030571916957, -18.346115985596157, -16.81706465346322, -12.688626056704285, -5.9608001953193535, -1.526551332133831, 0.15540513321240157, 0.3083102664256955, -0.1504051332141862, -0.30331026642748005, -2.1381718649870067, -0.6091205328540679, -0.30331026642748005, -0.1504051332141862, 1.0728359324921648, 0.7670256660655771, 0.15540513321240157, -4.125938596759827, -10.242143925291582, -12.994436323130872, -15.440918454543574, -14.370582522050517, -11.006669591358051, -11.31247985778464, -10.853764458144758, -10.395049058504876, -9.7834285256517, -6.113705328532648, 0.0024999999991076978, 4.589653996397924, 9.329713126010034, 11.776195257422737, 13.611056855982262, 12.387815790275912, 6.730325861384038, 4.283843729971337, -2.2910769982003005, -7.489851527452292, -7.336946394238999, -7.0311361278124105, -6.113705328532648, -4.278843729973121, -3.5143180639066514, -3.973033463546533, -5.349179662466178, -5.80789506210606, -6.878230994599117, -7.336946394238999, -4.278843729973121, -2.1381718649870067, -0.1504051332141862, 2.44898213141181, 1.9902667317719283, 1.9902667317719283, 2.7547923978383975, 0.46121539963898933, 1.9902667317719283, -0.1504051332141862, -5.502084795679472, -7.489851527452292, -10.547954191718171, -9.630523392438407, -5.9608001953193535, -2.902697531053476, -0.45621539964077396, 0.6141205328522832, 1.0728359324921648, 1.6844564653453404, 3.519318063904867, 2.6018872646251037, 0.3083102664256955, -2.7497923978401824, -5.654989928892766, -8.713092593158644, -9.936333658864994, -10.547954191718171, -10.395049058504876, -7.948566927092174, -5.349179662466178, -0.9149307992806556, 2.7547923978383975, 5.507084795677687, 8.106472060303684, 10.247143925289798, 10.400049058503091, 10.552954191716385, 7.341946394237214, 4.43674886318463, 1.6844564653453404, -1.832361598560419, -3.6672231971199456, -6.725325861385823, -9.7834285256517, -10.853764458144758, -9.477618259225112, -9.7834285256517, -7.79566179387888, -4.584653996399709, -6.5724207281725295, -7.336946394238999, -6.878230994599117, -9.171807992798525, -10.853764458144758, -11.006669591358051, -9.018902859585232, -6.725325861385823, -3.5143180639066514, 0.3083102664256955, 4.43674886318463, 5.812895062104275, 9.176807992796741, 11.470384990996148, 10.552954191716385, 7.341946394237214, 3.6722231971181607, 2.6018872646251037, -0.9149307992806556, -0.1504051332141862, -0.30331026642748005, -1.832361598560419, 0.3083102664256955, 2.143171864985222, 4.742559129611218, 7.95356692709039, 11.164574724569562, 10.247143925289798, 10.70585932492968, 9.023902859583446, 8.106472060303684, 4.589653996397924, 0.15540513321240157, -3.8201283303332394, -13.147341456344167, -17.58159031952969, -20.02807245094239, -20.48678785058227, -19.875167317729098, -15.746728720970163, -10.853764458144758, -6.419515594959235, 0.15540513321240157, 6.271610461744157, 11.470384990996148, 15.140108188115201, 20.033072450940605, 19.115641651660845, 20.64469298379378, 20.797598117007077, 18.96273651844755, 16.822064653461435, 13.916867122408851, 12.846531189915794, 7.341946394237214, 5.2012745292511, 0.3083102664256955, -4.890464262826296, -7.642756660665587, -7.336946394238999, -5.502084795679472, -4.125938596759827, -2.2910769982003005, -2.596887264626888, -1.832361598560419, -1.2207410657072433, 1.6844564653453404, 3.519318063904867, 6.271610461744157, 7.18904126102392, 6.271610461744157, 5.965800195317569, 3.825128330331455, 3.0606026642649855, -0.1504051332141862, -2.1381718649870067, -2.1381718649870067, -3.05560266426677, -3.05560266426677, -0.45621539964077396, 1.6844564653453404, 2.9076975310516913, 7.8006617938770955, 11.623290124209444, 14.68139278847532, 13.305246589555676, 9.635523392436623, 3.519318063904867, -3.973033463546533, -8.713092593158644, -14.217677388837224, -16.511254387036633, -17.734495452742983, -16.205444120610043, -14.064772255623929, -9.171807992798525, -4.431748863186415, -2.2910769982003005, 0.919930799278871, 1.9902667317719283, 6.883230994597333, 9.329713126010034, 14.375582522048733, 18.19821085238108, 16.974969786674727, 13.916867122408851, 8.565187459943566, -0.6091205328540679, -10.089238792078289, -14.982203054903692, -22.78036484878168, -24.156511047701326, -26.29718291268744, -30.119811243019786, -27.52042397839379, -21.404218649862035, -14.064772255623929, -3.6672231971199456, 4.895464262824512, 8.71809259315686, 10.858764458142973, 9.023902859583446, 10.247143925289798, 8.41228232673027, 7.494851527450508, 8.259377193516977, 9.329713126010034, 11.011669591356267, 10.400049058503091, 8.870997726370152, 1.9902667317719283, -5.043369396039591, -13.30024658955746, -15.746728720970163, -16.205444120610043, -13.606056855984047, -8.56018745994535, -5.196274529252884, -2.902697531053476, -1.679456465347125, 1.0728359324921648, 3.519318063904867, 10.247143925289798, 13.916867122408851, 17.586590319527904, 19.115641651660845, 16.057538987394967, 15.293013321328496, 10.858764458142973, 8.259377193516977, 2.296076998198516, -2.902697531053476, -9.324713126011819, -14.370582522050517, -16.05253898739675, -13.30024658955746, -8.56018745994535, -5.043369396039591, 1.3786461989187526, 2.143171864985222, 3.825128330331455, 3.825128330331455, 3.0606026642649855, 6.271610461744157, 7.341946394237214, 10.858764458142973, 14.68139278847532, 15.44591845454179, 11.623290124209444, 9.023902859583446, 3.2135077974782793, 0.0024999999991076978, 0.3083102664256955, 1.5315513321320464, 5.507084795677687, 5.048369396037806, 4.589653996397924, 1.5315513321320464, 0.6141205328522832, 1.9902667317719283, 2.6018872646251037, 6.271610461744157, 7.8006617938770955, 4.589653996397924, 1.9902667317719283, 3.6722231971181607, 5.048369396037806, 11.92910039063603, 17.43368518631461, 19.115641651660845, 17.7394954527412, 13.458151722768969, 11.470384990996148, 10.094238792076505, 11.164574724569562, 10.858764458142973, 10.70585932492968, 8.41228232673027, 3.519318063904867, -0.45621539964077396, -2.7497923978401824, -3.3614129306933576, -4.584653996399709, -2.7497923978401824, -3.5143180639066514, -5.043369396039591, -7.184041261025705, -5.349179662466178, -1.526551332133831, 1.0728359324921648, 7.036136127810626, 9.023902859583446, 8.565187459943566, 6.577420728170744, 7.8006617938770955, 6.883230994597333, 6.118705328530863, 5.354179662464394, 3.0606026642649855, 3.0606026642649855, 2.143171864985222, 3.366412930691573, 3.366412930691573, 1.2257410657054588, -3.3614129306933576, -5.043369396039591, -8.56018745994535, -10.089238792078289, -7.489851527452292, -5.9608001953193535, -2.1381718649870067, -0.45621539964077396, 1.9902667317719283, 2.143171864985222, 1.5315513321320464, 1.9902667317719283, 1.0728359324921648, 0.0024999999991076978, -0.1504051332141862, -1.679456465347125, -5.502084795679472, -6.878230994599117]\",\n          \"[-0.760572899977589, 1.991718699930857, 2.7562441443498695, 3.97948485542029, 3.8265797665364873, 4.132389944304093, 10.860213855191406, 10.401498588539997, 8.413732433050564, 4.896915388723105, 3.97948485542029, 5.049820477606908, 5.967251010909723, 9.025352788585774, 8.413732433050564, 7.802112077515354, 3.36786449988508, -1.0663830777451941, 0.00395254444142372, -2.901244144350825, -6.876776455329691, -5.347725566491666, -3.81867467765364, -4.43029503318885, -6.112251010910678, -6.723871366445889, -5.347725566491666, -2.442528877699417, 0.6155728999766339, 0.7684779888604365, 1.227193255511844, 3.8265797665364873, 3.2149594110012774, -0.6076678110937865, 2.4504339665822648, -0.14895254444237882, 1.227193255511844, 7.037586633096341, 6.425966277561131, 10.095688410772393, 9.025352788585774, 7.9550171663991565, 2.7562441443498695, -0.3018576333261814, 2.603339055466067, 0.921383077744239, -1.2192881666289968, -3.81867467765364, -2.136718699931812, -2.136718699931812, -2.748339055467022, -4.583200122072653, -0.6076678110937865, 0.6155728999766339, -0.6076678110937865, 3.2149594110012774, 1.3800983443956467, 7.037586633096341, 7.343396810863946, 7.802112077515354, 8.872447699701972, 8.71954261081817, 12.38926474402943, 11.318929121842812, 11.77764438849422, 9.025352788585774, 5.508535744258316, 3.0620543221174747, 1.5330034332794493, -3.512864499886035, -5.347725566491666, -5.806440833143073, -8.10001716640011, -1.5250983443966017, -2.442528877699417, -1.5250983443966017, -0.9134779888613916, -5.806440833143073, -3.9715797665374426, -5.347725566491666, -7.029681544213494, -9.629068055238138, -9.017447699702927, -4.277389944305048, -2.748339055467022, -1.3721932555127994, -1.5250983443966017, -0.14895254444237882, 3.5207695887688826, 1.0742881666280415, -2.901244144350825, -0.9134779888613916, -1.5250983443966017, 1.0742881666280415, 1.5330034332794493, -2.748339055467022, -5.347725566491666, -8.711637521935321, -8.558732433051519, -12.381359655146584, -14.827841077287424, -13.4516952773332, -12.381359655146584, -11.769739299611373, -7.029681544213494, -9.934878233005742, -9.017447699702927, -2.748339055467022, -2.289623788815615, 5.814345922025921, 6.578871366444933, 8.260827344166762, 6.578871366444933, 3.2149594110012774, 7.037586633096341, 4.5911052109555, -0.6076678110937865, -4.277389944305048, -6.723871366445889, -7.947112077516309, -5.1948204776078635, -9.78197314412194, -8.10001716640011, -9.476162966354334, -13.604600366217003, -9.476162966354334, -11.158118944076163, -6.723871366445889, -7.029681544213494, -6.5709662775620865, -4.736105210956455, -5.653535744259271, -10.39359349965715, -10.087783321889544, -3.6657695887698374, -3.6657695887698374, -0.9134779888613916, -1.830908522164207, 0.7684779888604365, 0.4626678110928314, -1.3721932555127994, -2.442528877699417, -5.500630655375468, -7.641301899748704, -8.252922255283915, -1.6780034332804044, -6.265156099794481, -5.959345922026876, -7.7942069886325065, -8.10001716640011, -4.124484855421246, -5.04191538872406, -8.252922255283915, -13.910410543984609, -11.922644388495176, -11.158118944076163, -6.4180611886782835, -7.7942069886325065, -6.4180611886782835, -9.017447699702927, -9.017447699702927, -0.4547627222099839, -2.5954339665832196, -1.9838136110480096, -9.934878233005742, -8.252922255283915, -7.335491721981099, -9.323257877470532, -8.252922255283915, -8.864542610819125, -9.78197314412194, -17.733037766079672, -15.286556343938832, -16.35689196612545, -14.369125810636016, -10.852308766308557, -6.112251010910678, -3.9715797665374426, -6.4180611886782835, -3.512864499886035, -1.3721932555127994, 7.802112077515354, 8.413732433050564, 8.71954261081817, 5.967251010909723, 3.36786449988508, 5.355630655374513, 2.1446237888146595, 2.603339055466067, 0.4626678110928314, 0.30976272220902884, 2.297528877698462, 3.36786449988508, -1.3721932555127994, -4.583200122072653, -4.583200122072653, -5.500630655375468, -4.277389944305048, -3.0541492332346274, -0.6076678110937865, -0.760572899977589, 1.6859085221632517, 1.6859085221632517, -0.3018576333261814, 4.132389944304093, -0.6076678110937865, -2.442528877699417, 1.991718699930857, -1.5250983443966017, -3.9715797665374426, -8.252922255283915, -10.240688410773348, -9.017447699702927, -12.381359655146584, -11.61683421072757, -7.7942069886325065, -5.806440833143073, 2.297528877698462, 4.744010299839303, -1.6780034332804044, -3.512864499886035, -4.889010299840258, 0.30976272220902884, 4.896915388723105, 7.343396810863946, 11.930549477378023, 10.401498588539997, 9.331162966353379, 6.273061188677328, 2.297528877698462, 0.00395254444142372, -2.748339055467022, -4.889010299840258, -4.43029503318885, -7.182586633097296, -11.61683421072757, -11.61683421072757, -9.78197314412194, -3.6657695887698374, -3.512864499886035, 0.4626678110928314, 4.132389944304093, 7.802112077515354, 14.682841077286469, 12.083454566261825, 16.517702143892098, 16.976417410543508, 15.753176699473087, 16.364797055008296, 9.942783321888589, 5.967251010909723, 5.049820477606908, -0.6076678110937865, -5.653535744259271, -2.289623788815615, -4.124484855421246, -2.289623788815615, -0.4547627222099839, -0.6076678110937865, -2.442528877699417, -4.583200122072653, -2.136718699931812, -3.3599594110022326, -0.9134779888613916, 1.227193255511844, 3.2149594110012774, 2.297528877698462, 2.603339055466067, 6.578871366444933, 3.36786449988508, -0.3018576333261814, -0.9134779888613916, -0.6076678110937865, 0.4626678110928314, 4.438200122071698, 4.5911052109555, 6.120156099793526, 6.884681544212539, 7.190491721980144, 8.10792225528296, 2.909149233233672, 0.1568576333252263, -7.488396810864901, -12.075549477378978, -8.864542610819125, -6.723871366445889, -5.347725566491666, -5.500630655375468, -1.2192881666289968, 4.5911052109555, 7.190491721980144, 8.260827344166762, 9.636973144120985, 5.355630655374513, 3.5207695887688826, 5.661440833142118, 2.7562441443498695, 3.2149594110012774, 2.297528877698462, -0.9134779888613916, -2.901244144350825, -2.748339055467022, -3.0541492332346274, -3.20705432211843, -5.347725566491666, -8.558732433051519, -6.4180611886782835, -6.265156099794481, -7.7942069886325065, -9.17035278858673, -8.558732433051519, -8.558732433051519, -7.7942069886325065, -5.04191538872406, -2.442528877699417, 1.0742881666280415, 0.6155728999766339, 0.921383077744239, 2.297528877698462, 5.661440833142118, 6.7317764553287365, 7.802112077515354, 9.331162966353379, 8.71954261081817, 13.153790188448443, 6.273061188677328, -2.5954339665832196, -7.488396810864901, -7.7942069886325065, -3.81867467765364, -3.81867467765364, -4.736105210956455, -6.5709662775620865, -5.806440833143073, -8.405827344167717, -5.347725566491666, -3.0541492332346274, -2.5954339665832196, -1.5250983443966017, 0.00395254444142372, 4.132389944304093, 3.97948485542029, 8.413732433050564, 5.661440833142118, 9.789878233004787, 17.282227588311112, 17.282227588311112, 18.35256321049773, 13.765410543983654, 11.930549477378023, 8.566637521934366, 2.7562441443498695, -3.81867467765364, -8.711637521935321, -12.687169832914188, -15.439461432822634, -13.757505455100807, -11.922644388495176, -6.265156099794481, -4.124484855421246, -3.9715797665374426, -6.5709662775620865, -7.029681544213494, -0.4547627222099839, 1.0742881666280415, 4.896915388723105, 7.190491721980144, 7.037586633096341, 8.413732433050564, 7.496301899747749, 11.930549477378023, 13.306695277332246, 9.942783321888589, 6.120156099793526, 0.921383077744239, -0.9134779888613916, -4.124484855421246, -10.852308766308557, -11.922644388495176, -10.852308766308557, -11.922644388495176, -11.463929121843767, -16.203986877241647, -19.5678988326853, -17.427227588312068, -15.745271610590239, -14.216220721752213, -14.216220721752213, -9.017447699702927, -1.830908522164207, -1.0663830777451941, 0.921383077744239, 2.297528877698462, 3.36786449988508, 7.9550171663991565, 6.884681544212539, 9.178257877469576, 11.013118944075208, 6.884681544212539, 5.814345922025921, 4.438200122071698, 3.8265797665364873, 5.20272556649071, 1.6859085221632517, -5.653535744259271, -7.029681544213494, -6.876776455329691, -8.10001716640011, -8.405827344167717, -7.029681544213494, -4.736105210956455, -6.4180611886782835, -4.583200122072653, -5.04191538872406, -2.442528877699417, -1.6780034332804044, -4.736105210956455, -0.760572899977589, -1.9838136110480096, -2.442528877699417, 0.30976272220902884, 0.7684779888604365, 3.5207695887688826, 7.496301899747749, 7.190491721980144, 7.649206988631551, 10.5544036774238, 10.095688410772393, 8.71954261081817, 4.438200122071698, 3.2149594110012774, 5.661440833142118, 3.8265797665364873, -2.901244144350825, -11.311024032959965, -17.58013267719587, -16.203986877241647, -14.674935988403622, -15.13365125505503, -17.121417410544463, -18.497563210498686, -11.311024032959965, -6.112251010910678, -6.4180611886782835, -6.5709662775620865, -2.442528877699417, -3.512864499886035, 0.6155728999766339, 8.10792225528296, 7.496301899747749, 10.248593499656195, 9.942783321888589, 8.872447699701972, 9.178257877469576, 9.331162966353379, 5.661440833142118, 5.20272556649071, 4.896915388723105, 3.97948485542029, 3.2149594110012774, -1.3721932555127994, 0.4626678110928314, 0.7684779888604365, -0.9134779888613916, -3.9715797665374426, -4.583200122072653, -4.124484855421246, -3.81867467765364, -2.289623788815615, -1.830908522164207, -2.136718699931812, -4.124484855421246, -1.3721932555127994, 3.673674677652685, 8.566637521934366, 6.425966277561131, 4.438200122071698, 6.425966277561131, 7.649206988631551, 10.248593499656195, 9.025352788585774, 5.355630655374513, -0.6076678110937865, -3.3599594110022326, -3.6657695887698374, -4.583200122072653, -5.500630655375468, -6.265156099794481, -5.806440833143073, -7.335491721981099, -8.711637521935321, -13.298790188449399, -12.381359655146584, -12.84007492179799, -13.910410543984609, -8.558732433051519, -8.711637521935321, -5.04191538872406, 0.4626678110928314, 1.5330034332794493]\",\n          \"[-11.922644388495176, -10.39359349965715, -9.78197314412194, -15.286556343938832, -16.203986877241647, -16.051081788357845, -13.4516952773332, -12.992980010681793, -13.298790188449399, -7.335491721981099, -9.629068055238138, -4.277389944305048, -7.182586633097296, -4.583200122072653, -4.43029503318885, -5.1948204776078635, -2.748339055467022, -11.158118944076163, -11.311024032959965, -11.158118944076163, -8.558732433051519, -8.558732433051519, -3.0541492332346274, -4.583200122072653, -8.864542610819125, -11.311024032959965, -14.369125810636016, -9.934878233005742, -12.84007492179799, -5.500630655375468, -6.723871366445889, -3.3599594110022326, 4.285295033187896, 2.7562441443498695, 6.120156099793526, 2.297528877698462, 1.5330034332794493, 1.0742881666280415, -1.9838136110480096, -3.9715797665374426, -1.3721932555127994, -2.136718699931812, -2.5954339665832196, -3.20705432211843, -9.17035278858673, -8.10001716640011, -9.17035278858673, -4.43029503318885, -5.04191538872406, -5.959345922026876, -5.347725566491666, -14.827841077287424, -12.84007492179799, -11.61683421072757, -10.087783321889544, -9.17035278858673, -10.087783321889544, -5.959345922026876, -4.43029503318885, -5.806440833143073, -3.512864499886035, -0.760572899977589, -4.277389944305048, -0.3018576333261814, 0.7684779888604365, 2.4504339665822648, 3.97948485542029, 0.921383077744239, -0.3018576333261814, -3.9715797665374426, -1.3721932555127994, -6.112251010910678, -4.277389944305048, 0.921383077744239, -6.5709662775620865, -7.335491721981099, -5.959345922026876, -8.711637521935321, -5.347725566491666, -4.43029503318885, -8.711637521935321, -4.889010299840258, -7.029681544213494, -5.04191538872406, -3.81867467765364, -5.653535744259271, 0.1568576333252263, -2.901244144350825, 0.4626678110928314, 3.673674677652685, 0.921383077744239, 2.1446237888146595, 2.909149233233672, 3.97948485542029, 5.049820477606908, 0.921383077744239, -2.289623788815615, -2.136718699931812, -4.124484855421246, 1.991718699930857, 0.921383077744239, -2.748339055467022, 0.6155728999766339, 0.1568576333252263, 1.8388136110470543, 2.909149233233672, 0.6155728999766339, -0.14895254444237882, 2.1446237888146595, 5.049820477606908, 4.285295033187896, 1.227193255511844, -0.9134779888613916, -3.20705432211843, -1.830908522164207, 0.7684779888604365, 2.603339055466067, 3.5207695887688826, 0.4626678110928314, 2.909149233233672, 3.2149594110012774, 1.227193255511844, 2.1446237888146595, 1.5330034332794493, -0.14895254444237882, 0.00395254444142372, 2.603339055466067, 5.049820477606908, 6.425966277561131, 5.967251010909723, 7.190491721980144, 6.884681544212539, 10.707308766307602, 9.789878233004787, 7.649206988631551, 9.331162966353379, 7.649206988631551, 8.413732433050564, 7.802112077515354, 9.331162966353379, 9.178257877469576, 8.71954261081817, 2.297528877698462, -1.6780034332804044, -0.9134779888613916, 5.661440833142118, 7.802112077515354, 3.0620543221174747, 10.860213855191406, 11.013118944075208, 13.153790188448443, 11.471834210726616, 9.178257877469576, 6.7317764553287365, -1.5250983443966017, 0.00395254444142372, 0.4626678110928314, 0.7684779888604365, 2.7562441443498695, 7.343396810863946, 6.120156099793526, 11.16602403295901, 12.236359655145629, 11.013118944075208, 11.77764438849422, 4.285295033187896, 10.5544036774238, 8.260827344166762, 4.438200122071698, -0.6076678110937865, -2.289623788815615, 3.36786449988508, 2.909149233233672, 2.4504339665822648, 0.7684779888604365, 7.9550171663991565, 7.037586633096341, 7.190491721980144, 0.30976272220902884, -0.760572899977589, 0.6155728999766339, -2.748339055467022, 4.285295033187896, -2.5954339665832196, -1.9838136110480096, -3.9715797665374426, -0.6076678110937865, 5.355630655374513, 7.9550171663991565, 9.636973144120985, 2.1446237888146595, 3.5207695887688826, 2.909149233233672, 3.5207695887688826, 0.4626678110928314, -1.2192881666289968, -4.889010299840258, -2.289623788815615, 1.0742881666280415, -2.442528877699417, -3.0541492332346274, -6.876776455329691, 0.1568576333252263, -1.830908522164207, -4.124484855421246, -1.0663830777451941, -5.959345922026876, -5.653535744259271, 0.00395254444142372, 0.4626678110928314, -1.830908522164207, -2.136718699931812, -5.806440833143073, -2.748339055467022, -1.830908522164207, 0.1568576333252263, 3.36786449988508, 5.967251010909723, 11.930549477378023, 13.306695277332246, 13.000885099564641, 4.5911052109555, -1.9838136110480096, -1.6780034332804044, -1.3721932555127994, -0.760572899977589, -0.9134779888613916, -3.3599594110022326, -2.136718699931812, 1.227193255511844, 1.3800983443956467, 3.8265797665364873, 3.36786449988508, 7.037586633096341, 9.178257877469576, 7.496301899747749, 7.496301899747749, 3.36786449988508, 4.438200122071698, 2.909149233233672, 0.00395254444142372, 0.00395254444142372, -0.9134779888613916, -1.830908522164207, -2.136718699931812, -2.901244144350825, -1.9838136110480096, 1.3800983443956467, -2.901244144350825, 0.1568576333252263, 0.4626678110928314, 0.6155728999766339, 0.921383077744239, -5.347725566491666, -1.6780034332804044, -4.583200122072653, -4.889010299840258, -7.182586633097296, -7.7942069886325065, -3.6657695887698374, -2.748339055467022, -2.5954339665832196, -4.124484855421246, -4.124484855421246, -10.240688410773348, -7.947112077516309, -7.947112077516309, -4.124484855421246, -1.5250983443966017, -2.289623788815615, 0.6155728999766339, -6.876776455329691, -4.277389944305048, -4.277389944305048, -3.0541492332346274, -1.0663830777451941, -3.9715797665374426, -4.889010299840258, -5.653535744259271, -3.3599594110022326, -5.500630655375468, -5.347725566491666, -7.641301899748704, -8.711637521935321, -9.476162966354334, -6.5709662775620865, -6.723871366445889, -12.534264744030386, -9.476162966354334, -11.61683421072757, -8.252922255283915, -4.583200122072653, -2.901244144350825, -0.6076678110937865, -1.0663830777451941, 0.4626678110928314, 0.1568576333252263, 2.297528877698462, 2.297528877698462, 1.6859085221632517, 0.6155728999766339, 4.744010299839303, 3.97948485542029, 3.36786449988508, 3.0620543221174747, -6.112251010910678, -5.500630655375468, -6.5709662775620865, -9.934878233005742, -12.84007492179799, -13.145885099565596, -9.934878233005742, -8.10001716640011, -6.723871366445889, -7.029681544213494, -4.583200122072653, -2.442528877699417, 0.4626678110928314, 1.0742881666280415, 3.5207695887688826, 3.97948485542029, 5.355630655374513, 6.120156099793526, 4.744010299839303, 6.120156099793526, 6.425966277561131, 7.9550171663991565, 5.355630655374513, 3.97948485542029, 2.297528877698462, 2.1446237888146595, -3.81867467765364, -8.10001716640011, -5.806440833143073, -1.9838136110480096, 0.921383077744239, -6.5709662775620865, -10.852308766308557, -14.063315632868411, -7.029681544213494, -1.830908522164207, -3.0541492332346274, -0.3018576333261814, -0.6076678110937865, -0.760572899977589, -2.5954339665832196, -4.736105210956455, -6.876776455329691, -3.9715797665374426, -6.876776455329691, -9.323257877470532, -7.947112077516309, -5.347725566491666, -0.6076678110937865, -0.760572899977589, 7.802112077515354, 12.542169832913233, 15.141556343937877, 16.823512321659706, 11.77764438849422, 7.343396810863946, 3.8265797665364873, -0.3018576333261814, -6.723871366445889, -9.476162966354334, -12.075549477378978, -11.463929121843767, -12.381359655146584, -13.145885099565596, -14.674935988403622, -17.274322499428266, -11.158118944076163, -9.78197314412194, -10.087783321889544, -8.405827344167717, -8.711637521935321, -9.017447699702927, -7.641301899748704, -3.9715797665374426, -1.6780034332804044, 0.4626678110928314, 3.673674677652685, 4.438200122071698, 3.673674677652685, 5.967251010909723, 3.2149594110012774, 1.991718699930857, 3.2149594110012774, -0.6076678110937865, 2.4504339665822648, 5.355630655374513, 6.7317764553287365, 11.16602403295901, 9.484068055237183, 10.401498588539997, 13.306695277332246, 12.236359655145629, 9.942783321888589, 11.624739299610418, 8.260827344166762, 2.909149233233672, -0.4547627222099839, -3.9715797665374426, 1.0742881666280415, 2.297528877698462, 5.508535744258316, 9.025352788585774, 7.649206988631551, 4.5911052109555, 6.273061188677328, 11.471834210726616, 7.343396810863946, 5.049820477606908, -1.3721932555127994, -7.335491721981099, -8.405827344167717, -5.347725566491666, -1.9838136110480096, 1.5330034332794493, 4.744010299839303, 5.049820477606908, 8.10792225528296, 9.178257877469576, 14.071220721751258, 8.872447699701972, 4.132389944304093, 1.0742881666280415, -4.277389944305048, -3.81867467765364, -3.9715797665374426, -2.901244144350825, -2.5954339665832196, 2.909149233233672, 4.285295033187896, 8.10792225528296, 8.413732433050564, 7.649206988631551, 9.331162966353379, 3.0620543221174747, 3.36786449988508, -3.9715797665374426, -4.583200122072653, -4.889010299840258, -7.029681544213494, -7.947112077516309, -7.947112077516309, 0.00395254444142372, -4.43029503318885, -3.81867467765364, -2.748339055467022, 0.7684779888604365, 0.921383077744239, 0.1568576333252263, 3.5207695887688826, 1.6859085221632517, 5.049820477606908, 2.7562441443498695, 2.1446237888146595, -5.653535744259271, -7.488396810864901, -8.405827344167717, -12.992980010681793, -6.4180611886782835, -4.124484855421246, -4.583200122072653, -8.558732433051519, -6.5709662775620865, -9.017447699702927, -9.629068055238138, -7.947112077516309, -10.852308766308557, -9.017447699702927, -4.889010299840258, 1.5330034332794493, -5.653535744259271, -9.629068055238138, -11.158118944076163, -12.687169832914188, -7.7942069886325065, -4.583200122072653, 1.227193255511844, -1.3721932555127994, -3.0541492332346274, -3.81867467765364, -2.442528877699417, 2.1446237888146595, 1.8388136110470543, -1.0663830777451941, -5.653535744259271, -4.43029503318885, -4.277389944305048, -1.830908522164207, -3.3599594110022326, -4.124484855421246, 0.00395254444142372, -0.4547627222099839, 2.603339055466067, 0.7684779888604365, 2.909149233233672, 8.413732433050564]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Shannon_Entropy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6384181492566036,\n        \"min\": -0.0,\n        \"max\": 8.885784284662025,\n        \"num_unique_values\": 13281,\n        \"samples\": [\n          6.954340952558192,\n          6.739003799380398,\n          8.257769053734359\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Approximate_Entropy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1882383166806365,\n        \"min\": 0.0,\n        \"max\": 1.4243943366480147,\n        \"num_unique_values\": 13284,\n        \"samples\": [\n          0.8129292993153228,\n          1.334914009966349,\n          1.1922914376936706\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sample_Entropy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.288630043512918,\n        \"min\": 0.0,\n        \"max\": 2.1759265796572853,\n        \"num_unique_values\": 13186,\n        \"samples\": [\n          0.7266439285598789,\n          1.3634285363828875,\n          1.299196317752428\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tsallis_Entropy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03801160793289522,\n        \"min\": 0.0,\n        \"max\": 0.99784,\n        \"num_unique_values\": 2697,\n        \"samples\": [\n          0.980856,\n          0.983632,\n          0.996392\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spectral_Entropy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10027983025981206,\n        \"min\": -0.0,\n        \"max\": 0.9067928834724264,\n        \"num_unique_values\": 13285,\n        \"samples\": [\n          0.6062864379384274,\n          0.6466934894520434,\n          0.6479109268450541\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "hdata"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-dcbfec08-c38b-45e2-a813-018566d9dd31\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject_ID</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Signal_Values</th>\n",
       "      <th>Shannon_Entropy</th>\n",
       "      <th>Approximate_Entropy</th>\n",
       "      <th>Sample_Entropy</th>\n",
       "      <th>Tsallis_Entropy</th>\n",
       "      <th>Spectral_Entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>1</td>\n",
       "      <td>[11.317479857782855, 11.011669591356267, 11.77...</td>\n",
       "      <td>7.511884</td>\n",
       "      <td>0.907534</td>\n",
       "      <td>0.929651</td>\n",
       "      <td>0.993672</td>\n",
       "      <td>0.489428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>2</td>\n",
       "      <td>[-5.9608001953193535, -10.395049058504876, -11...</td>\n",
       "      <td>7.213492</td>\n",
       "      <td>1.083219</td>\n",
       "      <td>1.117977</td>\n",
       "      <td>0.991832</td>\n",
       "      <td>0.680598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>3</td>\n",
       "      <td>[8.870997726370152, 9.023902859583446, 4.89546...</td>\n",
       "      <td>6.782381</td>\n",
       "      <td>1.128291</td>\n",
       "      <td>1.232144</td>\n",
       "      <td>0.989224</td>\n",
       "      <td>0.585859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>4</td>\n",
       "      <td>[-11.465384990997933, -11.006669591358051, -8....</td>\n",
       "      <td>7.689071</td>\n",
       "      <td>0.857106</td>\n",
       "      <td>0.902307</td>\n",
       "      <td>0.994496</td>\n",
       "      <td>0.431208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>5</td>\n",
       "      <td>[74.62020500808651, 61.16455328531666, 52.4489...</td>\n",
       "      <td>8.157974</td>\n",
       "      <td>0.559002</td>\n",
       "      <td>0.481663</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.310777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13295</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>46</td>\n",
       "      <td>[-1.0678359324939495, -4.584653996399709, -5.5...</td>\n",
       "      <td>7.090620</td>\n",
       "      <td>0.872365</td>\n",
       "      <td>0.902909</td>\n",
       "      <td>0.991288</td>\n",
       "      <td>0.652485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13296</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>47</td>\n",
       "      <td>[-10.242143925291582, -10.089238792078289, -9....</td>\n",
       "      <td>6.800197</td>\n",
       "      <td>1.139629</td>\n",
       "      <td>1.256508</td>\n",
       "      <td>0.989040</td>\n",
       "      <td>0.654079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13297</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>48</td>\n",
       "      <td>[7.18904126102392, 3.6722231971181607, 1.68445...</td>\n",
       "      <td>7.200287</td>\n",
       "      <td>0.867842</td>\n",
       "      <td>0.911789</td>\n",
       "      <td>0.991680</td>\n",
       "      <td>0.587804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13298</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>49</td>\n",
       "      <td>[-5.349179662466178, -7.489851527452292, -9.63...</td>\n",
       "      <td>7.167406</td>\n",
       "      <td>0.992832</td>\n",
       "      <td>1.059401</td>\n",
       "      <td>0.991784</td>\n",
       "      <td>0.498251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13299</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>50</td>\n",
       "      <td>[2.143171864985222, 0.6141205328522832, 0.0024...</td>\n",
       "      <td>6.864494</td>\n",
       "      <td>1.089605</td>\n",
       "      <td>1.220319</td>\n",
       "      <td>0.989848</td>\n",
       "      <td>0.645328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13300 rows × 9 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dcbfec08-c38b-45e2-a813-018566d9dd31')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-dcbfec08-c38b-45e2-a813-018566d9dd31 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-dcbfec08-c38b-45e2-a813-018566d9dd31');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-0ed270c9-30e9-436e-bc4b-c36501f64d83\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0ed270c9-30e9-436e-bc4b-c36501f64d83')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-0ed270c9-30e9-436e-bc4b-c36501f64d83 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_be2f5731-b54d-41cb-bec8-40f1dcb0ecfb\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('hdata')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_be2f5731-b54d-41cb-bec8-40f1dcb0ecfb button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('hdata');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "       Subject_ID Channel  Epoch  \\\n",
       "0               1     Fp1      1   \n",
       "1               1     Fp1      2   \n",
       "2               1     Fp1      3   \n",
       "3               1     Fp1      4   \n",
       "4               1     Fp1      5   \n",
       "...           ...     ...    ...   \n",
       "13295          14      Pz     46   \n",
       "13296          14      Pz     47   \n",
       "13297          14      Pz     48   \n",
       "13298          14      Pz     49   \n",
       "13299          14      Pz     50   \n",
       "\n",
       "                                           Signal_Values  Shannon_Entropy  \\\n",
       "0      [11.317479857782855, 11.011669591356267, 11.77...         7.511884   \n",
       "1      [-5.9608001953193535, -10.395049058504876, -11...         7.213492   \n",
       "2      [8.870997726370152, 9.023902859583446, 4.89546...         6.782381   \n",
       "3      [-11.465384990997933, -11.006669591358051, -8....         7.689071   \n",
       "4      [74.62020500808651, 61.16455328531666, 52.4489...         8.157974   \n",
       "...                                                  ...              ...   \n",
       "13295  [-1.0678359324939495, -4.584653996399709, -5.5...         7.090620   \n",
       "13296  [-10.242143925291582, -10.089238792078289, -9....         6.800197   \n",
       "13297  [7.18904126102392, 3.6722231971181607, 1.68445...         7.200287   \n",
       "13298  [-5.349179662466178, -7.489851527452292, -9.63...         7.167406   \n",
       "13299  [2.143171864985222, 0.6141205328522832, 0.0024...         6.864494   \n",
       "\n",
       "       Approximate_Entropy  Sample_Entropy  Tsallis_Entropy  Spectral_Entropy  \n",
       "0                 0.907534        0.929651         0.993672          0.489428  \n",
       "1                 1.083219        1.117977         0.991832          0.680598  \n",
       "2                 1.128291        1.232144         0.989224          0.585859  \n",
       "3                 0.857106        0.902307         0.994496          0.431208  \n",
       "4                 0.559002        0.481663         0.995984          0.310777  \n",
       "...                    ...             ...              ...               ...  \n",
       "13295             0.872365        0.902909         0.991288          0.652485  \n",
       "13296             1.139629        1.256508         0.989040          0.654079  \n",
       "13297             0.867842        0.911789         0.991680          0.587804  \n",
       "13298             0.992832        1.059401         0.991784          0.498251  \n",
       "13299             1.089605        1.220319         0.989848          0.645328  \n",
       "\n",
       "[13300 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input_file = 'data_with_entropies.csv'  # Replace with your actual file name\n",
    "hdata = pd.read_csv(input_file)\n",
    "hdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "C6F-mZH-Sq8V",
    "outputId": "99d1dbc3-8abe-4aec-cbcb-e575579d199f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/antropy/entropy.py:253: RuntimeWarning: invalid value encountered in divide\n",
      "  psd_norm = psd / psd.sum(axis=axis, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy calculations complete. Results saved to data_with_unentropies.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from scipy.stats import entropy as shannon_entropy\n",
    "import antropy as ant\n",
    "\n",
    "# Function to calculate Shannon Entropy\n",
    "def calculate_shannon_entropy(signal):\n",
    "    counter = Counter(signal)  # Count occurrences of each value\n",
    "    total_count = len(signal)\n",
    "    probabilities = [count / total_count for count in counter.values()]\n",
    "    return -sum(p * np.log2(p) for p in probabilities if p > 0)\n",
    "\n",
    "# Function to calculate Approximate Entropy\n",
    "def calculate_approximate_entropy(signal, m=2, r=0.2):\n",
    "    return ant.app_entropy(signal, order=m, metric=\"chebyshev\")\n",
    "\n",
    "# Function to calculate Sample Entropy\n",
    "def calculate_sample_entropy(signal, m=2, r=0.2):\n",
    "    return ant.sample_entropy(signal, order=m, metric=\"chebyshev\")\n",
    "\n",
    "# Function to calculate Tsallis Entropy\n",
    "def calculate_tsallis_entropy(signal, q=2):\n",
    "    counter = Counter(signal)  # Count occurrences of each value\n",
    "    total_count = len(signal)\n",
    "    probabilities = np.array([count / total_count for count in counter.values()])\n",
    "    tsallis = (1 - np.sum(probabilities ** q)) / (q - 1) if q != 1 else calculate_shannon_entropy(signal)\n",
    "    return tsallis\n",
    "\n",
    "# Function to calculate Spectral Entropy\n",
    "def calculate_spectral_entropy(signal, sampling_frequency=1):\n",
    "    return ant.spectral_entropy(signal, sf=sampling_frequency, method=\"welch\", normalize=True)\n",
    "\n",
    "# Load CSV data\n",
    "input_file = 'unhealthy_data_tabular.csv'  # Replace with your actual file\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "# Ensure Signal_Values is parsed as a list of floats\n",
    "data['Signal_Values'] = data['Signal_Values'].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Initialize new columns\n",
    "data['Shannon_Entropy'] = data['Signal_Values'].apply(calculate_shannon_entropy)\n",
    "data['Approximate_Entropy'] = data['Signal_Values'].apply(calculate_approximate_entropy)\n",
    "data['Sample_Entropy'] = data['Signal_Values'].apply(calculate_sample_entropy)\n",
    "data['Tsallis_Entropy'] = data['Signal_Values'].apply(calculate_tsallis_entropy)\n",
    "data['Spectral_Entropy'] = data['Signal_Values'].apply(calculate_spectral_entropy)\n",
    "\n",
    "# Save updated data to a new CSV\n",
    "output_file = 'data_with_unentropies.csv'\n",
    "data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Entropy calculations complete. Results saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 790
    },
    "id": "lUPwalWDTc3_",
    "outputId": "3de9855d-c95d-43ed-e40b-6a6fdfbebca9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"data\",\n  \"rows\": 13300,\n  \"fields\": [\n    {\n      \"column\": \"Subject_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 1,\n        \"max\": 14,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          10,\n          12,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Channel\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"Fp1\",\n          \"C4\",\n          \"F8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 1,\n        \"max\": 50,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          14,\n          40,\n          31\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Signal_Values\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13275,\n        \"samples\": [\n          \"[1.6844564653453404, 0.15540513321240157, -1.0678359324939495, -3.973033463546533, -3.2085077974800638, -2.1381718649870067, -0.45621539964077396, -0.1504051332141862, 2.7547923978383975, 2.143171864985222, 4.283843729971337, 5.354179662464394, 3.366412930691573, 1.2257410657054588, -1.9852667317737127, -4.278843729973121, -6.5724207281725295, -4.584653996399709, -6.113705328532648, -5.80789506210606, -6.725325861385823, -4.737559129613002, -0.9149307992806556, -1.832361598560419, 1.8373615985586342, 0.46121539963898933, -7.0311361278124105, -11.465384990997933, -13.147341456344167, -19.56935705130251, -18.651926252022747, -17.2757800531031, -22.78036484878168, -22.168744315928507, -20.180977584155684, -17.428685186316393, -10.700859324931464, -3.8201283303332394, -3.5143180639066514, -3.973033463546533, -6.419515594959235, -10.395049058504876, -10.395049058504876, -8.713092593158644, -4.584653996399709, -6.878230994599117, -8.254377193518762, -11.31247985778464, -13.606056855984047, -11.771195257424521, -8.713092593158644, -5.043369396039591, -6.419515594959235, -8.713092593158644, -13.147341456344167, -12.994436323130872, -12.077005523851108, -11.006669591358051, -8.407282326732055, -7.336946394238999, -5.502084795679472, -6.5724207281725295, -3.6672231971199456, -3.8201283303332394, -5.654989928892766, -5.502084795679472, -6.419515594959235, -7.642756660665587, -9.171807992798525, -9.630523392438407, -10.853764458144758, -8.56018745994535, -4.890464262826296, -1.0678359324939495, 0.15540513321240157, -2.2910769982003005, -7.336946394238999, -10.395049058504876, -10.700859324931464, -9.630523392438407, -5.043369396039591, -3.5143180639066514, -3.05560266426677, -1.832361598560419, 0.0024999999991076978, 5.659989928890981, 6.577420728170744, 8.259377193516977, 9.329713126010034, 1.5315513321320464, -3.3614129306933576, -3.6672231971199456, -3.973033463546533, -3.5143180639066514, 3.366412930691573, 8.106472060303684, 7.341946394237214, 11.164574724569562, 13.763961989195558, 11.623290124209444, 11.92910039063603, 13.458151722768969, 11.623290124209444, 12.999436323129087, 14.834297921688615, 12.234910657062619, 14.069772255622144, 11.317479857782855, 7.036136127810626, 6.577420728170744, 6.577420728170744, 7.036136127810626, 8.870997726370152, 10.400049058503091, 7.18904126102392, 5.048369396037806, 3.366412930691573, 2.44898213141181, 4.895464262824512, 9.788428525649916, 13.458151722768969, 13.305246589555676, 13.916867122408851, 11.011669591356267, 9.176807992796741, 7.95356692709039, 8.259377193516977, 11.317479857782855, 10.858764458142973, 12.082005523849324, 10.70585932492968, 8.71809259315686, 4.895464262824512, 3.366412930691573, 2.44898213141181, 0.46121539963898933, 1.9902667317719283, 3.0606026642649855, 3.2135077974782793, 1.5315513321320464, 2.7547923978383975, 2.9076975310516913, 3.2135077974782793, 5.507084795677687, 6.883230994597333, 5.812895062104275, 2.296076998198516, 0.0024999999991076978, -5.349179662466178, -8.254377193518762, -8.865997726371937, -6.113705328532648, -0.45621539964077396, 2.9076975310516913, 5.2012745292511, 5.965800195317569, 5.659989928890981, 0.919930799278871, 3.366412930691573, 1.3786461989187526, 0.3083102664256955, 1.6844564653453404, -0.6091205328540679, 0.3083102664256955, 0.6141205328522832, 4.283843729971337, 5.048369396037806, 9.023902859583446, 8.870997726370152, 8.106472060303684, 7.95356692709039, 4.895464262824512, 3.9780334635447487, 0.6141205328522832, 4.1309385967580425, 2.44898213141181, 3.825128330331455, 3.6722231971181607, 4.1309385967580425, 3.2135077974782793, 1.3786461989187526, 4.283843729971337, 0.6141205328522832, 4.283843729971337, 8.870997726370152, 9.635523392436623, 7.494851527450508, 10.094238792076505, 6.883230994597333, -0.45621539964077396, 2.296076998198516, -0.45621539964077396, -1.3736461989205373, -1.526551332133831, -1.3736461989205373, -0.30331026642748005, 1.2257410657054588, 5.507084795677687, 6.271610461744157, 5.965800195317569, 3.0606026642649855, 2.7547923978383975, 3.9780334635447487, 4.589653996397924, 4.589653996397924, 5.354179662464394, 4.895464262824512, 2.9076975310516913, 2.9076975310516913, 2.6018872646251037, 1.2257410657054588, 0.7670256660655771, 1.5315513321320464, 1.3786461989187526, 2.296076998198516, 3.825128330331455, 0.7670256660655771, 2.143171864985222, 3.6722231971181607, 1.3786461989187526, 3.825128330331455, 1.5315513321320464, -3.973033463546533, -5.654989928892766, -6.878230994599117, -5.9608001953193535, -5.196274529252884, -4.890464262826296, -5.196274529252884, -6.113705328532648, -6.419515594959235, -1.679456465347125, -0.45621539964077396, -1.9852667317737127, -2.1381718649870067, -6.113705328532648, -5.349179662466178, -7.0311361278124105, -6.725325861385823, -5.654989928892766, -8.56018745994535, -10.547954191718171, -12.688626056704285, -11.924100390637815, -12.994436323130872, -11.924100390637815, -10.853764458144758, -10.242143925291582, -9.7834285256517, -8.713092593158644, -7.0311361278124105, -7.184041261025705, -6.113705328532648, -5.9608001953193535, -4.584653996399709, -7.642756660665587, -8.713092593158644, -9.018902859585232, -11.159574724571346, -7.79566179387888, -7.0311361278124105, -4.737559129613002, -5.043369396039591, -6.113705328532648, -6.266610461745941, -8.56018745994535, -9.324713126011819, -9.018902859585232, -8.407282326732055, -6.5724207281725295, -4.431748863186415, -2.7497923978401824, 1.5315513321320464, 1.3786461989187526, 2.296076998198516, 3.0606026642649855, -1.3736461989205373, -3.3614129306933576, -4.125938596759827, -3.5143180639066514, -1.3736461989205373, -0.1504051332141862, -0.1504051332141862, -0.30331026642748005, -2.1381718649870067, 0.0024999999991076978, 0.0024999999991076978, 0.15540513321240157, -0.1504051332141862, -1.2207410657072433, 1.2257410657054588, 0.6141205328522832, 2.9076975310516913, 3.2135077974782793, -0.30331026642748005, -1.9852667317737127, -1.9852667317737127, -1.2207410657072433, 0.7670256660655771, 1.8373615985586342, 0.6141205328522832, 0.15540513321240157, -2.7497923978401824, -0.45621539964077396, 0.7670256660655771, 0.919930799278871, 0.919930799278871, 0.3083102664256955, -0.9149307992806556, -3.3614129306933576, -0.30331026642748005, -0.30331026642748005, 0.15540513321240157, 1.0728359324921648, -2.4439821314135943, -4.278843729973121, -4.890464262826296, -6.419515594959235, -6.113705328532648, -3.973033463546533, -5.80789506210606, -5.349179662466178, -7.79566179387888, -7.948566927092174, -4.584653996399709, -4.278843729973121, 1.3786461989187526, 0.7670256660655771, -0.6091205328540679, -2.2910769982003005, -2.902697531053476, -0.9149307992806556, 0.919930799278871, 4.1309385967580425, 3.6722231971181607, 0.3083102664256955, -2.7497923978401824, -3.2085077974800638, -3.973033463546533, -1.679456465347125, -0.6091205328540679, 0.7670256660655771, 2.9076975310516913, 1.5315513321320464, 3.6722231971181607, 2.143171864985222, -1.2207410657072433, -4.278843729973121, -6.5724207281725295, -6.5724207281725295, -2.902697531053476, 1.8373615985586342, 4.742559129611218, 4.895464262824512, 2.9076975310516913, 2.143171864985222, 2.9076975310516913, 5.507084795677687, 7.341946394237214, 7.647756660663802, 8.71809259315686, 6.424515594957451, 6.424515594957451, 8.259377193516977, 7.647756660663802, 8.565187459943566, 7.95356692709039, 6.883230994597333, 5.2012745292511, 4.742559129611218, 2.7547923978383975, 2.296076998198516, 2.7547923978383975, 1.8373615985586342, 1.3786461989187526, 1.3786461989187526, 2.44898213141181, 2.143171864985222, 3.6722231971181607, 4.1309385967580425, 2.7547923978383975, 0.919930799278871, 1.6844564653453404, 2.9076975310516913, 1.0728359324921648, 1.5315513321320464, 1.3786461989187526, 0.3083102664256955, 0.0024999999991076978, -0.1504051332141862, -2.596887264626888, -4.431748863186415, -5.9608001953193535, -2.7497923978401824, 0.15540513321240157, 0.7670256660655771, 3.825128330331455, 2.6018872646251037, 2.44898213141181, 2.6018872646251037, 3.9780334635447487, 4.742559129611218, 0.0024999999991076978, -5.196274529252884, -6.5724207281725295, -9.171807992798525, -10.547954191718171, -4.278843729973121, -7.489851527452292, -10.547954191718171, -9.936333658864994, -10.700859324931464, -6.113705328532648, -4.431748863186415, 0.3083102664256955, 0.3083102664256955, -3.6672231971199456, -5.043369396039591, -6.5724207281725295, -6.878230994599117, -4.890464262826296, -1.3736461989205373, 3.0606026642649855, 4.589653996397924, 3.6722231971181607, 4.742559129611218, 0.919930799278871, -1.0678359324939495, 1.5315513321320464, 2.143171864985222, 1.3786461989187526, 0.15540513321240157, 0.15540513321240157, 0.6141205328522832, -0.45621539964077396, 3.366412930691573, 4.895464262824512, 2.296076998198516, 3.2135077974782793, 1.9902667317719283, 0.7670256660655771, -0.7620256660673617, -3.05560266426677, -1.2207410657072433, 0.919930799278871, 3.0606026642649855, 5.354179662464394, 2.44898213141181, -0.1504051332141862, 0.15540513321240157, 1.8373615985586342, 7.647756660663802, 9.023902859583446, 8.565187459943566, 4.742559129611218, -2.1381718649870067, -3.2085077974800638, -4.737559129613002, -3.973033463546533, -2.596887264626888, -2.1381718649870067, -3.8201283303332394, -3.2085077974800638, -1.0678359324939495, 0.3083102664256955, 2.296076998198516, 4.1309385967580425, 5.354179662464394, 1.5315513321320464, 2.143171864985222, 0.7670256660655771, 0.46121539963898933, 3.0606026642649855, 3.6722231971181607, 4.43674886318463, 5.354179662464394, 5.965800195317569, 6.118705328530863, 9.023902859583446, 9.329713126010034, 13.763961989195558, 14.069772255622144, 12.387815790275912, 11.164574724569562, 6.424515594957451, 3.0606026642649855, 3.6722231971181607, 7.647756660663802, 6.730325861384038, 9.94133365886321, 10.70585932492968, 7.647756660663802, 7.494851527450508, 7.494851527450508, 5.812895062104275, 1.9902667317719283, 0.46121539963898933, -1.9852667317737127, -3.5143180639066514, -6.419515594959235]\",\n          \"[-6.113705328532648, -0.45621539964077396, 1.2257410657054588, -0.45621539964077396, 0.0024999999991076978, -1.3736461989205373, -2.902697531053476, -3.05560266426677, -2.902697531053476, -2.902697531053476, -6.878230994599117, -10.089238792078289, -9.018902859585232, -10.242143925291582, -9.7834285256517, -8.865997726371937, -11.006669591358051, -11.924100390637815, -14.370582522050517, -14.064772255623929, -12.994436323130872, -12.229910657064403, -8.865997726371937, -6.878230994599117, -5.9608001953193535, -3.5143180639066514, -7.336946394238999, -7.489851527452292, -3.5143180639066514, -5.502084795679472, -0.45621539964077396, 0.6141205328522832, -2.596887264626888, -4.125938596759827, -6.878230994599117, -8.713092593158644, -9.7834285256517, -7.948566927092174, -4.890464262826296, -4.584653996399709, -3.05560266426677, 0.46121539963898933, -2.596887264626888, -1.9852667317737127, -2.902697531053476, -6.113705328532648, -6.113705328532648, -8.101472060305468, -4.890464262826296, -4.278843729973121, -3.973033463546533, -1.3736461989205373, -1.526551332133831, -2.596887264626888, 1.0728359324921648, -0.1504051332141862, -0.30331026642748005, 0.919930799278871, -3.3614129306933576, -2.7497923978401824, -3.5143180639066514, -0.6091205328540679, -0.6091205328540679, -0.45621539964077396, 2.7547923978383975, 1.9902667317719283, 2.44898213141181, 2.44898213141181, 3.6722231971181607, 1.8373615985586342, 3.366412930691573, 4.742559129611218, 8.41228232673027, 9.788428525649916, 8.259377193516977, 12.082005523849324, 10.70585932492968, 9.482618259223328, 10.858764458142973, 13.305246589555676, 11.470384990996148, 11.776195257422737, 13.305246589555676, 8.870997726370152, 7.8006617938770955, 5.659989928890981, 3.2135077974782793, 1.8373615985586342, 1.9902667317719283, 2.6018872646251037, 5.354179662464394, 7.341946394237214, 7.95356692709039, 10.094238792076505, 8.565187459943566, 7.647756660663802, 5.507084795677687, 6.118705328530863, 5.659989928890981, 2.44898213141181, 2.44898213141181, 1.0728359324921648, 1.5315513321320464, 2.7547923978383975, 3.825128330331455, 5.812895062104275, 3.6722231971181607, 3.519318063904867, 5.2012745292511, 5.965800195317569, 7.647756660663802, 10.247143925289798, 9.176807992796741, 6.730325861384038, 5.965800195317569, 4.43674886318463, 7.341946394237214, 8.259377193516977, 10.552954191716385, 11.776195257422737, 10.858764458142973, 11.470384990996148, 8.565187459943566, 9.176807992796741, 7.95356692709039, 5.354179662464394, 3.9780334635447487, 3.825128330331455, 3.2135077974782793, 3.519318063904867, 4.1309385967580425, 0.919930799278871, 3.519318063904867, 1.0728359324921648, 1.6844564653453404, 4.589653996397924, 5.048369396037806, 7.036136127810626, 7.341946394237214, 6.577420728170744, 3.519318063904867, 1.0728359324921648, -1.832361598560419, -3.3614129306933576, -4.890464262826296, -3.6672231971199456, -1.832361598560419, -1.9852667317737127, 1.2257410657054588, 2.9076975310516913, 4.895464262824512, 6.271610461744157, 4.589653996397924, 1.9902667317719283, -0.1504051332141862, 0.7670256660655771, 1.6844564653453404, 4.43674886318463, 7.18904126102392, 5.2012745292511, 4.283843729971337, 1.0728359324921648, 0.0024999999991076978, 0.0024999999991076978, 0.0024999999991076978, -0.6091205328540679, -2.596887264626888, -1.2207410657072433, -2.2910769982003005, -1.526551332133831, -0.7620256660673617, 0.0024999999991076978, -1.679456465347125, -4.278843729973121, -3.3614129306933576, -7.184041261025705, -7.336946394238999, -8.865997726371937, -5.654989928892766, -4.890464262826296, -3.6672231971199456, 0.46121539963898933, 0.15540513321240157, 1.8373615985586342, 1.6844564653453404, 1.5315513321320464, -0.30331026642748005, -0.6091205328540679, -3.3614129306933576, -3.5143180639066514, -3.5143180639066514, -3.05560266426677, -0.30331026642748005, -1.832361598560419, 1.3786461989187526, -0.30331026642748005, -1.679456465347125, -1.679456465347125, -4.278843729973121, -3.3614129306933576, -3.05560266426677, 1.0728359324921648, 3.366412930691573, 3.9780334635447487, 0.15540513321240157, -3.6672231971199456, -7.0311361278124105, -9.171807992798525, -8.713092593158644, -6.725325861385823, -3.973033463546533, -5.9608001953193535, -5.043369396039591, -5.043369396039591, -4.125938596759827, -5.9608001953193535, -8.101472060305468, -11.465384990997933, -16.511254387036633, -17.2757800531031, -15.593823587756868, -11.465384990997933, -8.407282326732055, -1.526551332133831, 0.919930799278871, 2.6018872646251037, 3.6722231971181607, 0.6141205328522832, -0.1504051332141862, -2.4439821314135943, -4.431748863186415, -6.878230994599117, -8.254377193518762, -9.477618259225112, -8.865997726371937, -5.502084795679472, -2.596887264626888, 2.6018872646251037, 5.048369396037806, 3.519318063904867, 3.519318063904867, 1.0728359324921648, 0.0024999999991076978, -3.8201283303332394, -6.725325861385823, -9.630523392438407, -13.758961989197342, -10.395049058504876, -7.642756660665587, -4.431748863186415, 0.0024999999991076978, 0.919930799278871, 0.0024999999991076978, 0.919930799278871, -1.2207410657072433, -4.125938596759827, -2.596887264626888, -5.349179662466178, -4.584653996399709, -3.5143180639066514, -3.3614129306933576, -5.196274529252884, -6.5724207281725295, -5.043369396039591, -6.419515594959235, -5.654989928892766, -5.654989928892766, -6.419515594959235, -8.254377193518762, -7.948566927092174, -7.336946394238999, -6.419515594959235, -5.9608001953193535, -5.80789506210606, -5.349179662466178, -6.725325861385823, -4.431748863186415, -4.890464262826296, -0.6091205328540679, 2.296076998198516, 4.283843729971337, 6.730325861384038, 5.507084795677687, 2.9076975310516913, -0.7620256660673617, -3.6672231971199456, -7.79566179387888, -7.184041261025705, -7.336946394238999, -5.9608001953193535, -1.679456465347125, -0.9149307992806556, 1.9902667317719283, 3.9780334635447487, 5.965800195317569, 7.036136127810626, 8.71809259315686, 7.494851527450508, 6.577420728170744, 7.036136127810626, 5.965800195317569, 8.41228232673027, 8.870997726370152, 11.164574724569562, 10.094238792076505, 8.259377193516977, 8.41228232673027, 4.1309385967580425, 2.9076975310516913, 4.1309385967580425, 3.2135077974782793, 3.825128330331455, 4.283843729971337, -0.45621539964077396, -2.7497923978401824, -5.043369396039591, -7.336946394238999, -5.349179662466178, -5.9608001953193535, -3.973033463546533, -3.05560266426677, -0.9149307992806556, 3.0606026642649855, 5.354179662464394, 9.788428525649916, 10.094238792076505, 6.271610461744157, 4.742559129611218, 3.366412930691573, -0.9149307992806556, 0.7670256660655771, 2.143171864985222, 0.15540513321240157, 3.6722231971181607, 2.44898213141181, 1.3786461989187526, 1.5315513321320464, 0.46121539963898933, -1.2207410657072433, 0.15540513321240157, 0.15540513321240157, 0.0024999999991076978, 2.6018872646251037, 0.15540513321240157, 2.296076998198516, 4.1309385967580425, 6.424515594957451, 9.94133365886321, 11.92910039063603, 8.870997726370152, 6.424515594957451, 2.44898213141181, -2.902697531053476, -3.8201283303332394, -6.266610461745941, -6.113705328532648, -6.5724207281725295, -5.9608001953193535, -4.890464262826296, -4.431748863186415, -4.278843729973121, -3.5143180639066514, -3.3614129306933576, -2.1381718649870067, 0.919930799278871, 0.15540513321240157, 0.919930799278871, -0.6091205328540679, -1.2207410657072433, -1.2207410657072433, -1.3736461989205373, 1.0728359324921648, 1.8373615985586342, 2.6018872646251037, 0.46121539963898933, 0.7670256660655771, -2.1381718649870067, -5.502084795679472, -9.018902859585232, -11.31247985778464, -12.841531189917578, -15.746728720970163, -14.370582522050517, -13.30024658955746, -11.006669591358051, -9.630523392438407, -4.125938596759827, -1.832361598560419, -1.0678359324939495, 1.6844564653453404, 2.6018872646251037, 3.9780334635447487, 2.9076975310516913, 4.43674886318463, 4.43674886318463, 3.2135077974782793, 0.46121539963898933, -0.1504051332141862, -4.125938596759827, -8.101472060305468, -7.336946394238999, -8.713092593158644, -4.584653996399709, -3.973033463546533, -3.8201283303332394, -1.0678359324939495, -2.7497923978401824, -1.0678359324939495, 1.5315513321320464, 1.8373615985586342, 3.2135077974782793, 5.354179662464394, 3.366412930691573, 4.589653996397924, 3.519318063904867, 3.519318063904867, 5.354179662464394, 4.283843729971337, 4.1309385967580425, 0.919930799278871, 0.0024999999991076978, -2.7497923978401824, -5.349179662466178, -4.737559129613002, -4.737559129613002, -2.902697531053476, -0.6091205328540679, 1.0728359324921648, 3.0606026642649855, 5.965800195317569, 7.18904126102392, 10.552954191716385, 9.329713126010034, 8.870997726370152, 8.870997726370152, 3.2135077974782793, 5.507084795677687, 4.1309385967580425, 2.143171864985222, 3.6722231971181607, 1.5315513321320464, -0.30331026642748005, 0.6141205328522832, 0.6141205328522832, 0.15540513321240157, 2.6018872646251037, 4.1309385967580425, 7.8006617938770955, 9.176807992796741, 12.6936260567025, 12.234910657062619, 10.247143925289798, 12.387815790275912, 9.023902859583446, 8.259377193516977, 6.730325861384038, 5.659989928890981, 2.9076975310516913, 1.9902667317719283, 1.5315513321320464, -0.7620256660673617, -1.9852667317737127, -2.1381718649870067, -0.45621539964077396, -0.9149307992806556, 2.7547923978383975, 1.6844564653453404, 2.143171864985222, 2.296076998198516, 1.3786461989187526, 3.0606026642649855, 0.0024999999991076978, 3.519318063904867, 2.44898213141181, 2.296076998198516, 2.44898213141181, 0.3083102664256955, -1.526551332133831, -5.043369396039591, -2.7497923978401824, -2.7497923978401824, -1.9852667317737127, -1.9852667317737127, -0.30331026642748005, -2.596887264626888, -2.596887264626888, -0.30331026642748005, -0.9149307992806556, -0.30331026642748005, -1.0678359324939495, 0.46121539963898933, 0.3083102664256955, 2.143171864985222, 3.825128330331455, 2.7547923978383975, 1.0728359324921648, -2.596887264626888, -5.349179662466178, -7.184041261025705, -7.642756660665587]\",\n          \"[10.400049058503091, 3.0606026642649855, 6.271610461744157, 4.1309385967580425, 0.0024999999991076978, 0.3083102664256955, 4.589653996397924, 1.3786461989187526, 2.7547923978383975, 6.883230994597333, 4.43674886318463, 8.41228232673027, 5.659989928890981, 6.730325861384038, 6.271610461744157, 6.271610461744157, 8.106472060303684, 8.106472060303684, 11.623290124209444, 11.470384990996148, 13.916867122408851, 12.540720923489205, 9.94133365886321, 8.565187459943566, 5.659989928890981, -0.30331026642748005, 1.2257410657054588, -2.596887264626888, -9.7834285256517, -5.654989928892766, -9.936333658864994, -5.9608001953193535, 0.7670256660655771, 5.354179662464394, 8.870997726370152, 12.082005523849324, 10.400049058503091, 5.2012745292511, 3.0606026642649855, -3.2085077974800638, -1.679456465347125, -5.9608001953193535, -5.502084795679472, -5.9608001953193535, -7.489851527452292, -4.278843729973121, -8.101472060305468, -4.431748863186415, -4.737559129613002, -5.349179662466178, -3.3614129306933576, -0.6091205328540679, -1.0678359324939495, -1.0678359324939495, -1.832361598560419, -3.3614129306933576, -0.7620256660673617, 0.6141205328522832, 4.895464262824512, 5.2012745292511, 5.659989928890981, -0.1504051332141862, -0.1504051332141862, -0.1504051332141862, -4.278843729973121, 1.3786461989187526, 1.0728359324921648, -3.6672231971199456, 5.048369396037806, 6.424515594957451, -0.45621539964077396, 10.094238792076505, 4.589653996397924, -0.45621539964077396, 3.0606026642649855, -2.596887264626888, -1.679456465347125, -0.6091205328540679, 2.9076975310516913, 7.036136127810626, 9.329713126010034, 10.552954191716385, 11.011669591356267, 4.43674886318463, 2.9076975310516913, -0.30331026642748005, -6.5724207281725295, -3.8201283303332394, -9.477618259225112, -4.890464262826296, -5.349179662466178, -7.0311361278124105, -5.80789506210606, -8.101472060305468, -8.56018745994535, -5.196274529252884, -0.30331026642748005, 0.919930799278871, 3.9780334635447487, -1.0678359324939495, 2.296076998198516, -0.1504051332141862, -0.45621539964077396, 8.870997726370152, 5.2012745292511, 7.341946394237214, 4.895464262824512, 6.883230994597333, 4.43674886318463, 1.2257410657054588, 0.15540513321240157, -4.584653996399709, -4.584653996399709, -6.5724207281725295, -4.431748863186415, -6.725325861385823, -7.489851527452292, -8.101472060305468, -6.419515594959235, -8.254377193518762, -10.395049058504876, -9.018902859585232, -18.346115985596157, -16.358349253823338, -13.911867122410635, -12.077005523851108, -8.101472060305468, -8.56018745994535, -6.266610461745941, -6.878230994599117, -4.278843729973121, 0.7670256660655771, -0.6091205328540679, 0.46121539963898933, -0.30331026642748005, -6.5724207281725295, 0.0024999999991076978, 2.9076975310516913, 5.2012745292511, 11.776195257422737, 11.164574724569562, 8.259377193516977, 7.494851527450508, 4.283843729971337, 3.6722231971181607, 3.519318063904867, -0.45621539964077396, 0.7670256660655771, -4.890464262826296, -0.7620256660673617, 0.0024999999991076978, -0.45621539964077396, 6.577420728170744, 1.6844564653453404, 5.048369396037806, 7.341946394237214, 6.118705328530863, 4.283843729971337, 2.6018872646251037, -0.45621539964077396, -2.7497923978401824, -2.902697531053476, -5.349179662466178, -3.3614129306933576, -6.5724207281725295, -4.278843729973121, -2.2910769982003005, -3.5143180639066514, -1.679456465347125, 3.0606026642649855, 3.0606026642649855, 4.895464262824512, 12.6936260567025, 6.883230994597333, 6.424515594957451, 3.519318063904867, -3.2085077974800638, -4.125938596759827, -6.878230994599117, -5.654989928892766, -2.1381718649870067, -3.05560266426677, -0.9149307992806556, 0.15540513321240157, -0.9149307992806556, -1.0678359324939495, -5.654989928892766, -3.5143180639066514, -6.266610461745941, -7.489851527452292, -2.596887264626888, -2.2910769982003005, -3.05560266426677, -4.278843729973121, -3.05560266426677, -3.973033463546533, -0.1504051332141862, 2.296076998198516, 2.9076975310516913, 0.7670256660655771, 2.296076998198516, 3.9780334635447487, 3.9780334635447487, 4.1309385967580425, -1.3736461989205373, -1.9852667317737127, -8.254377193518762, -2.596887264626888, 1.9902667317719283, -0.45621539964077396, 2.7547923978383975, -0.7620256660673617, -3.2085077974800638, -0.30331026642748005, 1.0728359324921648, -0.30331026642748005, 0.919930799278871, -4.278843729973121, -4.125938596759827, -1.0678359324939495, -0.6091205328540679, 5.354179662464394, 2.6018872646251037, 5.354179662464394, 3.2135077974782793, 3.0606026642649855, 4.895464262824512, 3.0606026642649855, 2.6018872646251037, -0.1504051332141862, 3.0606026642649855, 7.341946394237214, 6.730325861384038, 7.036136127810626, 1.9902667317719283, -7.336946394238999, -9.018902859585232, -7.79566179387888, -5.80789506210606, 0.3083102664256955, 3.6722231971181607, 0.7670256660655771, -1.3736461989205373, 1.8373615985586342, 6.271610461744157, 5.2012745292511, 8.71809259315686, 7.95356692709039, -0.7620256660673617, -1.0678359324939495, 0.46121539963898933, 0.7670256660655771, 0.919930799278871, 3.825128330331455, 5.2012745292511, 4.895464262824512, 10.552954191716385, 11.623290124209444, 4.589653996397924, -0.45621539964077396, -3.3614129306933576, -6.266610461745941, -3.2085077974800638, 2.44898213141181, 6.271610461744157, 2.9076975310516913, 7.494851527450508, 13.15234145634238, 12.082005523849324, 16.66915952024814, 13.611056855982262, 5.048369396037806, 4.895464262824512, 3.519318063904867, 4.283843729971337, 5.048369396037806, -2.4439821314135943, -1.0678359324939495, -4.431748863186415, -5.349179662466178, 2.143171864985222, -2.4439821314135943, -4.890464262826296, -5.196274529252884, -5.80789506210606, -3.2085077974800638, 1.3786461989187526, 6.577420728170744, 5.507084795677687, 2.9076975310516913, 2.7547923978383975, 2.44898213141181, 0.919930799278871, 7.341946394237214, 5.507084795677687, 3.9780334635447487, 5.354179662464394, -5.502084795679472, -9.018902859585232, -9.7834285256517, -16.511254387036633, -14.52348765526381, -10.547954191718171, -6.725325861385823, -2.902697531053476, -4.584653996399709, -3.973033463546533, -1.832361598560419, -3.2085077974800638, 0.7670256660655771, 8.565187459943566, 8.106472060303684, 6.883230994597333, 8.41228232673027, 4.895464262824512, -0.1504051332141862, -3.5143180639066514, -2.4439821314135943, -1.2207410657072433, -0.6091205328540679, 3.519318063904867, 6.118705328530863, 2.6018872646251037, 1.3786461989187526, 0.0024999999991076978, 0.0024999999991076978, -2.1381718649870067, -4.431748863186415, -8.56018745994535, -13.30024658955746, -14.217677388837224, -9.018902859585232, -5.502084795679472, -8.254377193518762, -7.489851527452292, -10.853764458144758, -10.395049058504876, -4.278843729973121, -2.902697531053476, 0.7670256660655771, 1.2257410657054588, -0.9149307992806556, 0.0024999999991076978, 3.0606026642649855, 4.1309385967580425, 5.659989928890981, 4.895464262824512, 0.919930799278871, -2.4439821314135943, -4.431748863186415, -4.431748863186415, -5.502084795679472, -4.278843729973121, -3.3614129306933576, -4.890464262826296, -7.489851527452292, -6.878230994599117, -4.584653996399709, -2.2910769982003005, 2.296076998198516, 13.916867122408851, 11.011669591356267, 7.95356692709039, 15.293013321328496, 5.2012745292511, 4.1309385967580425, 5.965800195317569, 1.6844564653453404, 1.3786461989187526, 0.919930799278871, 4.1309385967580425, 5.965800195317569, 7.95356692709039, 7.95356692709039, 3.0606026642649855, -3.6672231971199456, -2.7497923978401824, -10.395049058504876, -4.431748863186415, 2.143171864985222, 0.919930799278871, 10.400049058503091, 8.41228232673027, 7.647756660663802, 9.94133365886321, 2.296076998198516, 0.3083102664256955, 3.825128330331455, 0.6141205328522832, 10.400049058503091, 10.858764458142973, 9.329713126010034, 11.011669591356267, 0.15540513321240157, 4.43674886318463, 0.46121539963898933, 1.5315513321320464, 2.9076975310516913, -3.05560266426677, -3.6672231971199456, -10.089238792078289, -12.077005523851108, -9.324713126011819, -7.642756660665587, -4.278843729973121, 1.0728359324921648, 0.46121539963898933, 3.519318063904867, 0.0024999999991076978, -1.679456465347125, 0.6141205328522832, -8.407282326732055, -3.2085077974800638, -2.1381718649870067, -6.5724207281725295, 1.2257410657054588, -0.1504051332141862, -0.45621539964077396, 3.519318063904867, 1.2257410657054588, 4.283843729971337, 2.296076998198516, -9.171807992798525, -11.924100390637815, -16.511254387036633, -17.58159031952969, -9.324713126011819, -1.2207410657072433, 1.2257410657054588, 0.7670256660655771, 1.9902667317719283, 0.0024999999991076978, 2.44898213141181, 6.577420728170744, 2.7547923978383975, -0.1504051332141862, -3.8201283303332394, -8.56018745994535, -5.502084795679472, -5.502084795679472, -4.431748863186415, 2.296076998198516, 0.7670256660655771, 0.7670256660655771, 1.5315513321320464, 0.0024999999991076978, -0.9149307992806556, -2.902697531053476, -0.7620256660673617, 0.46121539963898933, -0.9149307992806556, 0.919930799278871, 3.519318063904867, -2.4439821314135943, 0.46121539963898933, 4.1309385967580425, -0.30331026642748005, 1.9902667317719283, -1.3736461989205373, -5.9608001953193535, -3.05560266426677, -3.6672231971199456, -0.30331026642748005, 3.9780334635447487, 0.919930799278871, 0.15540513321240157, 0.0024999999991076978, -4.584653996399709, -5.043369396039591, -8.254377193518762, -13.147341456344167, -13.147341456344167, -11.771195257424521, -3.973033463546533, 0.6141205328522832, 6.424515594957451, 4.742559129611218, 0.919930799278871, 4.1309385967580425, 1.6844564653453404, 9.176807992796741, 17.43368518631461, 11.623290124209444, 10.552954191716385, 7.95356692709039, 1.3786461989187526, 6.271610461744157, 4.742559129611218, 5.2012745292511, 5.048369396037806, 0.7670256660655771, 2.6018872646251037, -1.9852667317737127, -1.679456465347125, -0.30331026642748005, -3.973033463546533, -0.1504051332141862, 4.43674886318463, 0.15540513321240157, 4.742559129611218]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Shannon_Entropy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5943260218124136,\n        \"min\": -0.0,\n        \"max\": 8.841254959649039,\n        \"num_unique_values\": 13264,\n        \"samples\": [\n          6.755670965016566,\n          6.8889209136275,\n          6.970855961568139\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Approximate_Entropy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23697039662263977,\n        \"min\": 0.0,\n        \"max\": 1.428654753756505,\n        \"num_unique_values\": 13274,\n        \"samples\": [\n          0.9032839937982842,\n          0.8654524890829234,\n          0.9903966383552762\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sample_Entropy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.37063829106005464,\n        \"min\": -0.0,\n        \"max\": 2.2865633884627803,\n        \"num_unique_values\": 13192,\n        \"samples\": [\n          0.4477007939179926,\n          1.210780182553961,\n          1.19554980813181\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tsallis_Entropy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.046933577151714576,\n        \"min\": 0.0,\n        \"max\": 0.997736,\n        \"num_unique_values\": 1970,\n        \"samples\": [\n          0.984008,\n          0.989472,\n          0.995816\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spectral_Entropy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11937387793272723,\n        \"min\": -0.0,\n        \"max\": 0.9290783781243442,\n        \"num_unique_values\": 13274,\n        \"samples\": [\n          0.6715155349876026,\n          0.4280289411877838,\n          0.6182627296947785\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-b78a4481-f246-4db5-95c1-4f3bfc7e543c\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject_ID</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Signal_Values</th>\n",
       "      <th>Shannon_Entropy</th>\n",
       "      <th>Approximate_Entropy</th>\n",
       "      <th>Sample_Entropy</th>\n",
       "      <th>Tsallis_Entropy</th>\n",
       "      <th>Spectral_Entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>1</td>\n",
       "      <td>[-3.5143180639066514, -1.526551332133831, -0.3...</td>\n",
       "      <td>7.296329</td>\n",
       "      <td>0.949664</td>\n",
       "      <td>0.972611</td>\n",
       "      <td>0.992424</td>\n",
       "      <td>0.569092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>2</td>\n",
       "      <td>[2.44898213141181, 4.742559129611218, 7.036136...</td>\n",
       "      <td>7.002282</td>\n",
       "      <td>0.797395</td>\n",
       "      <td>0.767046</td>\n",
       "      <td>0.990336</td>\n",
       "      <td>0.554492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>3</td>\n",
       "      <td>[-4.431748863186415, -4.125938596759827, -5.04...</td>\n",
       "      <td>7.636261</td>\n",
       "      <td>0.679709</td>\n",
       "      <td>0.634840</td>\n",
       "      <td>0.993984</td>\n",
       "      <td>0.409134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>4</td>\n",
       "      <td>[-3.6672231971199456, -3.8201283303332394, -6....</td>\n",
       "      <td>7.467782</td>\n",
       "      <td>0.813597</td>\n",
       "      <td>0.758204</td>\n",
       "      <td>0.993400</td>\n",
       "      <td>0.479331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Fp1</td>\n",
       "      <td>5</td>\n",
       "      <td>[3.2135077974782793, 3.6722231971181607, 2.754...</td>\n",
       "      <td>7.209213</td>\n",
       "      <td>0.756629</td>\n",
       "      <td>0.759479</td>\n",
       "      <td>0.991824</td>\n",
       "      <td>0.588887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13295</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>46</td>\n",
       "      <td>[-13.597209280679062, -15.56500930814572, 3.57...</td>\n",
       "      <td>7.631395</td>\n",
       "      <td>0.687565</td>\n",
       "      <td>0.747175</td>\n",
       "      <td>0.994152</td>\n",
       "      <td>0.402272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13296</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>47</td>\n",
       "      <td>[4.291881878108741, -14.133882015442696, -11.4...</td>\n",
       "      <td>7.537039</td>\n",
       "      <td>0.486753</td>\n",
       "      <td>0.480683</td>\n",
       "      <td>0.993840</td>\n",
       "      <td>0.345263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13297</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>48</td>\n",
       "      <td>[-3.579318231757892, 10.73195469527235, 8.0485...</td>\n",
       "      <td>7.553090</td>\n",
       "      <td>0.553027</td>\n",
       "      <td>0.561509</td>\n",
       "      <td>0.993832</td>\n",
       "      <td>0.350390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13298</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>49</td>\n",
       "      <td>[-10.019391048921502, 8.764154667805693, 12.69...</td>\n",
       "      <td>7.845748</td>\n",
       "      <td>0.812216</td>\n",
       "      <td>0.822885</td>\n",
       "      <td>0.994984</td>\n",
       "      <td>0.389353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13299</th>\n",
       "      <td>14</td>\n",
       "      <td>Pz</td>\n",
       "      <td>50</td>\n",
       "      <td>[15.025336573381423, 8.406372844629937, -10.01...</td>\n",
       "      <td>7.579523</td>\n",
       "      <td>0.528375</td>\n",
       "      <td>0.494555</td>\n",
       "      <td>0.994032</td>\n",
       "      <td>0.315332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13300 rows × 9 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b78a4481-f246-4db5-95c1-4f3bfc7e543c')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-b78a4481-f246-4db5-95c1-4f3bfc7e543c button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-b78a4481-f246-4db5-95c1-4f3bfc7e543c');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-cf619036-7228-43c6-8db3-9d9e99997084\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cf619036-7228-43c6-8db3-9d9e99997084')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-cf619036-7228-43c6-8db3-9d9e99997084 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_93c9dc0c-1f6b-4b7b-8aa4-219a1d18bfd4\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_93c9dc0c-1f6b-4b7b-8aa4-219a1d18bfd4 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('data');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "       Subject_ID Channel  Epoch  \\\n",
       "0               1     Fp1      1   \n",
       "1               1     Fp1      2   \n",
       "2               1     Fp1      3   \n",
       "3               1     Fp1      4   \n",
       "4               1     Fp1      5   \n",
       "...           ...     ...    ...   \n",
       "13295          14      Pz     46   \n",
       "13296          14      Pz     47   \n",
       "13297          14      Pz     48   \n",
       "13298          14      Pz     49   \n",
       "13299          14      Pz     50   \n",
       "\n",
       "                                           Signal_Values  Shannon_Entropy  \\\n",
       "0      [-3.5143180639066514, -1.526551332133831, -0.3...         7.296329   \n",
       "1      [2.44898213141181, 4.742559129611218, 7.036136...         7.002282   \n",
       "2      [-4.431748863186415, -4.125938596759827, -5.04...         7.636261   \n",
       "3      [-3.6672231971199456, -3.8201283303332394, -6....         7.467782   \n",
       "4      [3.2135077974782793, 3.6722231971181607, 2.754...         7.209213   \n",
       "...                                                  ...              ...   \n",
       "13295  [-13.597209280679062, -15.56500930814572, 3.57...         7.631395   \n",
       "13296  [4.291881878108741, -14.133882015442696, -11.4...         7.537039   \n",
       "13297  [-3.579318231757892, 10.73195469527235, 8.0485...         7.553090   \n",
       "13298  [-10.019391048921502, 8.764154667805693, 12.69...         7.845748   \n",
       "13299  [15.025336573381423, 8.406372844629937, -10.01...         7.579523   \n",
       "\n",
       "       Approximate_Entropy  Sample_Entropy  Tsallis_Entropy  Spectral_Entropy  \n",
       "0                 0.949664        0.972611         0.992424          0.569092  \n",
       "1                 0.797395        0.767046         0.990336          0.554492  \n",
       "2                 0.679709        0.634840         0.993984          0.409134  \n",
       "3                 0.813597        0.758204         0.993400          0.479331  \n",
       "4                 0.756629        0.759479         0.991824          0.588887  \n",
       "...                    ...             ...              ...               ...  \n",
       "13295             0.687565        0.747175         0.994152          0.402272  \n",
       "13296             0.486753        0.480683         0.993840          0.345263  \n",
       "13297             0.553027        0.561509         0.993832          0.350390  \n",
       "13298             0.812216        0.822885         0.994984          0.389353  \n",
       "13299             0.528375        0.494555         0.994032          0.315332  \n",
       "\n",
       "[13300 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = 'data_with_unentropies.csv'  # Replace with your actual file name\n",
    "data = pd.read_csv(input_file)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "XwR07h8OWuz_",
    "outputId": "5ddf9986-72e7-4c2d-c217-63a30a56b8ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Fp1_Shannon_Entropy  Fp1_Approximate_Entropy  Fp1_Sample_Entropy  \\\n",
      "0               7.296329                 0.949664            0.972611   \n",
      "1               7.002282                 0.797395            0.767046   \n",
      "2               7.636261                 0.679709            0.634840   \n",
      "3               7.467782                 0.813597            0.758204   \n",
      "4               7.209213                 0.756629            0.759479   \n",
      "..                   ...                      ...                 ...   \n",
      "695             7.510716                 0.482028            0.408978   \n",
      "696             7.784220                 0.780040            0.858951   \n",
      "697             7.738418                 0.677618            0.705295   \n",
      "698             7.871188                 0.799784            0.882716   \n",
      "699             7.721516                 0.818647            0.946215   \n",
      "\n",
      "     Fp1_Tsallis_Entropy  Fp1_Spectral_Entropy  Fp2_Shannon_Entropy  \\\n",
      "0               0.992424              0.569092             6.825361   \n",
      "1               0.990336              0.554492             7.011631   \n",
      "2               0.993984              0.409134             7.244994   \n",
      "3               0.993400              0.479331             7.437131   \n",
      "4               0.991824              0.588887             7.218179   \n",
      "..                   ...                   ...                  ...   \n",
      "695             0.993784              0.291532             7.627162   \n",
      "696             0.994776              0.417158             7.937948   \n",
      "697             0.994584              0.431100             7.685244   \n",
      "698             0.995048              0.449326             8.237471   \n",
      "699             0.994488              0.415117             7.675974   \n",
      "\n",
      "     Fp2_Approximate_Entropy  Fp2_Sample_Entropy  Fp2_Tsallis_Entropy  \\\n",
      "0                   0.796101            0.786664             0.989024   \n",
      "1                   0.779591            0.744922             0.990728   \n",
      "2                   0.716808            0.734899             0.992080   \n",
      "3                   0.719631            0.628802             0.993064   \n",
      "4                   0.764514            0.700932             0.991648   \n",
      "..                       ...                 ...                  ...   \n",
      "695                 0.895103            0.967149             0.994088   \n",
      "696                 0.761860            0.765095             0.995416   \n",
      "697                 0.591125            0.539608             0.994432   \n",
      "698                 1.044529            1.186838             0.996288   \n",
      "699                 0.866616            0.945819             0.994344   \n",
      "\n",
      "     Fp2_Spectral_Entropy  ...  Cz_Shannon_Entropy  Cz_Approximate_Entropy  \\\n",
      "0                0.581076  ...            7.147614                0.761899   \n",
      "1                0.600691  ...            7.078138                0.826785   \n",
      "2                0.560941  ...            7.094067                0.791701   \n",
      "3                0.449552  ...            6.660928                0.919787   \n",
      "4                0.558721  ...            7.430903                0.744301   \n",
      "..                    ...  ...                 ...                     ...   \n",
      "695              0.492749  ...            7.516283                0.524176   \n",
      "696              0.426490  ...            7.553090                0.517805   \n",
      "697              0.364124  ...            7.519659                0.682121   \n",
      "698              0.337011  ...            7.628741                0.695246   \n",
      "699              0.405553  ...            7.554787                0.544605   \n",
      "\n",
      "     Cz_Sample_Entropy  Cz_Tsallis_Entropy  Cz_Spectral_Entropy  \\\n",
      "0             0.765806            0.991480             0.532502   \n",
      "1             0.867162            0.991136             0.581750   \n",
      "2             0.836357            0.991232             0.588120   \n",
      "3             0.881973            0.987680             0.600047   \n",
      "4             0.721152            0.993280             0.470324   \n",
      "..                 ...                 ...                  ...   \n",
      "695           0.495397            0.993728             0.315409   \n",
      "696           0.456241            0.993896             0.321099   \n",
      "697           0.721160            0.993704             0.374417   \n",
      "698           0.736045            0.994304             0.399745   \n",
      "699           0.546518            0.993912             0.374414   \n",
      "\n",
      "     Pz_Shannon_Entropy  Pz_Approximate_Entropy  Pz_Sample_Entropy  \\\n",
      "0              6.613093                0.790395           0.784157   \n",
      "1              6.599002                0.878277           0.928236   \n",
      "2              6.817391                0.833766           0.846984   \n",
      "3              7.280130                0.750863           0.763493   \n",
      "4              5.802963                1.070876           1.079710   \n",
      "..                  ...                     ...                ...   \n",
      "695            7.631395                0.687565           0.747175   \n",
      "696            7.537039                0.486753           0.480683   \n",
      "697            7.553090                0.553027           0.561509   \n",
      "698            7.845748                0.812216           0.822885   \n",
      "699            7.579523                0.528375           0.494555   \n",
      "\n",
      "     Pz_Tsallis_Entropy  Pz_Spectral_Entropy  \n",
      "0              0.986504             0.581641  \n",
      "1              0.988016             0.610374  \n",
      "2              0.989384             0.581838  \n",
      "3              0.992272             0.520361  \n",
      "4              0.976232             0.672494  \n",
      "..                  ...                  ...  \n",
      "695            0.994152             0.402272  \n",
      "696            0.993840             0.345263  \n",
      "697            0.993832             0.350390  \n",
      "698            0.994984             0.389353  \n",
      "699            0.994032             0.315332  \n",
      "\n",
      "[700 rows x 95 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your data is loaded into a DataFrame called 'df'\n",
    "# Example: df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# List of entropy measures\n",
    "entropy_measures = ['Shannon_Entropy', 'Approximate_Entropy', 'Sample_Entropy', 'Tsallis_Entropy', 'Spectral_Entropy']\n",
    "\n",
    "# Initialize an empty list to store the feature vectors\n",
    "feature_vectors = []\n",
    "df = data\n",
    "# Group by Subject_ID and Epoch\n",
    "for (subject_id, epoch), group in df.groupby(['Subject_ID', 'Epoch']):\n",
    "    # Initialize a list for the feature vector\n",
    "    feature_vector = []\n",
    "\n",
    "    # Loop through each channel (19 channels)\n",
    "    for channel in group['Channel'].unique():\n",
    "        # Extract the entropy measures for the current channel\n",
    "        channel_data = group[group['Channel'] == channel]\n",
    "\n",
    "        # Append the entropy measures to the feature vector\n",
    "        for entropy in entropy_measures:\n",
    "            feature_vector.append(channel_data[entropy].values[0])\n",
    "\n",
    "    # Append the feature vector for the current subject and epoch\n",
    "    feature_vectors.append(feature_vector)\n",
    "\n",
    "# Convert the feature vectors into a DataFrame\n",
    "feature_df = pd.DataFrame(feature_vectors, columns=[f\"{channel}_{entropy}\" for channel in df['Channel'].unique() for entropy in entropy_measures])\n",
    "\n",
    "# Display the resulting feature DataFrame\n",
    "print(feature_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "DlCFqTmPaKrg"
   },
   "outputs": [],
   "source": [
    "# Save the resulting feature DataFrame to a CSV file\n",
    "feature_df.to_csv('feature_vectors.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Y3jrumqIbcay",
    "outputId": "c0ca9648-0463-43d2-9ede-e7ab1401ea9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Fp1_Shannon_Entropy  Fp1_Approximate_Entropy  Fp1_Sample_Entropy  \\\n",
      "0               7.511884                 0.907534            0.929651   \n",
      "1               7.213492                 1.083219            1.117977   \n",
      "2               6.782381                 1.128291            1.232144   \n",
      "3               7.689071                 0.857106            0.902307   \n",
      "4               8.157974                 0.559002            0.481663   \n",
      "..                   ...                      ...                 ...   \n",
      "695             7.571292                 0.931838            0.929213   \n",
      "696             7.839090                 0.694633            0.640583   \n",
      "697             7.734826                 0.810653            0.790117   \n",
      "698             7.295846                 1.146391            1.259092   \n",
      "699             7.547497                 0.887800            0.919679   \n",
      "\n",
      "     Fp1_Tsallis_Entropy  Fp1_Spectral_Entropy  Fp2_Shannon_Entropy  \\\n",
      "0               0.993672              0.489428             7.821819   \n",
      "1               0.991832              0.680598             7.397955   \n",
      "2               0.989224              0.585859             7.234885   \n",
      "3               0.994496              0.431208             7.651069   \n",
      "4               0.995984              0.310777             7.622632   \n",
      "..                   ...                   ...                  ...   \n",
      "695             0.993800              0.463633             7.268673   \n",
      "696             0.994720              0.455591             7.685466   \n",
      "697             0.994336              0.505429             7.628518   \n",
      "698             0.992184              0.651997             7.391557   \n",
      "699             0.993744              0.619887             6.965214   \n",
      "\n",
      "     Fp2_Approximate_Entropy  Fp2_Sample_Entropy  Fp2_Tsallis_Entropy  \\\n",
      "0                   0.956776            0.993801             0.994936   \n",
      "1                   1.194553            1.305047             0.993032   \n",
      "2                   1.110046            1.249609             0.991776   \n",
      "3                   1.168422            1.286485             0.994200   \n",
      "4                   0.881640            0.886875             0.994168   \n",
      "..                       ...                 ...                  ...   \n",
      "695                 0.914443            0.900827             0.991928   \n",
      "696                 0.743685            0.684650             0.994032   \n",
      "697                 0.901483            0.924417             0.994104   \n",
      "698                 1.059083            1.119217             0.993080   \n",
      "699                 1.197068            1.345442             0.990520   \n",
      "\n",
      "     Fp2_Spectral_Entropy  ...  Cz_Shannon_Entropy  Cz_Approximate_Entropy  \\\n",
      "0                0.474091  ...            6.837864                0.983005   \n",
      "1                0.635770  ...            6.910854                1.016661   \n",
      "2                0.583017  ...            6.523416                1.110548   \n",
      "3                0.502972  ...            6.692182                0.993231   \n",
      "4                0.439784  ...            6.962014                0.911128   \n",
      "..                    ...  ...                 ...                     ...   \n",
      "695              0.552438  ...            7.472955                0.887429   \n",
      "696              0.642256  ...            7.083918                0.941313   \n",
      "697              0.514857  ...            7.275692                0.912124   \n",
      "698              0.586145  ...            6.840892                0.978579   \n",
      "699              0.675082  ...            6.973866                0.924632   \n",
      "\n",
      "     Cz_Sample_Entropy  Cz_Tsallis_Entropy  Cz_Spectral_Entropy  \\\n",
      "0             0.973945            0.989160             0.509111   \n",
      "1             1.056811            0.990448             0.460522   \n",
      "2             1.181880            0.986952             0.600978   \n",
      "3             0.961031            0.988144             0.551663   \n",
      "4             0.944181            0.990456             0.434872   \n",
      "..                 ...                 ...                  ...   \n",
      "695           0.878300            0.993544             0.520622   \n",
      "696           0.981847            0.991136             0.627383   \n",
      "697           0.951498            0.992080             0.609938   \n",
      "698           1.008879            0.989432             0.644174   \n",
      "699           0.988122            0.990448             0.626995   \n",
      "\n",
      "     Pz_Shannon_Entropy  Pz_Approximate_Entropy  Pz_Sample_Entropy  \\\n",
      "0              6.434723                1.027496           0.956847   \n",
      "1              6.737305                1.054528           1.124126   \n",
      "2              6.514214                1.061305           1.160770   \n",
      "3              6.795213                0.988096           0.959889   \n",
      "4              6.705653                1.143597           1.195229   \n",
      "..                  ...                     ...                ...   \n",
      "695            7.090620                0.872365           0.902909   \n",
      "696            6.800197                1.139629           1.256508   \n",
      "697            7.200287                0.867842           0.911789   \n",
      "698            7.167406                0.992832           1.059401   \n",
      "699            6.864494                1.089605           1.220319   \n",
      "\n",
      "     Pz_Tsallis_Entropy  Pz_Spectral_Entropy  \n",
      "0              0.983752             0.611563  \n",
      "1              0.989064             0.497259  \n",
      "2              0.986232             0.687580  \n",
      "3              0.989048             0.604050  \n",
      "4              0.988656             0.538834  \n",
      "..                  ...                  ...  \n",
      "695            0.991288             0.652485  \n",
      "696            0.989040             0.654079  \n",
      "697            0.991680             0.587804  \n",
      "698            0.991784             0.498251  \n",
      "699            0.989848             0.645328  \n",
      "\n",
      "[700 rows x 95 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your data is loaded into a DataFrame called 'df'\n",
    "# Example: df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# List of entropy measures\n",
    "entropy_measures = ['Shannon_Entropy', 'Approximate_Entropy', 'Sample_Entropy', 'Tsallis_Entropy', 'Spectral_Entropy']\n",
    "\n",
    "# Initialize an empty list to store the feature vectors\n",
    "feature_vectors = []\n",
    "df = hdata\n",
    "# Group by Subject_ID and Epoch\n",
    "for (subject_id, epoch), group in df.groupby(['Subject_ID', 'Epoch']):\n",
    "    # Initialize a list for the feature vector\n",
    "    feature_vector = []\n",
    "\n",
    "    # Loop through each channel (19 channels)\n",
    "    for channel in group['Channel'].unique():\n",
    "        # Extract the entropy measures for the current channel\n",
    "        channel_data = group[group['Channel'] == channel]\n",
    "\n",
    "        # Append the entropy measures to the feature vector\n",
    "        for entropy in entropy_measures:\n",
    "            feature_vector.append(channel_data[entropy].values[0])\n",
    "\n",
    "    # Append the feature vector for the current subject and epoch\n",
    "    feature_vectors.append(feature_vector)\n",
    "\n",
    "# Convert the feature vectors into a DataFrame\n",
    "feature_df = pd.DataFrame(feature_vectors, columns=[f\"{channel}_{entropy}\" for channel in df['Channel'].unique() for entropy in entropy_measures])\n",
    "\n",
    "# Display the resulting feature DataFrame\n",
    "print(feature_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "hIO0BBukb0Pf"
   },
   "outputs": [],
   "source": [
    "# Save the resulting feature DataFrame to a CSV file\n",
    "feature_df.to_csv('hfeature_vectors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "iTwzz8kMcPYO",
    "outputId": "16f5581f-f2ee-4082-d1a1-d57a66a9dcbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files combined, shuffled, and saved as 'shuffled_combined_features.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files\n",
    "feature_df = pd.read_csv('feature_vectors.csv')\n",
    "hfeature_df = pd.read_csv('hfeature_vectors.csv')\n",
    "\n",
    "# Add a Label column\n",
    "feature_df['Label'] = 1\n",
    "hfeature_df['Label'] = 0\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "combined_df = pd.concat([feature_df, hfeature_df], ignore_index=True)\n",
    "\n",
    "# Shuffle the combined DataFrame\n",
    "shuffled_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save the shuffled DataFrame to a new CSV file\n",
    "shuffled_df.to_csv('shuffled_combined_features.csv', index=False)\n",
    "\n",
    "# Print a success message\n",
    "print(\"Files combined, shuffled, and saved as 'shuffled_combined_features.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "cnARppWsdEyZ",
    "outputId": "7e5e1c23-ef37-4ec9-da6a-4fa7a1a1b8dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       140\n",
      "           1       0.92      0.86      0.89       140\n",
      "\n",
      "    accuracy                           0.89       280\n",
      "   macro avg       0.89      0.89      0.89       280\n",
      "weighted avg       0.89      0.89      0.89       280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the shuffled dataset\n",
    "data = pd.read_csv('shuffled_combined_features.csv')\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X = data.drop(columns=['Label'])  # Drop the label column to get features\n",
    "y = data['Label']  # The label column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm_model = SVC(kernel='linear', random_state=42)  # You can change the kernel to 'rbf', 'poly', etc.\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "-rSQasxzdWk8",
    "outputId": "eca71ef9-6b46-4bac-bceb-065f9ad35552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91       140\n",
      "           1       0.93      0.89      0.91       140\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.91      0.91      0.91       280\n",
      "weighted avg       0.91      0.91      0.91       280\n",
      "\n",
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       140\n",
      "           1       0.89      0.91      0.90       140\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.90      0.90      0.90       280\n",
      "weighted avg       0.90      0.90      0.90       280\n",
      "\n",
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91       140\n",
      "           1       0.90      0.92      0.91       140\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.91      0.91      0.91       280\n",
      "weighted avg       0.91      0.91      0.91       280\n",
      "\n",
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       140\n",
      "           1       0.93      0.89      0.91       140\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.92      0.91      0.91       280\n",
      "weighted avg       0.92      0.91      0.91       280\n",
      "\n",
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       140\n",
      "           1       0.90      0.88      0.89       140\n",
      "\n",
      "    accuracy                           0.89       280\n",
      "   macro avg       0.89      0.89      0.89       280\n",
      "weighted avg       0.89      0.89      0.89       280\n",
      "\n",
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       140\n",
      "           1       0.89      0.94      0.91       140\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.91      0.91      0.91       280\n",
      "weighted avg       0.91      0.91      0.91       280\n",
      "\n",
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       140\n",
      "           1       0.91      0.91      0.91       140\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.91      0.91      0.91       280\n",
      "weighted avg       0.91      0.91      0.91       280\n",
      "\n",
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       140\n",
      "           1       0.92      0.89      0.91       140\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.91      0.91      0.91       280\n",
      "weighted avg       0.91      0.91      0.91       280\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       140\n",
      "           1       0.95      0.93      0.94       140\n",
      "\n",
      "    accuracy                           0.94       280\n",
      "   macro avg       0.94      0.94      0.94       280\n",
      "weighted avg       0.94      0.94      0.94       280\n",
      "\n",
      "Accuracy: 0.93\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92       140\n",
      "           1       0.89      0.96      0.93       140\n",
      "\n",
      "    accuracy                           0.93       280\n",
      "   macro avg       0.93      0.93      0.92       280\n",
      "weighted avg       0.93      0.93      0.92       280\n",
      "\n",
      "Accuracy: 0.88\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       140\n",
      "           1       0.88      0.89      0.88       140\n",
      "\n",
      "    accuracy                           0.88       280\n",
      "   macro avg       0.88      0.88      0.88       280\n",
      "weighted avg       0.88      0.88      0.88       280\n",
      "\n",
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90       140\n",
      "           1       0.91      0.90      0.90       140\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.90      0.90      0.90       280\n",
      "weighted avg       0.90      0.90      0.90       280\n",
      "\n",
      "Accuracy: 0.92\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       140\n",
      "           1       0.93      0.90      0.92       140\n",
      "\n",
      "    accuracy                           0.92       280\n",
      "   macro avg       0.92      0.92      0.92       280\n",
      "weighted avg       0.92      0.92      0.92       280\n",
      "\n",
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90       140\n",
      "           1       0.90      0.89      0.90       140\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.90      0.90      0.90       280\n",
      "weighted avg       0.90      0.90      0.90       280\n",
      "\n",
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89       140\n",
      "           1       0.88      0.90      0.89       140\n",
      "\n",
      "    accuracy                           0.89       280\n",
      "   macro avg       0.89      0.89      0.89       280\n",
      "weighted avg       0.89      0.89      0.89       280\n",
      "\n",
      "Accuracy: 0.93\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       140\n",
      "           1       0.95      0.91      0.93       140\n",
      "\n",
      "    accuracy                           0.93       280\n",
      "   macro avg       0.93      0.93      0.93       280\n",
      "weighted avg       0.93      0.93      0.93       280\n",
      "\n",
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       140\n",
      "           1       0.90      0.88      0.89       140\n",
      "\n",
      "    accuracy                           0.89       280\n",
      "   macro avg       0.89      0.89      0.89       280\n",
      "weighted avg       0.89      0.89      0.89       280\n",
      "\n",
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       140\n",
      "           1       0.90      0.91      0.90       140\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.90      0.90      0.90       280\n",
      "weighted avg       0.90      0.90      0.90       280\n",
      "\n",
      "Accuracy: 0.88\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89       140\n",
      "           1       0.90      0.86      0.88       140\n",
      "\n",
      "    accuracy                           0.88       280\n",
      "   macro avg       0.88      0.88      0.88       280\n",
      "weighted avg       0.88      0.88      0.88       280\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       140\n",
      "           1       0.94      0.94      0.94       140\n",
      "\n",
      "    accuracy                           0.94       280\n",
      "   macro avg       0.94      0.94      0.94       280\n",
      "weighted avg       0.94      0.94      0.94       280\n",
      "\n",
      "Accuracy: 0.92\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92       140\n",
      "           1       0.90      0.94      0.92       140\n",
      "\n",
      "    accuracy                           0.92       280\n",
      "   macro avg       0.92      0.92      0.92       280\n",
      "weighted avg       0.92      0.92      0.92       280\n",
      "\n",
      "Accuracy: 0.88\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88       140\n",
      "           1       0.87      0.90      0.88       140\n",
      "\n",
      "    accuracy                           0.88       280\n",
      "   macro avg       0.88      0.88      0.88       280\n",
      "weighted avg       0.88      0.88      0.88       280\n",
      "\n",
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91       140\n",
      "           1       0.95      0.87      0.91       140\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.91      0.91      0.91       280\n",
      "weighted avg       0.91      0.91      0.91       280\n",
      "\n",
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91       140\n",
      "           1       0.91      0.90      0.91       140\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.91      0.91      0.91       280\n",
      "weighted avg       0.91      0.91      0.91       280\n",
      "\n",
      "Accuracy: 0.93\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       140\n",
      "           1       0.92      0.94      0.93       140\n",
      "\n",
      "    accuracy                           0.93       280\n",
      "   macro avg       0.93      0.93      0.92       280\n",
      "weighted avg       0.93      0.93      0.92       280\n",
      "\n",
      "Accuracy: 0.88\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       140\n",
      "           1       0.90      0.86      0.88       140\n",
      "\n",
      "    accuracy                           0.88       280\n",
      "   macro avg       0.88      0.88      0.88       280\n",
      "weighted avg       0.88      0.88      0.88       280\n",
      "\n",
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       140\n",
      "           1       0.91      0.89      0.90       140\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.90      0.90      0.90       280\n",
      "weighted avg       0.90      0.90      0.90       280\n",
      "\n",
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89       140\n",
      "           1       0.88      0.91      0.89       140\n",
      "\n",
      "    accuracy                           0.89       280\n",
      "   macro avg       0.89      0.89      0.89       280\n",
      "weighted avg       0.89      0.89      0.89       280\n",
      "\n",
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.85      0.89       140\n",
      "           1       0.86      0.94      0.90       140\n",
      "\n",
      "    accuracy                           0.89       280\n",
      "   macro avg       0.90      0.89      0.89       280\n",
      "weighted avg       0.90      0.89      0.89       280\n",
      "\n",
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       140\n",
      "           1       0.90      0.88      0.89       140\n",
      "\n",
      "    accuracy                           0.89       280\n",
      "   macro avg       0.89      0.89      0.89       280\n",
      "weighted avg       0.89      0.89      0.89       280\n",
      "\n",
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       140\n",
      "           1       0.91      0.91      0.91       140\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.91      0.91      0.91       280\n",
      "weighted avg       0.91      0.91      0.91       280\n",
      "\n",
      "Accuracy: 0.93\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       140\n",
      "           1       0.93      0.91      0.92       140\n",
      "\n",
      "    accuracy                           0.93       280\n",
      "   macro avg       0.93      0.93      0.92       280\n",
      "weighted avg       0.93      0.93      0.92       280\n",
      "\n",
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91       140\n",
      "           1       0.89      0.94      0.91       140\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.91      0.91      0.91       280\n",
      "weighted avg       0.91      0.91      0.91       280\n",
      "\n",
      "Accuracy: 0.92\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92       140\n",
      "           1       0.93      0.91      0.92       140\n",
      "\n",
      "    accuracy                           0.92       280\n",
      "   macro avg       0.92      0.92      0.92       280\n",
      "weighted avg       0.92      0.92      0.92       280\n",
      "\n",
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.90       140\n",
      "           1       0.88      0.93      0.90       140\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.90      0.90      0.90       280\n",
      "weighted avg       0.90      0.90      0.90       280\n",
      "\n",
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       140\n",
      "           1       0.91      0.89      0.90       140\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.90      0.90      0.90       280\n",
      "weighted avg       0.90      0.90      0.90       280\n",
      "\n",
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90       140\n",
      "           1       0.91      0.88      0.89       140\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.90      0.90      0.90       280\n",
      "weighted avg       0.90      0.90      0.90       280\n",
      "\n",
      "Accuracy: 0.88\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88       140\n",
      "           1       0.87      0.89      0.88       140\n",
      "\n",
      "    accuracy                           0.88       280\n",
      "   macro avg       0.88      0.88      0.88       280\n",
      "weighted avg       0.88      0.88      0.88       280\n",
      "\n",
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       140\n",
      "           1       0.89      0.93      0.91       140\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.91      0.91      0.91       280\n",
      "weighted avg       0.91      0.91      0.91       280\n",
      "\n",
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       140\n",
      "           1       0.89      0.93      0.91       140\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.91      0.91      0.91       280\n",
      "weighted avg       0.91      0.91      0.91       280\n",
      "\n",
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       140\n",
      "           1       0.92      0.89      0.91       140\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.91      0.91      0.91       280\n",
      "weighted avg       0.91      0.91      0.91       280\n",
      "\n",
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       140\n",
      "           1       0.92      0.88      0.90       140\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.90      0.90      0.90       280\n",
      "weighted avg       0.90      0.90      0.90       280\n",
      "\n",
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       140\n",
      "           1       0.92      0.86      0.89       140\n",
      "\n",
      "    accuracy                           0.89       280\n",
      "   macro avg       0.89      0.89      0.89       280\n",
      "weighted avg       0.89      0.89      0.89       280\n",
      "\n",
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.90       140\n",
      "           1       0.92      0.86      0.89       140\n",
      "\n",
      "    accuracy                           0.89       280\n",
      "   macro avg       0.89      0.89      0.89       280\n",
      "weighted avg       0.89      0.89      0.89       280\n",
      "\n",
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90       140\n",
      "           1       0.88      0.92      0.90       140\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.90      0.90      0.90       280\n",
      "weighted avg       0.90      0.90      0.90       280\n",
      "\n",
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       140\n",
      "           1       0.91      0.89      0.90       140\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.90      0.90      0.90       280\n",
      "weighted avg       0.90      0.90      0.90       280\n",
      "\n",
      "Accuracy: 0.88\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88       140\n",
      "           1       0.88      0.87      0.87       140\n",
      "\n",
      "    accuracy                           0.88       280\n",
      "   macro avg       0.88      0.88      0.87       280\n",
      "weighted avg       0.88      0.88      0.87       280\n",
      "\n",
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88       140\n",
      "           1       0.86      0.93      0.89       140\n",
      "\n",
      "    accuracy                           0.89       280\n",
      "   macro avg       0.89      0.89      0.89       280\n",
      "weighted avg       0.89      0.89      0.89       280\n",
      "\n",
      "Accuracy: 0.92\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92       140\n",
      "           1       0.93      0.91      0.92       140\n",
      "\n",
      "    accuracy                           0.92       280\n",
      "   macro avg       0.92      0.92      0.92       280\n",
      "weighted avg       0.92      0.92      0.92       280\n",
      "\n",
      "Accuracy: 0.92\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       140\n",
      "           1       0.94      0.90      0.92       140\n",
      "\n",
      "    accuracy                           0.92       280\n",
      "   macro avg       0.92      0.92      0.92       280\n",
      "weighted avg       0.92      0.92      0.92       280\n",
      "\n",
      "Accuracy: 0.93\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93       140\n",
      "           1       0.94      0.91      0.92       140\n",
      "\n",
      "    accuracy                           0.93       280\n",
      "   macro avg       0.93      0.93      0.92       280\n",
      "weighted avg       0.93      0.93      0.92       280\n",
      "\n",
      "Accuracy: 0.87\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87       140\n",
      "           1       0.88      0.86      0.87       140\n",
      "\n",
      "    accuracy                           0.87       280\n",
      "   macro avg       0.87      0.87      0.87       280\n",
      "weighted avg       0.87      0.87      0.87       280\n",
      "\n",
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       140\n",
      "           1       0.92      0.85      0.88       140\n",
      "\n",
      "    accuracy                           0.89       280\n",
      "   macro avg       0.89      0.89      0.89       280\n",
      "weighted avg       0.89      0.89      0.89       280\n",
      "\n",
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89       140\n",
      "           1       0.90      0.89      0.89       140\n",
      "\n",
      "    accuracy                           0.89       280\n",
      "   macro avg       0.89      0.89      0.89       280\n",
      "weighted avg       0.89      0.89      0.89       280\n",
      "\n",
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89       140\n",
      "           1       0.89      0.90      0.89       140\n",
      "\n",
      "    accuracy                           0.89       280\n",
      "   macro avg       0.89      0.89      0.89       280\n",
      "weighted avg       0.89      0.89      0.89       280\n",
      "\n",
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       140\n",
      "           1       0.89      0.91      0.90       140\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.90      0.90      0.90       280\n",
      "weighted avg       0.90      0.90      0.90       280\n",
      "\n",
      "Accuracy: 0.93\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93       140\n",
      "           1       0.94      0.91      0.92       140\n",
      "\n",
      "    accuracy                           0.93       280\n",
      "   macro avg       0.93      0.93      0.92       280\n",
      "weighted avg       0.93      0.93      0.92       280\n",
      "\n",
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.90       140\n",
      "           1       0.92      0.86      0.89       140\n",
      "\n",
      "    accuracy                           0.89       280\n",
      "   macro avg       0.89      0.89      0.89       280\n",
      "weighted avg       0.89      0.89      0.89       280\n",
      "\n",
      "Accuracy: 0.92\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       140\n",
      "           1       0.93      0.90      0.92       140\n",
      "\n",
      "    accuracy                           0.92       280\n",
      "   macro avg       0.92      0.92      0.92       280\n",
      "weighted avg       0.92      0.92      0.92       280\n",
      "\n",
      "Accuracy: 0.86\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86       140\n",
      "           1       0.85      0.87      0.86       140\n",
      "\n",
      "    accuracy                           0.86       280\n",
      "   macro avg       0.86      0.86      0.86       280\n",
      "weighted avg       0.86      0.86      0.86       280\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       140\n",
      "           1       0.96      0.91      0.93       140\n",
      "\n",
      "    accuracy                           0.94       280\n",
      "   macro avg       0.94      0.94      0.94       280\n",
      "weighted avg       0.94      0.94      0.94       280\n",
      "\n",
      "Accuracy: 0.88\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87       140\n",
      "           1       0.86      0.90      0.88       140\n",
      "\n",
      "    accuracy                           0.88       280\n",
      "   macro avg       0.88      0.88      0.87       280\n",
      "weighted avg       0.88      0.88      0.87       280\n",
      "\n",
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89       140\n",
      "           1       0.88      0.91      0.89       140\n",
      "\n",
      "    accuracy                           0.89       280\n",
      "   macro avg       0.89      0.89      0.89       280\n",
      "weighted avg       0.89      0.89      0.89       280\n",
      "\n",
      "Accuracy: 0.93\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       140\n",
      "           1       0.94      0.91      0.93       140\n",
      "\n",
      "    accuracy                           0.93       280\n",
      "   macro avg       0.93      0.93      0.93       280\n",
      "weighted avg       0.93      0.93      0.93       280\n",
      "\n",
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90       140\n",
      "           1       0.87      0.94      0.91       140\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.91      0.90      0.90       280\n",
      "weighted avg       0.91      0.90      0.90       280\n",
      "\n",
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89       140\n",
      "           1       0.88      0.91      0.90       140\n",
      "\n",
      "    accuracy                           0.89       280\n",
      "   macro avg       0.89      0.89      0.89       280\n",
      "weighted avg       0.89      0.89      0.89       280\n",
      "\n",
      "Accuracy: 0.88\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       140\n",
      "           1       0.89      0.86      0.88       140\n",
      "\n",
      "    accuracy                           0.88       280\n",
      "   macro avg       0.88      0.88      0.88       280\n",
      "weighted avg       0.88      0.88      0.88       280\n",
      "\n",
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90       140\n",
      "           1       0.90      0.91      0.90       140\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.90      0.90      0.90       280\n",
      "weighted avg       0.90      0.90      0.90       280\n",
      "\n",
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89       140\n",
      "           1       0.90      0.89      0.89       140\n",
      "\n",
      "    accuracy                           0.89       280\n",
      "   macro avg       0.89      0.89      0.89       280\n",
      "weighted avg       0.89      0.89      0.89       280\n",
      "\n",
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90       140\n",
      "           1       0.90      0.90      0.90       140\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.90      0.90      0.90       280\n",
      "weighted avg       0.90      0.90      0.90       280\n",
      "\n",
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       140\n",
      "           1       0.91      0.91      0.91       140\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.91      0.91      0.91       280\n",
      "weighted avg       0.91      0.91      0.91       280\n",
      "\n",
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       140\n",
      "           1       0.91      0.91      0.91       140\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.91      0.91      0.91       280\n",
      "weighted avg       0.91      0.91      0.91       280\n",
      "\n",
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89       140\n",
      "           1       0.88      0.92      0.90       140\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.90      0.90      0.90       280\n",
      "weighted avg       0.90      0.90      0.90       280\n",
      "\n",
      "Accuracy: 0.93\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       140\n",
      "           1       0.92      0.93      0.93       140\n",
      "\n",
      "    accuracy                           0.93       280\n",
      "   macro avg       0.93      0.93      0.92       280\n",
      "weighted avg       0.93      0.93      0.92       280\n",
      "\n",
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       140\n",
      "           1       0.91      0.89      0.90       140\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.90      0.90      0.90       280\n",
      "weighted avg       0.90      0.90      0.90       280\n",
      "\n",
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89       140\n",
      "           1       0.86      0.95      0.90       140\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.90      0.90      0.90       280\n",
      "weighted avg       0.90      0.90      0.90       280\n",
      "\n",
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90       140\n",
      "           1       0.91      0.89      0.90       140\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.90      0.90      0.90       280\n",
      "weighted avg       0.90      0.90      0.90       280\n",
      "\n",
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       140\n",
      "           1       0.90      0.88      0.89       140\n",
      "\n",
      "    accuracy                           0.89       280\n",
      "   macro avg       0.89      0.89      0.89       280\n",
      "weighted avg       0.89      0.89      0.89       280\n",
      "\n",
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89       140\n",
      "           1       0.88      0.91      0.89       140\n",
      "\n",
      "    accuracy                           0.89       280\n",
      "   macro avg       0.89      0.89      0.89       280\n",
      "weighted avg       0.89      0.89      0.89       280\n",
      "\n",
      "Accuracy: 0.93\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93       140\n",
      "           1       0.92      0.95      0.93       140\n",
      "\n",
      "    accuracy                           0.93       280\n",
      "   macro avg       0.93      0.93      0.93       280\n",
      "weighted avg       0.93      0.93      0.93       280\n",
      "\n",
      "Accuracy: 0.93\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       140\n",
      "           1       0.95      0.91      0.93       140\n",
      "\n",
      "    accuracy                           0.93       280\n",
      "   macro avg       0.93      0.93      0.93       280\n",
      "weighted avg       0.93      0.93      0.93       280\n",
      "\n",
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       140\n",
      "           1       0.91      0.89      0.90       140\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.90      0.90      0.90       280\n",
      "weighted avg       0.90      0.90      0.90       280\n",
      "\n",
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90       140\n",
      "           1       0.88      0.94      0.91       140\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.91      0.90      0.90       280\n",
      "weighted avg       0.91      0.90      0.90       280\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.94       140\n",
      "           1       0.92      0.96      0.94       140\n",
      "\n",
      "    accuracy                           0.94       280\n",
      "   macro avg       0.94      0.94      0.94       280\n",
      "weighted avg       0.94      0.94      0.94       280\n",
      "\n",
      "Accuracy: 0.92\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92       140\n",
      "           1       0.90      0.94      0.92       140\n",
      "\n",
      "    accuracy                           0.92       280\n",
      "   macro avg       0.92      0.92      0.92       280\n",
      "weighted avg       0.92      0.92      0.92       280\n",
      "\n",
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       140\n",
      "           1       0.92      0.89      0.91       140\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.91      0.91      0.91       280\n",
      "weighted avg       0.91      0.91      0.91       280\n",
      "\n",
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       140\n",
      "           1       0.90      0.93      0.91       140\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.91      0.91      0.91       280\n",
      "weighted avg       0.91      0.91      0.91       280\n",
      "\n",
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       140\n",
      "           1       0.90      0.92      0.91       140\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.91      0.91      0.91       280\n",
      "weighted avg       0.91      0.91      0.91       280\n",
      "\n",
      "Accuracy: 0.92\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       140\n",
      "           1       0.92      0.92      0.92       140\n",
      "\n",
      "    accuracy                           0.92       280\n",
      "   macro avg       0.92      0.92      0.92       280\n",
      "weighted avg       0.92      0.92      0.92       280\n",
      "\n",
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       140\n",
      "           1       0.93      0.89      0.91       140\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.91      0.91      0.91       280\n",
      "weighted avg       0.91      0.91      0.91       280\n",
      "\n",
      "Accuracy: 0.88\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.88       140\n",
      "           1       0.85      0.92      0.89       140\n",
      "\n",
      "    accuracy                           0.88       280\n",
      "   macro avg       0.88      0.88      0.88       280\n",
      "weighted avg       0.88      0.88      0.88       280\n",
      "\n",
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       140\n",
      "           1       0.90      0.87      0.88       140\n",
      "\n",
      "    accuracy                           0.89       280\n",
      "   macro avg       0.89      0.89      0.89       280\n",
      "weighted avg       0.89      0.89      0.89       280\n",
      "\n",
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       140\n",
      "           1       0.89      0.93      0.91       140\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.91      0.91      0.91       280\n",
      "weighted avg       0.91      0.91      0.91       280\n",
      "\n",
      "Accuracy: 0.92\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       140\n",
      "           1       0.91      0.93      0.92       140\n",
      "\n",
      "    accuracy                           0.92       280\n",
      "   macro avg       0.92      0.92      0.92       280\n",
      "weighted avg       0.92      0.92      0.92       280\n",
      "\n",
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90       140\n",
      "           1       0.88      0.94      0.91       140\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.91      0.90      0.90       280\n",
      "weighted avg       0.91      0.90      0.90       280\n",
      "\n",
      "Accuracy: 0.93\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       140\n",
      "           1       0.93      0.92      0.93       140\n",
      "\n",
      "    accuracy                           0.93       280\n",
      "   macro avg       0.93      0.93      0.93       280\n",
      "weighted avg       0.93      0.93      0.93       280\n",
      "\n",
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91       140\n",
      "           1       0.92      0.89      0.90       140\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.90      0.90      0.90       280\n",
      "weighted avg       0.90      0.90      0.90       280\n",
      "\n",
      "Accuracy: 0.93\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93       140\n",
      "           1       0.95      0.90      0.92       140\n",
      "\n",
      "    accuracy                           0.93       280\n",
      "   macro avg       0.93      0.93      0.92       280\n",
      "weighted avg       0.93      0.93      0.92       280\n",
      "\n",
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       140\n",
      "           1       0.90      0.93      0.91       140\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.91      0.91      0.91       280\n",
      "weighted avg       0.91      0.91      0.91       280\n",
      "\n",
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       140\n",
      "           1       0.90      0.91      0.91       140\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.91      0.91      0.91       280\n",
      "weighted avg       0.91      0.91      0.91       280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the shuffled dataset\n",
    "data = pd.read_csv('shuffled_combined_features.csv')\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X = data.drop(columns=['Label'])  # Drop the label column to get features\n",
    "y = data['Label']  # The label column\n",
    "\n",
    "for a in range(100):\n",
    "  # Split the data into training and testing sets\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=a, stratify=y)\n",
    "\n",
    "  # Initialize the SVM model\n",
    "  svm_model = SVC(kernel='linear', random_state=42)  # You can change the kernel to 'rbf', 'poly', etc.\n",
    "\n",
    "  # Train the SVM model\n",
    "  svm_model.fit(X_train, y_train)\n",
    "\n",
    "  # Predict the test set\n",
    "  y_pred = svm_model.predict(X_test)\n",
    "\n",
    "  # Evaluate the model\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "  report = classification_report(y_test, y_pred)\n",
    "\n",
    "  # Print the results\n",
    "  print(f\"Accuracy: {accuracy:.2f}\")\n",
    "  print(\"\\nClassification Report:\\n\")\n",
    "  print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "xEyHbQGed0NL",
    "outputId": "a32bb664-fa80-44ed-b94f-2e98a4769b3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       140\n",
      "           1       0.92      0.86      0.89       140\n",
      "\n",
      "    accuracy                           0.89       280\n",
      "   macro avg       0.89      0.89      0.89       280\n",
      "weighted avg       0.89      0.89      0.89       280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the shuffled dataset\n",
    "data = pd.read_csv('shuffled_combined_features.csv')\n",
    "\n",
    "# Fill null values with the average of the respective columns\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X = data.drop(columns=['Label'])  # Drop the label column to get features\n",
    "y = data['Label']  # The label column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm_model = SVC(kernel='linear', random_state=42)  # You can change the kernel to 'rbf', 'poly', etc.\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "jDAGlWn6d7oR",
    "outputId": "87fd84c3-aa81-4424-85ab-b0c2205615fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       140\n",
      "           1       0.99      0.94      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.97      0.96      0.96       280\n",
      "weighted avg       0.97      0.96      0.96       280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the shuffled dataset\n",
    "data = pd.read_csv('shuffled_combined_features.csv')\n",
    "\n",
    "# Fill null values with the average of the respective columns\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X = data.drop(columns=['Label'])  # Drop the label column to get features\n",
    "y = data['Label']  # The label column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "nr1gWNMZeLk9",
    "outputId": "4fde03d7-e9b2-4e13-adac-57cbc725507e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       140\n",
      "           1       0.99      0.93      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       140\n",
      "           1       0.94      0.94      0.94       140\n",
      "\n",
      "    accuracy                           0.94       280\n",
      "   macro avg       0.94      0.94      0.94       280\n",
      "weighted avg       0.94      0.94      0.94       280\n",
      "\n",
      "Accuracy: 0.97\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       140\n",
      "           1       0.97      0.97      0.97       140\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.97      0.97      0.97       280\n",
      "weighted avg       0.97      0.97      0.97       280\n",
      "\n",
      "Accuracy: 0.97\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       140\n",
      "           1       0.99      0.95      0.97       140\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.97      0.97      0.97       280\n",
      "weighted avg       0.97      0.97      0.97       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       140\n",
      "           1       0.94      0.96      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       140\n",
      "           1       0.96      0.96      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.93\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       140\n",
      "           1       0.94      0.92      0.93       140\n",
      "\n",
      "    accuracy                           0.93       280\n",
      "   macro avg       0.93      0.93      0.93       280\n",
      "weighted avg       0.93      0.93      0.93       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95       140\n",
      "           1       0.95      0.94      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.98\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       140\n",
      "           1       0.99      0.96      0.98       140\n",
      "\n",
      "    accuracy                           0.98       280\n",
      "   macro avg       0.98      0.98      0.98       280\n",
      "weighted avg       0.98      0.98      0.98       280\n",
      "\n",
      "Accuracy: 0.97\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       140\n",
      "           1       0.96      0.98      0.97       140\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.97      0.97      0.97       280\n",
      "weighted avg       0.97      0.97      0.97       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95       140\n",
      "           1       0.95      0.94      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.97\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       140\n",
      "           1       0.98      0.97      0.97       140\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.98      0.97      0.97       280\n",
      "weighted avg       0.98      0.97      0.97       280\n",
      "\n",
      "Accuracy: 0.97\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       140\n",
      "           1       0.99      0.95      0.97       140\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.97      0.97      0.97       280\n",
      "weighted avg       0.97      0.97      0.97       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95       140\n",
      "           1       0.96      0.93      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       140\n",
      "           1       0.97      0.96      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.97\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       140\n",
      "           1       0.99      0.94      0.97       140\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.97      0.97      0.97       280\n",
      "weighted avg       0.97      0.97      0.97       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       140\n",
      "           1       0.96      0.95      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95       140\n",
      "           1       0.97      0.94      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95       140\n",
      "           1       0.99      0.91      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.93\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93       140\n",
      "           1       0.92      0.95      0.93       140\n",
      "\n",
      "    accuracy                           0.93       280\n",
      "   macro avg       0.93      0.93      0.93       280\n",
      "weighted avg       0.93      0.93      0.93       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       140\n",
      "           1       0.96      0.96      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.92\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       140\n",
      "           1       0.92      0.92      0.92       140\n",
      "\n",
      "    accuracy                           0.92       280\n",
      "   macro avg       0.92      0.92      0.92       280\n",
      "weighted avg       0.92      0.92      0.92       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       140\n",
      "           1       0.96      0.94      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.97\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98       140\n",
      "           1       1.00      0.95      0.97       140\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.98      0.97      0.97       280\n",
      "weighted avg       0.98      0.97      0.97       280\n",
      "\n",
      "Accuracy: 0.97\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       140\n",
      "           1       0.96      0.97      0.97       140\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.97      0.97      0.97       280\n",
      "weighted avg       0.97      0.97      0.97       280\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       140\n",
      "           1       0.94      0.94      0.94       140\n",
      "\n",
      "    accuracy                           0.94       280\n",
      "   macro avg       0.94      0.94      0.94       280\n",
      "weighted avg       0.94      0.94      0.94       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       140\n",
      "           1       0.97      0.93      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       140\n",
      "           1       0.96      0.92      0.94       140\n",
      "\n",
      "    accuracy                           0.94       280\n",
      "   macro avg       0.94      0.94      0.94       280\n",
      "weighted avg       0.94      0.94      0.94       280\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       140\n",
      "           1       0.94      0.94      0.94       140\n",
      "\n",
      "    accuracy                           0.94       280\n",
      "   macro avg       0.94      0.94      0.94       280\n",
      "weighted avg       0.94      0.94      0.94       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       140\n",
      "           1       0.95      0.96      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       140\n",
      "           1       0.94      0.93      0.94       140\n",
      "\n",
      "    accuracy                           0.94       280\n",
      "   macro avg       0.94      0.94      0.94       280\n",
      "weighted avg       0.94      0.94      0.94       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       140\n",
      "           1       0.96      0.96      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.97\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       140\n",
      "           1       0.96      0.98      0.97       140\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.97      0.97      0.97       280\n",
      "weighted avg       0.97      0.97      0.97       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96       140\n",
      "           1       0.97      0.94      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96       140\n",
      "           1       0.96      0.95      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       140\n",
      "           1       0.94      0.94      0.94       140\n",
      "\n",
      "    accuracy                           0.94       280\n",
      "   macro avg       0.94      0.94      0.94       280\n",
      "weighted avg       0.94      0.94      0.94       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       140\n",
      "           1       0.97      0.95      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       140\n",
      "           1       0.96      0.96      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       140\n",
      "           1       0.96      0.96      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       140\n",
      "           1       0.96      0.96      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.98\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       140\n",
      "           1       0.99      0.96      0.98       140\n",
      "\n",
      "    accuracy                           0.98       280\n",
      "   macro avg       0.98      0.98      0.98       280\n",
      "weighted avg       0.98      0.98      0.98       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       140\n",
      "           1       0.96      0.96      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       140\n",
      "           1       0.99      0.94      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.97      0.96      0.96       280\n",
      "weighted avg       0.97      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       140\n",
      "           1       0.97      0.96      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       140\n",
      "           1       0.94      0.96      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94       140\n",
      "           1       0.96      0.93      0.94       140\n",
      "\n",
      "    accuracy                           0.94       280\n",
      "   macro avg       0.94      0.94      0.94       280\n",
      "weighted avg       0.94      0.94      0.94       280\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       140\n",
      "           1       0.94      0.94      0.94       140\n",
      "\n",
      "    accuracy                           0.94       280\n",
      "   macro avg       0.94      0.94      0.94       280\n",
      "weighted avg       0.94      0.94      0.94       280\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93       140\n",
      "           1       0.92      0.95      0.94       140\n",
      "\n",
      "    accuracy                           0.94       280\n",
      "   macro avg       0.94      0.94      0.94       280\n",
      "weighted avg       0.94      0.94      0.94       280\n",
      "\n",
      "Accuracy: 0.97\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       140\n",
      "           1       0.99      0.96      0.97       140\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.98      0.98      0.97       280\n",
      "weighted avg       0.98      0.97      0.97       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95       140\n",
      "           1       0.97      0.94      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       140\n",
      "           1       0.98      0.94      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       140\n",
      "           1       0.97      0.90      0.93       140\n",
      "\n",
      "    accuracy                           0.94       280\n",
      "   macro avg       0.94      0.94      0.94       280\n",
      "weighted avg       0.94      0.94      0.94       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       140\n",
      "           1       0.96      0.94      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       140\n",
      "           1       0.99      0.93      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       140\n",
      "           1       0.96      0.92      0.94       140\n",
      "\n",
      "    accuracy                           0.94       280\n",
      "   macro avg       0.94      0.94      0.94       280\n",
      "weighted avg       0.94      0.94      0.94       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       140\n",
      "           1       0.96      0.95      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.97\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       140\n",
      "           1       0.97      0.96      0.97       140\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.97      0.97      0.97       280\n",
      "weighted avg       0.97      0.97      0.97       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95       140\n",
      "           1       0.97      0.94      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.97\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       140\n",
      "           1       0.99      0.95      0.97       140\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.97      0.97      0.97       280\n",
      "weighted avg       0.97      0.97      0.97       280\n",
      "\n",
      "Accuracy: 0.97\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       140\n",
      "           1       0.99      0.94      0.97       140\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.97      0.97      0.97       280\n",
      "weighted avg       0.97      0.97      0.97       280\n",
      "\n",
      "Accuracy: 0.97\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       140\n",
      "           1       0.99      0.96      0.97       140\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.97      0.97      0.97       280\n",
      "weighted avg       0.97      0.97      0.97       280\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       140\n",
      "           1       0.94      0.94      0.94       140\n",
      "\n",
      "    accuracy                           0.94       280\n",
      "   macro avg       0.94      0.94      0.94       280\n",
      "weighted avg       0.94      0.94      0.94       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       140\n",
      "           1       0.96      0.96      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.97\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       140\n",
      "           1       0.97      0.96      0.97       140\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.97      0.97      0.97       280\n",
      "weighted avg       0.97      0.97      0.97       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       140\n",
      "           1       0.94      0.96      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       140\n",
      "           1       0.95      0.95      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       140\n",
      "           1       0.96      0.95      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       140\n",
      "           1       0.96      0.96      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       140\n",
      "           1       0.97      0.91      0.94       140\n",
      "\n",
      "    accuracy                           0.94       280\n",
      "   macro avg       0.94      0.94      0.94       280\n",
      "weighted avg       0.94      0.94      0.94       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       140\n",
      "           1       0.96      0.96      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       140\n",
      "           1       0.94      0.96      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       140\n",
      "           1       0.94      0.94      0.94       140\n",
      "\n",
      "    accuracy                           0.94       280\n",
      "   macro avg       0.94      0.94      0.94       280\n",
      "weighted avg       0.94      0.94      0.94       280\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       140\n",
      "           1       0.96      0.91      0.94       140\n",
      "\n",
      "    accuracy                           0.94       280\n",
      "   macro avg       0.94      0.94      0.94       280\n",
      "weighted avg       0.94      0.94      0.94       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       140\n",
      "           1       0.98      0.93      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.93\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       140\n",
      "           1       0.93      0.92      0.93       140\n",
      "\n",
      "    accuracy                           0.93       280\n",
      "   macro avg       0.93      0.93      0.93       280\n",
      "weighted avg       0.93      0.93      0.93       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       140\n",
      "           1       0.96      0.97      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       140\n",
      "           1       0.97      0.93      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.97\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       140\n",
      "           1       0.97      0.97      0.97       140\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.97      0.97      0.97       280\n",
      "weighted avg       0.97      0.97      0.97       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       140\n",
      "           1       0.96      0.94      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.97\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       140\n",
      "           1       0.97      0.96      0.97       140\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.97      0.97      0.97       280\n",
      "weighted avg       0.97      0.97      0.97       280\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       140\n",
      "           1       0.96      0.91      0.94       140\n",
      "\n",
      "    accuracy                           0.94       280\n",
      "   macro avg       0.94      0.94      0.94       280\n",
      "weighted avg       0.94      0.94      0.94       280\n",
      "\n",
      "Accuracy: 0.93\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93       140\n",
      "           1       0.91      0.96      0.93       140\n",
      "\n",
      "    accuracy                           0.93       280\n",
      "   macro avg       0.93      0.93      0.93       280\n",
      "weighted avg       0.93      0.93      0.93       280\n",
      "\n",
      "Accuracy: 0.97\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       140\n",
      "           1       0.98      0.96      0.97       140\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.97      0.97      0.97       280\n",
      "weighted avg       0.97      0.97      0.97       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96       140\n",
      "           1       0.95      0.98      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.97\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       140\n",
      "           1       0.96      0.97      0.97       140\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.97      0.97      0.97       280\n",
      "weighted avg       0.97      0.97      0.97       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       140\n",
      "           1       0.96      0.94      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       140\n",
      "           1       0.95      0.96      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96       140\n",
      "           1       0.96      0.95      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       140\n",
      "           1       0.95      0.96      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       140\n",
      "           1       0.96      0.94      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       140\n",
      "           1       0.96      0.96      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.93\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       140\n",
      "           1       0.93      0.93      0.93       140\n",
      "\n",
      "    accuracy                           0.93       280\n",
      "   macro avg       0.93      0.93      0.93       280\n",
      "weighted avg       0.93      0.93      0.93       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       140\n",
      "           1       0.97      0.96      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       140\n",
      "           1       0.95      0.97      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       140\n",
      "           1       0.96      0.94      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       140\n",
      "           1       0.97      0.93      0.95       140\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.95      0.95      0.95       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       140\n",
      "           1       0.97      0.95      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       140\n",
      "           1       0.98      0.94      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n",
      "Accuracy: 0.98\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       140\n",
      "           1       1.00      0.96      0.98       140\n",
      "\n",
      "    accuracy                           0.98       280\n",
      "   macro avg       0.98      0.98      0.98       280\n",
      "weighted avg       0.98      0.98      0.98       280\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       140\n",
      "           1       0.98      0.94      0.96       140\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.96      0.96      0.96       280\n",
      "weighted avg       0.96      0.96      0.96       280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the shuffled dataset\n",
    "data = pd.read_csv('shuffled_combined_features.csv')\n",
    "\n",
    "# Fill null values with the average of the respective columns\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X = data.drop(columns=['Label'])  # Drop the label column to get features\n",
    "y = data['Label']  # The label column\n",
    "for a in range(100):\n",
    "  # Split the data into training and testing sets\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=a, stratify=y)\n",
    "\n",
    "  # Initialize the Random Forest model\n",
    "  rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "  # Train the Random Forest model\n",
    "  rf_model.fit(X_train, y_train)\n",
    "\n",
    "  # Predict the test set\n",
    "  y_pred = rf_model.predict(X_test)\n",
    "\n",
    "  # Evaluate the model\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "  report = classification_report(y_test, y_pred)\n",
    "\n",
    "  # Print the results\n",
    "  print(f\"Accuracy: {accuracy:.2f}\")\n",
    "  print(\"\\nClassification Report:\\n\")\n",
    "  print(report)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
